-e # ===== FILE: ./core/config.py =====

"""
============================================================
 HIREX â€¢ core/config.py
 ------------------------------------------------------------
 Global configuration for backend constants, environment
 variables, and directory paths.

 Version : 2.1.2
 Author  : Sri Akash Kadali
============================================================
"""

from __future__ import annotations

import os
from pathlib import Path
from dotenv import load_dotenv


# ============================================================
# ðŸŒ Environment Setup
# ============================================================

_env_loaded = (
    load_dotenv(dotenv_path=Path(__file__).resolve().parents[2] / ".env")
    or load_dotenv(dotenv_path=Path(__file__).resolve().parents[1] / ".env")
    or load_dotenv()
)


def _clean_env(val: str | None, default: str = "") -> str:
    v = (val if val is not None else default)
    return str(v).strip().strip('"').strip("'")


def _getenv_clean(name: str, default: str = "") -> str:
    return _clean_env(os.getenv(name), default)


# ============================================================
# ðŸ“ Directory Structure (portable / any machine)
# ============================================================

BASE_DIR = Path(__file__).resolve().parents[2]
if not (BASE_DIR / "backend").exists():
    candidate = Path(__file__).resolve().parents[1]
    BASE_DIR = candidate if (candidate / "backend").exists() else Path.cwd()

BACKEND_DIR = BASE_DIR / "backend"
FRONTEND_DIR = BASE_DIR / "frontend"

DATA_DIR = BACKEND_DIR / "data"
CACHE_DIR = DATA_DIR / "cache"
TEMP_LATEX_DIR = CACHE_DIR / "latex_builds"
TEMPLATE_DIR = BACKEND_DIR / "templates"

# Kept for backwards compatibility; not used for PDFs anymore
OUTPUT_DIR = DATA_DIR / "output"
SAMPLES_DIR = DATA_DIR / "samples"
LOGS_DIR = DATA_DIR / "logs"
HISTORY_DIR = DATA_DIR / "history"
MASTERMINDS_DIR = DATA_DIR / "mastermind_sessions"
CONTEXTS_DIR = DATA_DIR / "contexts"

# --- Legacy sample dirs (kept to avoid breaking any imports) ---
SAMPLES_JOB_RESUMES_DIR = SAMPLES_DIR / "Job Resumes"
SAMPLES_COVER_LETTERS_DIR = SAMPLES_DIR / "Cover Letters"
SAMPLES_JOB_RESUME_HUMANIZED_DIR = SAMPLES_DIR / "Job Resume Humanized"

# --- NEW flat libraries (single folder per artifact type) ---
# Default to project-local backend/data/*; allow absolute overrides via .env
def _resolve_env_path(var_name: str, default_path: Path) -> Path:
    raw = _getenv_clean(var_name, "")
    if not raw:
        return default_path
    p = Path(os.path.expanduser(raw))
    if not p.is_absolute():
        p = BASE_DIR / p
    return p

OPTIMIZED_DIR = _resolve_env_path("OPTIMIZED_DIR", DATA_DIR / "Optimized")
HUMANIZED_DIR = _resolve_env_path("HUMANIZED_DIR", DATA_DIR / "Humanized")
COVER_LETTERS_DIR = _resolve_env_path("COVER_LETTERS_DIR", DATA_DIR / "Cover Letters")

for d in (
    DATA_DIR,
    CACHE_DIR,
    TEMP_LATEX_DIR,
    TEMPLATE_DIR,
    OUTPUT_DIR,
    SAMPLES_DIR,
    LOGS_DIR,
    HISTORY_DIR,
    MASTERMINDS_DIR,
    CONTEXTS_DIR,
    SAMPLES_JOB_RESUMES_DIR,
    SAMPLES_COVER_LETTERS_DIR,
    SAMPLES_JOB_RESUME_HUMANIZED_DIR,
    OPTIMIZED_DIR,
    HUMANIZED_DIR,
    COVER_LETTERS_DIR,
):
    d.mkdir(parents=True, exist_ok=True)

(LOGS_DIR / "events.jsonl").touch(exist_ok=True)


# ============================================================
# âš™ï¸ Core Settings
# ============================================================

APP_NAME = "HIREX"
APP_VERSION = "2.1.2"
DEBUG_MODE = _getenv_clean("DEBUG", "true").lower() == "true"

MAX_UPLOAD_MB = int(_getenv_clean("MAX_UPLOAD_MB", "5"))
ALLOWED_EXTENSIONS = {".tex", ".txt"}

DEFAULT_MODEL = _getenv_clean("DEFAULT_MODEL", "gpt-4o-mini")
API_BASE_URL = _getenv_clean("API_BASE_URL", "http://127.0.0.1:8000")

CANDIDATE_NAME = _getenv_clean("CANDIDATE_NAME", "Sri Akash Kadali")
APPLICANT_EMAIL = _getenv_clean("APPLICANT_EMAIL", "kadali18@umd.edu")
APPLICANT_PHONE = _getenv_clean("APPLICANT_PHONE", "+1 240-726-9356")
APPLICANT_CITYSTATE = _getenv_clean("APPLICANT_CITYSTATE", "College Park, MD")

# ============================================================
# ðŸ” Security & Secrets
# ============================================================

SECRET_KEY = _getenv_clean("HIREX_SECRET", "hirex-dev-secret")
JWT_ALGORITHM = "HS256"


# ============================================================
# ðŸ¤– API Keys (OpenAI + Humanize)
# ============================================================

OPENAI_API_KEY = _getenv_clean("OPENAI_API_KEY", "")

HUMANIZE_API_KEY = _clean_env(
    os.getenv("HUMANIZE_API_KEY")
    or os.getenv("HUMANIZE_TOKEN")
    or os.getenv("AI_HUMANIZE_KEY")
    or os.getenv("AIHUMANIZE_KEY")
    or ""
)

HUMANIZE_MAIL = _clean_env(
    os.getenv("HUMANIZE_MAIL")
    or os.getenv("AI_HUMANIZE_MAIL")
    or os.getenv("HUMANIZE_API_MAIL")
    or os.getenv("AIHUMANIZE_MAIL")
    or "kadali18@umd.edu"
)

# âœ… Default to using Humanize everywhere (can be overridden in .env)
HUMANIZE_DEFAULT_ON = _getenv_clean("HUMANIZE_DEFAULT_ON", "true").lower() in {"1", "true", "yes", "on"}
# Default Humanize mode for the service (0=quality, 1=balance, 2=enhanced)
HUMANIZE_MODE_DEFAULT = _getenv_clean("HUMANIZE_MODE_DEFAULT", "balance").lower()
AIHUMANIZE_MODE_ID = {"quality": "0", "balance": "1", "enhanced": "2"}

HUMANIZE_CONFIG_OK = bool(HUMANIZE_API_KEY and HUMANIZE_MAIL)

if DEBUG_MODE:
    if not OPENAI_API_KEY:
        print("[HIREX] âš ï¸ OPENAI_API_KEY not found in environment.")
    if not HUMANIZE_API_KEY:
        print("[HIREX] âš ï¸ HUMANIZE_API_KEY not found. Humanize will fail unless fallback is enabled.")
    if not HUMANIZE_MAIL:
        print("[HIREX] âš ï¸ HUMANIZE_MAIL not set. It must match your AIHumanize registered email.")
    print(f"[HIREX] â„¹ï¸ HUMANIZE_DEFAULT_ON={HUMANIZE_DEFAULT_ON}, HUMANIZE_MODE_DEFAULT={HUMANIZE_MODE_DEFAULT}")


# ============================================================
# ðŸ§· Helpers
# ============================================================

def _ensure_file(path: Path, content: str) -> None:
    if not path.exists():
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(content, encoding="utf-8")
        if DEBUG_MODE:
            print(f"[HIREX] ðŸ“„ Created default: {path}")


def _slugify(s: str) -> str:
    import re, unicodedata
    s = unicodedata.normalize("NFKD", s)
    s = re.sub(r"[^\w\s.-]", "", s)
    s = re.sub(r"\s+", "_", s.strip())
    return s or "unnamed"


def _candidate_prefix() -> str:
    return _slugify(CANDIDATE_NAME) or "Candidate"


# ============================================================
# ðŸ§  Feature Module Paths & Defaults
# ============================================================

BASE_COVERLETTER_PATH = _resolve_env_path("BASE_COVERLETTER_PATH", SAMPLES_DIR / "base_coverletter.tex")
BASE_RESUME_PATH = _resolve_env_path("BASE_RESUME_PATH", SAMPLES_DIR / "base_resume.tex")

LOG_PATH = LOGS_DIR / "events.jsonl"
HISTORY_PATH = HISTORY_DIR / "history.jsonl"

MASTERMINDS_PATH = MASTERMINDS_DIR
MASTERMINDS_MODEL = _getenv_clean("MASTERMINDS_MODEL", DEFAULT_MODEL)

# â— Keep fallback OFF so we don't leak [LOCAL-FALLBACK:*]. Fail hard if Humanize is down.
SUPERHUMAN_LOCAL_ENABLED = _getenv_clean("SUPERHUMAN_LOCAL_ENABLED", "false").lower() in {"1", "true", "yes", "on"}
SUPERHUMAN_MODEL = _getenv_clean("SUPERHUMAN_MODEL", DEFAULT_MODEL)
COVERLETTER_MODEL = _getenv_clean("COVERLETTER_MODEL", DEFAULT_MODEL)
TALK_SUMMARY_MODEL = _getenv_clean("TALK_SUMMARY_MODEL", "gpt-4o-mini")
TALK_ANSWER_MODEL = _getenv_clean("TALK_ANSWER_MODEL", DEFAULT_MODEL)


def is_humanize_enabled() -> bool:
    """
    Humanize is considered enabled when:
      â€¢ HUMANIZE_DEFAULT_ON is true (default),
      â€¢ we have valid key+mail,
      â€¢ and we are NOT using local fallback.
    """
    return HUMANIZE_DEFAULT_ON and HUMANIZE_CONFIG_OK and not SUPERHUMAN_LOCAL_ENABLED


def get_contexts_dir() -> Path:
    """Return the canonical contexts directory used by /api/context and friends."""
    return CONTEXTS_DIR


# ============================================================
# âœ¨ Portable Default Templates
# ============================================================

_DEFAULT_RESUME_TEX = r"""% HIREX default base_resume.tex
\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{enumitem}
\pagenumbering{gobble}
\begin{document}
\begin{center}
{\LARGE Your Name}\\
\vspace{2pt}
your.email@example.com \quad | \quad (123) 456-7890 \quad | \url{https://example.com}
\end{center}
\vspace{8pt}
\section*{Summary}
Results-oriented professional with experience in software engineering and AI.
\section*{Experience}
\textbf{Company} \hfill City, ST \\
\emph{Role} \hfill 2023--Present
\begin{itemize}[leftmargin=*]
    \item Bullet 1 describing impact.
    \item Bullet 2 describing impact.
\end{itemize}
\section*{Education}
\textbf{University}, Degree, Year
\end{document}
"""

_DEFAULT_COVERLETTER_TEX = r"""% HIREX default base_coverletter.tex (portable)
\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\pagenumbering{gobble}
\begin{document}
\noindent Date: \today

\vspace{10pt}
Hiring Manager \\
Company \\
City, State

\vspace{10pt}
Dear Hiring Manager,

I am excited to apply for the role. My background in software and AI aligns with your needs.

%-----------BODY-START-----------
% (Body content will be injected here by HIREX)
%-----------BODY-END-------------

\vspace{12pt}
Sincerely, \\
Your Name
\end{document}
"""

_ensure_file(BASE_RESUME_PATH, _DEFAULT_RESUME_TEX)
_ensure_file(BASE_COVERLETTER_PATH, _DEFAULT_COVERLETTER_TEX)

DEFAULT_BASE_RESUME = BASE_RESUME_PATH

os.environ.setdefault("BASE_RESUME_PATH", str(BASE_RESUME_PATH))
os.environ.setdefault("BASE_COVERLETTER_PATH", str(BASE_COVERLETTER_PATH))


# ============================================================
# ðŸ’° Model Catalog & Pricing
# ============================================================

OPENAI_MODELS = [
    "gpt-5",
    "gpt-5-mini",
    "gpt-5-nano",
    "gpt-5-chat-latest",
    "gpt-5-thinking",
    "gpt-5-thinking-mini",
    "gpt-5-thinking-nano",
    "gpt-5-pro",
    "gpt-4o",
    "gpt-4o-mini",
    "o3",
    "o3-mini",
]

MODEL_ALIASES = {
    "GPT-5 (Auto)": "gpt-5",
    "GPT-5 Fast / Instant": "gpt-5-chat-latest",
    "GPT-5 Thinking": "gpt-5-thinking",
    "GPT-5 Pro": "gpt-5-pro",
    "GPT-5 Mini": "gpt-5-mini",
    "GPT-5 Nano": "gpt-5-nano",
    "GPT-4o": "gpt-4o",
}

OPENAI_MODEL_PRICING = {
    "gpt-5": {"input": 1.25, "output": 10.00, "cached_input": 0.125},
    "gpt-5-mini": {"input": 0.25, "output": 2.00, "cached_input": 0.025},
    "gpt-5-nano": {"input": 0.05, "output": 0.40, "cached_input": 0.005},
    "gpt-5-pro": {"input": 15.00, "output": 120.00},
    "gpt-4o": {"input": 5.00, "output": 15.00},
    "gpt-4o-mini": {"input": 0.15, "output": 0.60},
    "o3": {"input": 1.10, "output": 4.40},
    "o3-mini": {"input": 0.60, "output": 2.50},
}

AIHUMANIZE_PLANS = {
    "basic": {"price_month": 6, "words_per_request": 500},
    "starter": {"price_month": 15, "words_per_request": 500},
    "pro": {"price_month": 25, "words_per_request": 1500},
    "premium": {"price_month": 40, "words_per_request": 3000},
}

AVAILABLE_MODELS = {
    "openai": OPENAI_MODELS,
    "aihumanize": ["quality", "balance", "enhanced", "private"],
}

MODEL_PRICING = {
    "openai": OPENAI_MODEL_PRICING,
    "aihumanize": {
        "modes": ["quality", "balance", "enhanced", "private"],
        "plans": AIHUMANIZE_PLANS,
        "unit": "subscription",
    },
}


# ============================================================
# ðŸ§© Output Path Utilities (NEW flat-folder scheme)
# ============================================================

def _slug(s: str) -> str:
    return _slugify(s)


def build_filenames(company: str, role: str) -> dict[str, str]:
    """
    Standardized final artifact names.

    â€¢ Optimized resumes:
        "Sri_{Company}_{Role}.pdf"
    â€¢ Humanized resumes:
        "Sri_Kadali_{Company}_{Role}.pdf"
    â€¢ Cover letters:
        "Sri_{Company}_{Role}_Cover_Letter.pdf"
    """
    c, r = _slug(company), _slug(role)
    return {
        "optimized":    f"Sri_{c}_{r}.pdf",
        "humanized":    f"Sri_Kadali_{c}_{r}.pdf",
        "cover_letter": f"Sri_{c}_{r}_CoverLetter.pdf",
    }


# --- Final output locations (no per-job subfolders) ---

def get_optimized_pdf_path(company: str, role: str) -> Path:
    names = build_filenames(company, role)
    return (OPTIMIZED_DIR / names["optimized"]).resolve()


def get_humanized_pdf_path(company: str, role: str) -> Path:
    names = build_filenames(company, role)
    return (HUMANIZED_DIR / names["humanized"]).resolve()


def get_coverletter_pdf_path(company: str, role: str) -> Path:
    names = build_filenames(company, role)
    return (COVER_LETTERS_DIR / names["cover_letter"]).resolve()


# --- Backwards-compat sample helpers now map to the same flat scheme ---

def get_sample_resume_pdf_path(company: str, role: str) -> Path:
    return get_optimized_pdf_path(company, role)


def get_sample_humanized_pdf_path(company: str, role: str) -> Path:
    return get_humanized_pdf_path(company, role)


def get_sample_coverletter_pdf_path(company: str, role: str) -> Path:
    return get_coverletter_pdf_path(company, role)


# --- Deprecated: per-job folder builder (left as no-op alias to avoid import errors) ---

def get_job_run_dir(company: str, role: str) -> Path:
    """
    Deprecated: Per-job directories are no longer used.
    Returns OPTIMIZED_DIR for compatibility if any caller still references this.
    """
    return OPTIMIZED_DIR


# ============================================================
# ðŸ“Š Diagnostics
# ============================================================

if __name__ == "__main__":
    print("=========== HIREX CONFIG ===========")
    print(f"APP_NAME              : {APP_NAME}")
    print(f"VERSION               : {APP_VERSION}")
    print(f"BASE_DIR              : {BASE_DIR}")
    print(f"OPENAI_API_KEY_LEN    : {len(OPENAI_API_KEY) if OPENAI_API_KEY else 0}")
    print(f"HUMANIZE_API_KEY_LEN  : {len(HUMANIZE_API_KEY) if HUMANIZE_API_KEY else 0}")
    print(f"HUMANIZE_MAIL         : {HUMANIZE_MAIL or 'missing'}")
    print(f"SUPERHUMAN_LOCAL      : {SUPERHUMAN_LOCAL_ENABLED}")
    print(f"HUMANIZE_DEFAULT_ON   : {HUMANIZE_DEFAULT_ON}")
    print(f"HUMANIZE_MODE_DEFAULT : {HUMANIZE_MODE_DEFAULT} (id={AIHUMANIZE_MODE_ID.get(HUMANIZE_MODE_DEFAULT,'?')})")
    print(f"HUMANIZE_ENABLED      : {is_humanize_enabled()}")
    print(f"DEFAULT_MODEL         : {DEFAULT_MODEL}")
    print(f"OPTIMIZED_DIR         : {OPTIMIZED_DIR}")
    print(f"HUMANIZED_DIR         : {HUMANIZED_DIR}")
    print(f"COVER_LETTERS_DIR     : {COVER_LETTERS_DIR}")-e 


-e # ===== FILE: ./core/compiler.py =====

"""
HIREX â€¢ core/compiler.py
Secure LaTeX compiler â€” converts .tex â†’ .pdf in a sandboxed temp directory.
Prevents shell escapes, runs pdflatex with restricted flags.
Author: Sri Akash Kadali
"""

from __future__ import annotations

import os
import shutil
import subprocess
import tempfile
from pathlib import Path

from backend.core import config

# Robust logger wrapper (works with both new/old signatures)
try:
    from backend.core.utils import log_event as _core_log_event  # type: ignore

    def _elog(event: str, meta: dict | None = None) -> None:
        try:
            _core_log_event(event, meta or {})
        except TypeError:
            # Back-compat: older log_event(msg: str)
            _core_log_event(f"{event} {meta or ''}")  # type: ignore
except Exception:  # pragma: no cover
    def _elog(event: str, meta: dict | None = None) -> None:  # fallback to print
        print(event, meta or "")


# ============================================================
# ðŸ§© Safe PDF Compilation Utility
# ============================================================
def compile_latex_safely(tex_string: str) -> bytes | None:
    """
    Compiles LaTeX source code into PDF bytes securely.
    Returns PDF bytes (on success) or None (on failure).

    Security & Stability:
    - Uses sandboxed temp directory under config.TEMP_LATEX_DIR
    - Disables shell escape and restricts file I/O (openin/openout "p")
    - Runs pdflatex twice for stable references
    - Cleans up temporary files automatically
    - Compatible with TeX Live / MiKTeX on all OS
    """
    pdflatex_path = shutil.which("pdflatex")
    if pdflatex_path is None:
        _elog("latex_pdflatex_missing", {"detail": "pdflatex not found in PATH"})
        return None

    # Ensure our build root exists (tempfile will use it as parent)
    try:
        Path(config.TEMP_LATEX_DIR).mkdir(parents=True, exist_ok=True)
    except Exception:
        # If TEMP_LATEX_DIR is missing or invalid, fall back to system tmp
        pass

    # Safer TeX environment
    env = os.environ.copy()
    # Prevent TeX from reading/writing outside the working directory
    env.setdefault("openout_any", "p")   # p = paranoid (write only in cwd)
    env.setdefault("openin_any", "p")    # p = paranoid (read only in cwd)
    # Explicitly disable shell escape
    env.setdefault("shell_escape", "f")  # f = false
    # Keep logs readable but bounded
    env.setdefault("max_print_line", "1000")

    try:
        temp_root = getattr(config, "TEMP_LATEX_DIR", None)
        with tempfile.TemporaryDirectory(dir=str(temp_root) if temp_root else None) as tmpdir:
            tmp = Path(tmpdir)
            tex_path = tmp / "main.tex"
            pdf_path = tmp / "main.pdf"
            log_path = tmp / "compile.log"

            # Write LaTeX source
            tex_path.write_text(tex_string, encoding="utf-8")
            _elog("latex_compile_start", {"workdir": str(tmp)})

            # Safe compile command (explicitly disable shell-escape)
            # IMPORTANT: use relative filename (main.tex), not absolute path,
            # so TeX in paranoid mode (openin_any=p) will read it.
            cmd = [
                pdflatex_path,
                "-interaction=nonstopmode",
                "-halt-on-error",
                "-file-line-error",
                "-no-shell-escape",
                "-synctex=0",
                tex_path.name,  # <--- changed from str(tex_path)
            ]

            # Run pdflatex twice for cross-refs
            for i in range(2):
                proc = subprocess.run(
                    cmd,
                    cwd=tmp,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.STDOUT,
                    timeout=90,
                    encoding="utf-8",
                    errors="ignore",
                    check=False,
                    env=env,
                )
                # Append compiler output
                try:
                    with open(log_path, "a", encoding="utf-8") as lf:
                        lf.write(proc.stdout or "")
                        lf.write("\n")
                except Exception:
                    pass

                _elog("latex_pdflatex_pass", {"pass": i + 1, "returncode": proc.returncode})

            # Check PDF output
            if pdf_path.exists():
                pdf_bytes = pdf_path.read_bytes()
                size_kb = len(pdf_bytes) / 1024
                _elog("latex_pdf_built", {"size_kb": round(size_kb, 1)})
                return pdf_bytes

            # Error fallback â€” show last ~20 lines of log
            if log_path.exists():
                lines = log_path.read_text(encoding="utf-8", errors="ignore").splitlines()
                tail = "\n".join(lines[-20:])
                _elog("latex_no_pdf", {"tail": tail})
            else:
                _elog("latex_no_log", {"detail": "Compilation failed â€” no log file created"})
            return None

    except subprocess.TimeoutExpired:
        _elog("latex_timeout", {"limit_seconds": 90})
        return None
    except Exception as e:
        _elog("latex_unexpected_error", {"error": str(e)})
        return None


# ============================================================
# ðŸ§ª Local Test
# ============================================================
if __name__ == "__main__":
    sample_tex = r"""
    \documentclass{article}
    \begin{document}
    Hello World! This is a HIREX LaTeX compile test.
    \end{document}
    """
    result = compile_latex_safely(sample_tex)
    print("âœ… PDF generated:", bool(result))
-e 


-e # ===== FILE: ./core/security.py =====

"""
HIREX â€¢ core/security.py (v2.0.0)
Security and validation utilities for uploaded files and user input.

âš ï¸ This build preserves full LaTeX content (no sanitization or macro stripping).
It keeps a backward-compatible `secure_tex_input(...)` API:

  â€¢ secure_tex_input(text: str) -> str
      Pass-through (returns text unchanged).

  â€¢ secure_tex_input(filename: str, content: bytes|bytearray|str) -> str
      Validates file (extension/size/non-empty), decodes to UTF-8, and returns raw LaTeX.

Author: Sri Akash Kadali
"""

from __future__ import annotations

import os
from typing import Any, Union

from backend.core import config
from backend.core.utils import safe_filename, log_event


# ============================================================
# âš™ï¸ File Validation
# ============================================================
def validate_file(upload_name: str, content: Union[bytes, bytearray, str]) -> str:
    """
    Validate uploaded file before use.
    Returns sanitized filename if safe, else raises ValueError.
    """
    if not upload_name:
        raise ValueError("âŒ Missing filename in upload.")

    _, ext = os.path.splitext(upload_name)
    allowed = getattr(config, "ALLOWED_EXTENSIONS", {".tex"})
    if ext.lower() not in allowed:
        raise ValueError(f"âŒ Invalid file extension: {ext} (allowed: {', '.join(sorted(allowed))})")

    # normalize to bytes for size & emptiness checks
    raw = content if isinstance(content, (bytes, bytearray)) else str(content).encode("utf-8", "ignore")

    size_mb = len(raw) / (1024 * 1024)
    max_mb = float(getattr(config, "MAX_UPLOAD_MB", 5))
    if size_mb > max_mb:
        raise ValueError(f"âŒ File exceeds {max_mb:.0f} MB limit (got {size_mb:.2f} MB).")

    if not raw.strip():
        raise ValueError("âŒ Uploaded file is empty.")

    safe_name = safe_filename(upload_name)
    # log_event supports string + optional meta signature across builds
    log_event(f"âœ… File validated: {safe_name} ({size_mb:.2f} MB)")
    return safe_name


# ============================================================
# ðŸ§© Pass-through LaTeX (No Sanitization)
# ============================================================
def secure_tex_input(*args: Any) -> str:
    """
    Backward-compatible pass-through.

    Usage A (strings in code paths â€” preserve as-is):
        secure_tex_input(text: str) -> str

    Usage B (uploads â€” validate & decode):
        secure_tex_input(filename: str, content: bytes|bytearray|str) -> str
    """
    # --- Usage A: single arg (plain text) ---
    if len(args) == 1:
        text = args[0]
        if text is None:
            return ""
        if not isinstance(text, str):
            text = str(text)
        # No escaping/sanitization â€” preserve full LaTeX/content
        return text

    # --- Usage B: two args (filename + raw content) ---
    if len(args) == 2:
        filename, content = args[0], args[1]
        _ = validate_file(str(filename), content)

        # Decode to UTF-8 lossily; preserve bytes that decode
        if isinstance(content, (bytes, bytearray)):
            tex = content.decode("utf-8", errors="ignore")
        elif isinstance(content, str):
            tex = content
        else:
            raise TypeError("Unsupported content type for LaTeX input. Expected bytes or str.")

        log_event(f"âœ… Raw LaTeX preserved and validated for: {filename}")
        return tex

    # --- Invalid usage ---
    raise TypeError(
        "secure_tex_input expects either (text: str) OR (filename: str, content: bytes|bytearray|str)"
    )


# ============================================================
# ðŸ§ª Local Test
# ============================================================
if __name__ == "__main__":
    example_bytes = br"""
    \documentclass{article}
    \begin{document}
    Hello \textbf{World!} This content should remain unchanged.
    \input{my_commands.tex}
    \end{document}
    """

    try:
        # File path usage
        raw_from_file = secure_tex_input("resume.tex", example_bytes)
        print("==== Raw (file) Output ====")
        print(raw_from_file)

        # Plain text usage
        raw_text = secure_tex_input(r"\section*{Projects} \textit{Keep everything intact.}")
        print("\n==== Raw (text) Output ====")
        print(raw_text)
    except Exception as e:
        print("ERROR:", e)
-e 


-e # ===== FILE: ./core/mastermind_memory.py =====

# ============================================================
#  HIREX v2.0.0 â€” backend/data/mastermind_sessions.py
#  ------------------------------------------------------------
#  Lightweight filesystem store for MasterMind chat sessions.
#  Compatible with /api/mastermind endpoints.
#  â€¢ Robust path resolution via backend.core.config
#  â€¢ UTF-8 safe read/write with graceful fallbacks
#  â€¢ Returns both legacy (created) and modern (created_at/updated_at) fields
# ============================================================

from __future__ import annotations

import json
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional

# Prefer configured directory; fall back to repo-friendly defaults
try:
    from backend.core import config
    _DEFAULT_DIR = Path(
        getattr(config, "MASTERMINDS_PATH", getattr(config, "MASTERMINDS_DIR", Path("backend") / "data" / "mastermind_sessions"))
    )
except Exception:
    _DEFAULT_DIR = Path("backend/data/mastermind_sessions")

DATA_DIR: Path = _DEFAULT_DIR
DATA_DIR.mkdir(parents=True, exist_ok=True)


def _now_iso() -> str:
    return datetime.utcnow().isoformat()


def _session_path(session_id: str) -> Path:
    return DATA_DIR / f"{session_id}.json"


def _read_json(path: Path) -> Optional[Dict[str, Any]]:
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return None


def _write_json(path: Path, data: Dict[str, Any]) -> None:
    path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")


def _new_session_id() -> str:
    return f"mm_{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}_{uuid.uuid4().hex[:6]}"


def start_session(meta: Dict[str, Any]) -> Dict[str, Any]:
    """
    Create a new session file with provided metadata.
    Returns full session dict.
    """
    sid = _new_session_id()
    now = _now_iso()
    data: Dict[str, Any] = {
        "id": sid,
        "created": now,            # legacy
        "created_at": now,         # modern
        "updated_at": now,
        "meta": meta or {},
        "messages": [],
    }
    _write_json(_session_path(sid), data)
    return data


def load_session(session_id: str) -> Dict[str, Any]:
    """
    Load a session by id. Returns {} if not found or unreadable.
    """
    p = _session_path(session_id)
    data = _read_json(p)
    return data or {}


def append_message(session_id: str, message: Dict[str, Any]) -> Dict[str, Any]:
    """
    Append a single message dict to a session (creates file if missing).
    Returns the updated session dict.
    """
    p = _session_path(session_id)
    data = _read_json(p) or {
        "id": session_id,
        "created": _now_iso(),
        "created_at": _now_iso(),
        "updated_at": _now_iso(),
        "meta": {},
        "messages": [],
    }
    data.setdefault("messages", []).append(message)
    data["updated_at"] = _now_iso()
    _write_json(p, data)
    return data


def list_sessions() -> List[Dict[str, Any]]:
    """
    Return a list of session metadata for dashboards.
    Sorted by updated_at (desc), falling back to created/created_at.
    """
    items: List[Dict[str, Any]] = []
    for file in DATA_DIR.glob("*.json"):
        try:
            data = _read_json(file)
            if not data:
                continue
            created = data.get("created_at") or data.get("created")
            updated = data.get("updated_at") or created
            meta = data.get("meta", {}) or {}
            items.append(
                {
                    "id": data.get("id"),
                    "created": created,
                    "created_at": created,
                    "updated_at": updated,
                    "persona": meta.get("persona", "General"),
                    "message_count": len(data.get("messages", []) or []),
                }
            )
        except Exception:
            continue

    def _key(d: Dict[str, Any]) -> str:
        return (d.get("updated_at") or d.get("created_at") or "")

    return sorted(items, key=_key, reverse=True)
-e 


-e # ===== FILE: ./core/utils.py =====

"""
ASTRA â€¢ core/utils.py (v2.1.2)
Common utility functions shared across backend modules.
For this version: No LaTeX escaping or text cleaning â€” passes LaTeX as-is.
Author: Sri Akash Kadali
"""

from __future__ import annotations

import re
import html
import hashlib
import json
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional

# ============================================================
# ðŸ“ Logging path (prefer config; safe local fallback if import fails)
# ============================================================
try:
    from backend.core import config as _cfg  # type: ignore
    LOG_PATH = Path(getattr(_cfg, "LOG_PATH"))
except Exception:
    # Dev/test fallback (project-local)
    LOG_PATH = Path("data/logs/events.jsonl")

LOG_PATH.parent.mkdir(parents=True, exist_ok=True)


# ============================================================
# ðŸ—‚ï¸ Filesystem Helpers
# ============================================================
def ensure_dir(p: Path | str) -> None:
    """Create directory (and parents) if it does not exist."""
    Path(p).mkdir(parents=True, exist_ok=True)


# ============================================================
# ðŸ” HASHING UTILITIES
# ============================================================
def sha256_str(data: Optional[str]) -> str:
    """Generate a full SHA256 hash of a string."""
    if data is None:
        data = ""
    return hashlib.sha256(data.encode("utf-8")).hexdigest()


def simple_hash(data: Optional[str], length: int = 8) -> str:
    """Generate a short deterministic hash (used for cache keys or content IDs)."""
    return sha256_str(data or "")[:max(1, int(length))]


# ============================================================
# ðŸ·ï¸ Naming Helpers (no LaTeX escaping)
# ============================================================
def safe_filename(name: Optional[str]) -> str:
    """Convert a string into a safe, cross-platform filename."""
    if not name:
        return "file"
    # keep letters, digits, underscore, dot, dash; replace others with underscore
    name = re.sub(r"[^A-Za-z0-9_.-]", "_", name)
    # Avoid leading/trailing dots or underscores; trim length
    name = name.strip("._") or "file"
    return name[:64]


def slug_part(s: Optional[str]) -> str:
    """
    A permissive slug for path/filename parts:
      - Replace non [A-Za-z0-9_.-] with underscores
      - Keep length generous (no hard trim here; callers can trim if needed)
    """
    s = s or ""
    s = re.sub(r"[^A-Za-z0-9_.-]+", "_", s).strip("._")
    return s or "unnamed"


def build_filenames(company: str, role: str) -> Dict[str, str]:
    """
    Standardized final artifact names:

      â€¢ Optimized resumes:
          "Sri_{Company}_{Role}.pdf"
      â€¢ Humanized resumes:
          "Sri_Kadali_{Company}_{Role}.pdf"
      â€¢ Cover letters:
          "Sri_{Company}_{Role}_Cover_Letter.pdf"
    """
    c = slug_part(company)
    r = slug_part(role)
    return {
        "optimized":    f"Sri_{c}_{r}.pdf",
        "humanized":    f"Sri_Kadali_{c}_{r}.pdf",
        "cover_letter": f"Sri_{c}_{r}_Cover_Letter.pdf",
    }


def build_output_paths(company: str, role: str) -> Dict[str, Path]:
    """
    Convenience helper that returns the *full* Paths for each final artifact,
    using directories from config (if available).

    Returns dict with keys: optimized, humanized, cover_letter
    """
    names = build_filenames(company, role)
    try:
        # Prefer config-provided directories (typically absolute/user-data-safe)
        opt_dir = Path(getattr(_cfg, "OPTIMIZED_DIR"))
        hum_dir = Path(getattr(_cfg, "HUMANIZED_DIR"))
        cov_dir = Path(getattr(_cfg, "COVER_LETTERS_DIR"))
    except Exception:
        # Safe fallbacks â€” project-local relative paths
        opt_dir = Path("data/Optimized")
        hum_dir = Path("data/Humanized")
        cov_dir = Path("data/Cover Letters")

    # Ensure the directories exist
    for d in (opt_dir, hum_dir, cov_dir):
        d.mkdir(parents=True, exist_ok=True)

    return {
        "optimized": (opt_dir / names["optimized"]).resolve(),
        "humanized": (hum_dir / names["humanized"]).resolve(),
        "cover_letter": (cov_dir / names["cover_letter"]).resolve(),
    }


# ============================================================
# ðŸ“œ TEXT HELPERS (NO LATEX ESCAPING)
# ============================================================
def tex_escape(text: Optional[str]) -> str:
    """
    Passthrough for LaTeX text (no escaping).
    Used when sending LaTeX to or receiving from OpenAI/Humanize.
    """
    return text or ""


def html_escape(text: Optional[str]) -> str:
    """HTML-escape text for safe display inside web UIs (not LaTeX)."""
    return html.escape(text or "")


def clean_text(text: Optional[str]) -> str:
    """
    Lightweight text cleaner (no normalization, no space compression).
    Keeps LaTeX intact.
    """
    if not text:
        return ""
    return str(text)


# ============================================================
# ðŸ§  LOGGING & DIAGNOSTIC HELPERS
# ============================================================
def utc_now_iso() -> str:
    """Return current UTC timestamp in ISO-8601 format."""
    return datetime.utcnow().isoformat() + "Z"


def log_event(event: str, meta: Optional[Dict[str, Any]] = None) -> None:
    """
    Append a JSON line to the global event log and print to console.
    Used by all backend modules for analytics and dashboard.

    Accepts:
      â€¢ event: short event string
      â€¢ meta : optional dict payload (anything JSON-serializable; non-serializable values coerced to str)
    """
    record = {
        "timestamp": utc_now_iso(),
        "event": str(event),
        "meta": meta or {},
    }

    # Console log (truncate very large metas for readability)
    try:
        preview = json.dumps(record["meta"], ensure_ascii=False, default=str)
        if len(preview) > 800:
            preview = preview[:800] + "â€¦"
        print(f"[{record['timestamp']}] {record['event']} :: {preview}")
    except Exception:
        print(f"[{record['timestamp']}] {record['event']} :: (unserializable meta)")

    # Persistent log (append JSONL)
    try:
        LOG_PATH.parent.mkdir(parents=True, exist_ok=True)
        with open(LOG_PATH, "a", encoding="utf-8") as f:
            f.write(json.dumps(record, ensure_ascii=False, default=str) + "\n")
    except Exception as e:
        print(f"[ASTRA] âš ï¸ Failed to write event log: {e}")


def benchmark(name: str):
    """
    Context manager for timing code blocks.

    Example:
        with benchmark("Optimize Resume"):
            run_some_code()
    """
    import time

    class _Timer:
        def __enter__(self):
            self._start = time.time()
            return self

        def __exit__(self, exc_type, exc_val, exc_tb):
            duration_ms = (time.time() - self._start) * 1000.0
            log_event("â±ï¸ benchmark", {"name": name, "duration_ms": round(duration_ms, 1)})

    return _Timer()


# ============================================================
# ðŸ§ª Local Test (generic for any companies/roles)
# ============================================================
if __name__ == "__main__":
    import sys

    # 1) Quick LaTeX + hash sanity check
    sample = r"""
    \documentclass{article}
    \begin{document}
    Hello \textbf{World!} $E = mc^2$
    \end{document}
    """
    print("Original LaTeX (unchanged):")
    print(sample)
    print("SHA256:", sha256_str(sample))
    print("Short Hash:", simple_hash(sample))
    print("Safe File:", safe_filename("My Resume (final).tex"))

    # 2) Filename + output path checks (accept multiple pairs from stdin or argv)
    pairs: list[tuple[str, str]] = []

    # Read JSONL from stdin: each line like {"company":"...", "role":"..."}
    if sys.stdin and not sys.stdin.isatty():
        for line in sys.stdin:
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
                pairs.append((str(obj["company"]), str(obj["role"])))
            except Exception:
                # Ignore malformed lines
                pass

    # Or accept args as JSON or "Company:Role"
    if not pairs and len(sys.argv) > 1:
        for a in sys.argv[1:]:
            a = a.strip()
            if not a:
                continue
            try:
                obj = json.loads(a)
                pairs.append((str(obj["company"]), str(obj["role"])))
                continue
            except Exception:
                pass
            if ":" in a:
                c, r = a.split(":", 1)
                pairs.append((c.strip(), r.strip()))

    # Fallback instructional example if nothing was provided
    if not pairs:
        print("\nUsage:")
        print("  â€¢ cat jobs.jsonl | python -m backend.core.utils")
        print('  â€¢ python -m backend.core.utils "Company:Role" ...')
        print('  â€¢ python -m backend.core.utils \'{"company":"X","role":"Y"}\' ...')
        pairs = [("ExampleCo", "ExampleRole")]

    # Verify the filename scheme + full paths for each pair
    for company, role in pairs:
        names = build_filenames(company, role)
        paths = build_output_paths(company, role)
        print(f"\n[{company} â€¢ {role}]")
        print(" Names :", names)
        print(" Paths :", {k: str(v) for k, v in paths.items()})

    # 3) Micro-benchmark
    with benchmark("Hash Generation"):
        for _ in range(10000):
            sha256_str(sample)
-e 


-e # ===== FILE: ./tests/test_optimize.py =====

"""
HIREX â€¢ tests/test_optimize.py
Minimal end-to-end tests for API + static frontend.
Run:  pytest -q
Author: Sri Akash Kadali
"""

from io import BytesIO
from pathlib import Path
from fastapi.testclient import TestClient
from backend.main import app

client = TestClient(app)


# ============================================================
# ðŸ”§ Sample Minimal LaTeX Resume
# ============================================================

def _sample_tex() -> str:
    """Returns a minimal valid LaTeX resume for test upload."""
    return r"""
\documentclass[letterpaper,10pt]{article}
\usepackage[margin=0.6in]{geometry}
\begin{document}
\section{Education}
\begin{itemize}
\item B.S. in Computer Science, XYZ University
\end{itemize}

\section{Skills}
Languages: Python, SQL
Cloud: AWS, Docker

\section{Experience}
\textbf{Acme Corp} \hfill \textit{Software Intern} \hfill 2024
\begin{itemize}
\item worked on python data pipelines
\item helped with docker deployment
\end{itemize}
\end{document}
""".strip()


# ============================================================
# ðŸ§  API Health & Frontend Tests
# ============================================================

def test_health_endpoint():
    """Ensure /health endpoint is alive and reports version."""
    r = client.get("/health")
    assert r.status_code == 200, f"Health failed: {r.text}"
    data = r.json()
    assert data.get("status") == "ok"
    assert "version" in data


def test_frontend_index_served():
    """Ensure root / serves the frontend HTML file."""
    r = client.get("/")
    assert r.status_code == 200, f"Frontend index not served: {r.text}"
    assert "text/html" in r.headers.get("content-type", "")


# ============================================================
# ðŸš€ /api/optimize End-to-End Tests
# ============================================================

def test_optimize_endpoint_happy_path(tmp_path: Path):
    """
    Verify that /api/optimize processes a sample resume and JD text
    end-to-end through OpenAI + Humanize pipeline.
    """
    tex_bytes = _sample_tex().encode("utf-8")
    files = {"base_resume_tex": ("resume.tex", BytesIO(tex_bytes), "text/plain")}
    data = {"jd_text": "We need Python, AWS, FastAPI. Seniority: SWE I or Senior."}

    r = client.post("/api/optimize", files=files, data=data)
    assert r.status_code == 200, f"Unexpected response: {r.text}"
    payload = r.json()

    # Check essential keys in response
    for key in ("tex_string", "jd_summary", "coverage", "pdf_base64"):
        assert key in payload, f"Missing key in response: {key}"

    # Validate JD summary structure
    jd = payload["jd_summary"]
    for key in ("must_haves", "skills", "metrics", "seniority"):
        assert key in jd, f"Missing JD key: {key}"

    # Ensure coverage includes at least Python (case-insensitive)
    items = {c["item"].lower() for c in payload["coverage"]}
    assert "python" in items, f"Coverage missing Python: {items}"

    # PDF presence check
    pdf_b64 = payload.get("pdf_base64")
    assert isinstance(pdf_b64, (str, type(None)))
    if pdf_b64:
        assert len(pdf_b64) > 50, "Encoded PDF too small (possibly truncated)."


def test_optimize_endpoint_missing_fields():
    """Missing JD text should result in a validation or bad request error."""
    tex_bytes = _sample_tex().encode("utf-8")
    files = {"base_resume_tex": ("resume.tex", BytesIO(tex_bytes), "text/plain")}
    r = client.post("/api/optimize", files=files, data={})
    assert r.status_code in (400, 422), f"Expected validation failure, got {r.status_code}"


def test_optimize_endpoint_invalid_file():
    """Invalid extension or empty content should not crash the API."""
    files = {"base_resume_tex": ("resume.txt", BytesIO(b""), "text/plain")}
    r = client.post("/api/optimize", files=files, data={"jd_text": "Python"})
    assert r.status_code in (400, 500), f"Unexpected status: {r.status_code}"
-e 


-e # ===== FILE: ./api/optimize.py =====

"""
Resume optimizer API (FastAPI) â€” ENHANCED VERSION with SKILL VALIDATION & SELECTIVE QUANTIFICATION

IMPROVEMENTS:
- GPT-based skill validation (removes PhD, MS, random words)
- Selective quantification: 3 heroic numbers across experience (1 per block)
- Realistic messy numbers ending in odd digits
- âœ¨ NEW: UNIQUE NUMBER TRACKING - never repeats same number
- âœ¨ NEW: STRICTER SKILL VALIDATION - filters ISO standards, certifications
- Action verb diversity tracking (no repetition)
- Result phrases without numbers
- Technical depth indicators
- Skill progression across experience blocks
- Believability constraints for intern-level
- Bullet structure templates
- Cross-bullet coherence
- Industry-specific vocabulary
- Enhanced company context with progression
"""

import base64
import json
import re
import asyncio
import threading
import random
from pathlib import Path
from typing import List, Tuple, Dict, Iterable, Optional, Set, Any

# --- third-party ---
from fastapi import APIRouter, UploadFile, Form, File, HTTPException
from fastapi.responses import JSONResponse

from backend.core import config
from backend.core.compiler import compile_latex_safely
from backend.core.security import secure_tex_input
from backend.core.utils import log_event, safe_filename, build_output_paths
from backend.api.render_tex import render_final_tex

router = APIRouter(prefix="/api/optimize", tags=["optimize"])

# --- OpenAI ---
try:
    from openai import OpenAI
except Exception:
    OpenAI = None

_openai_client: Optional["OpenAI"] = None
_openai_lock = threading.Lock()


def get_openai_client() -> "OpenAI":
    global _openai_client
    if OpenAI is None:
        raise RuntimeError("OpenAI SDK not available.")
    if _openai_client is None:
        with _openai_lock:
            if _openai_client is None:
                _openai_client = OpenAI(api_key=getattr(config, "OPENAI_API_KEY", ""))
    return _openai_client


# ============================================================
# ðŸŽ² REALISTIC NUMBER GENERATION WITH UNIQUE TRACKING
# ============================================================

# âœ¨ UPGRADED: Track numbers by category for diversity
_used_numbers_by_category: Dict[str, Set[str]] = {
    "percent": set(),
    "count": set(),
    "metric": set(),
    "comparison": set()
}
_quantified_bullet_positions: Set[int] = set()  # Track which bullet positions have numbers


def reset_number_tracking():
    """Reset number tracking for new resume."""
    global _used_numbers_by_category, _quantified_bullet_positions
    _used_numbers_by_category = {
        "percent": set(),
        "count": set(),
        "metric": set(),
        "comparison": set()
    }
    _quantified_bullet_positions.clear()


def generate_messy_decimal(min_val: float, max_val: float, decimal_places: int = 2) -> float:
    """Generate a messy decimal number ending in odd digit."""
    for _ in range(50):
        num = random.uniform(min_val, max_val)
        rounded = round(num, decimal_places)
        
        # Ensure last digit is odd
        if decimal_places == 2:
            last_digit = int((rounded * 100) % 10)
        elif decimal_places == 1:
            last_digit = int((rounded * 10) % 10)
        else:
            last_digit = int(rounded % 10)
        
        if last_digit % 2 != 0:
            return rounded
    
    return round(min_val, decimal_places)


def generate_messy_number(category: str, jd_context: str = "") -> str:
    """
    Generate realistic, unique numbers by category.
    Each category has different value ranges and formats.
    âœ¨ UPGRADED: Wide range, no repetition, odd endings
    """
    global _used_numbers_by_category
    
    for attempt in range(100):
        formatted = ""
        
        if category == "percent":
            # Wide range: 7-89%
            if "accuracy" in jd_context.lower() or "precision" in jd_context.lower():
                base = random.randint(11, 29)  # 11-29% improvement
            else:
                base = random.randint(7, 89)
            
            # Make it messy with decimals
            if random.random() < 0.6:  # 60% chance of decimal
                decimal = generate_messy_decimal(base, base + 0.99, 2)
                formatted = f"{decimal}%"
            else:
                # Ensure odd
                if base % 2 == 0:
                    base += 1
                formatted = f"{base}%"
        
        elif category == "count":
            # Large counts: 1,234 or 12K+
            base = random.choice([
                random.randint(567, 9999),
                random.randint(10000, 99999)
            ])
            
            # Ensure odd
            if base % 2 == 0:
                base += 1
            
            if base >= 10000:
                formatted = f"{base//1000}K+"
            elif base >= 1000:
                formatted = f"{base:,}"
            else:
                formatted = str(base)
        
        elif category == "metric":
            # F1/Precision/Recall: 0.73-0.97
            metric_name = random.choice(["F1 score", "precision", "recall", "accuracy"])
            value = generate_messy_decimal(0.73, 0.97, 2)
            formatted = f"{metric_name} of {value}"
        
        elif category == "comparison":
            # Hero point: from X to Y (improvement)
            if "accuracy" in jd_context.lower():
                start = random.randint(51, 67)
                improvement = random.randint(17, 33)
            else:
                start = random.randint(41, 79)
                improvement = random.randint(11, 29)
            
            # Ensure both odd
            if start % 2 == 0:
                start += 1
            if improvement % 2 == 0:
                improvement += 1
            
            end = min(99, start + improvement)
            if end % 2 == 0:
                end -= 1
            
            formatted = f"from {start}% to {end}%"
        
        # Check uniqueness
        if formatted and formatted not in _used_numbers_by_category[category]:
            _used_numbers_by_category[category].add(formatted)
            log_event(f"ðŸŽ² [NUMBER-{category.upper()}] Generated: {formatted}")
            return formatted
    
    # Fallback
    fallback = f"{random.randint(13, 87)}%"
    _used_numbers_by_category[category].add(fallback)
    return fallback

QUANTIFICATION_TEMPLATES = {
    "percent_improvement": [
        "improving {metric} by {value}",
        "achieving {value} enhancement in {metric}",
        "boosting {metric} performance by {value}",
        "elevating {metric} through {value} improvement",
    ],
    "count_scale": [
        "processing {value} data samples daily",
        "analyzing {value} records for pattern detection",
        "handling {value} concurrent model predictions",
        "evaluating {value} feature combinations systematically",
    ],
    "metric_achievement": [
        "attaining {value} on validation datasets",
        "reaching {value} across diverse test scenarios",
        "delivering {value} in production deployment",
        "securing {value} during rigorous evaluation",
    ],
    "comparison_hero": [
        "improving model accuracy {value} through systematic hyperparameter optimization",
        "enhancing prediction reliability {value} via ensemble methodology",
        "accelerating inference speed {value} using optimized architecture",
        "increasing system throughput {value} with distributed processing",
    ],
}


def generate_quantified_phrase(category: str, jd_context: str = "") -> str:
    """
    Generate a realistic quantified phrase with category-specific numbers.
    âœ¨ UPGRADED: Each category gets different number types
    """
    templates = QUANTIFICATION_TEMPLATES.get(category, QUANTIFICATION_TEMPLATES["percent_improvement"])
    template = random.choice(templates)
    
    if category == "percent_improvement":
        metric = random.choice(["accuracy", "precision", "throughput", "efficiency"])
        value = generate_messy_number("percent", jd_context)
        return template.format(metric=metric, value=value)
    
    elif category == "count_scale":
        value = generate_messy_number("count", jd_context)
        return template.format(value=value)
    
    elif category == "metric_achievement":
        value = generate_messy_number("metric", jd_context)
        return template.format(value=value)
    
    elif category == "comparison_hero":
        value = generate_messy_number("comparison", jd_context)
        return template.format(value=value)
    
    return template

# Track quantification: bullet positions (absolute index 0-11) that get numbers
QUANTIFIED_POSITIONS = [1, 5, 6, 9]  # Positions 2, 6, 7, 10 (0-indexed)
HERO_POSITIONS = [1, 5]  # Positions 2 and 6 are hero points


def reset_quantification_tracking():
    """Reset quantification tracking for new resume."""
    reset_number_tracking()


def get_quantification_category(bullet_position: int, jd_context: str = "") -> Optional[str]:
    """
    Determine which quantification category to use for this bullet position.
    Returns None if this position shouldn't be quantified.
    âœ¨ NEW: Maps positions to categories for diversity
    """
    if bullet_position not in QUANTIFIED_POSITIONS:
        return None
    
    # Map positions to categories (4 different types)
    category_map = {
        1: "comparison_hero",    # Position 2: Hero point with comparison
        5: "comparison_hero",    # Position 6: Hero point with comparison
        6: "count_scale",        # Position 7: Count-based
        9: "metric_achievement"  # Position 10: Metric (F1/precision/recall)
    }
    
    # Position 1 might use percent if JD doesn't emphasize comparison
    if bullet_position == 1 and "accuracy" not in jd_context.lower():
        return "percent_improvement"
    
    return category_map.get(bullet_position, None)


def should_quantify_bullet(bullet_position: int) -> bool:
    """Check if this bullet position (0-11) should have a number."""
    return bullet_position in QUANTIFIED_POSITIONS

# ============================================================
# ðŸ’ª ACTION VERB MANAGEMENT - NO REPETITION ACROSS ALL 12 BULLETS
# ============================================================

ACTION_VERBS = {
    "development": [
        "Architected", "Engineered", "Developed", "Built", "Implemented",
        "Constructed", "Designed", "Created", "Established", "Formulated",
        "Programmed", "Prototyped", "Assembled"
    ],
    "research": [
        "Investigated", "Explored", "Analyzed", "Evaluated", "Validated",
        "Examined", "Studied", "Researched", "Assessed", "Characterized",
        "Scrutinized", "Probed"
    ],
    "optimization": [
        "Optimized", "Enhanced", "Streamlined", "Accelerated", "Refined",
        "Improved", "Strengthened", "Advanced", "Elevated", "Augmented",
        "Amplified", "Intensified"
    ],
    "data_work": [
        "Processed", "Transformed", "Aggregated", "Curated", "Cleaned",
        "Structured", "Organized", "Consolidated", "Standardized", "Normalized",
        "Synthesized", "Compiled"
    ],
    "ml_training": [
        "Trained", "Fine-tuned", "Calibrated", "Tuned", "Configured",
        "Parameterized", "Adapted", "Specialized", "Customized", "Fitted",
        "Conditioned", "Adjusted"
    ],
    "deployment": [
        "Deployed", "Launched", "Released", "Shipped", "Delivered",
        "Productionized", "Operationalized", "Integrated", "Provisioned", "Staged",
        "Rolled-out", "Instituted"
    ],
    "analysis": [
        "Analyzed", "Diagnosed", "Identified", "Discovered", "Uncovered",
        "Detected", "Recognized", "Profiled", "Mapped", "Quantified",
        "Interpreted", "Dissected"
    ],
    "collaboration": [
        "Collaborated", "Partnered", "Coordinated", "Facilitated", "Supported",
        "Contributed", "Assisted", "Engaged", "Interfaced", "Liaised",
        "Cooperated", "Unified"
    ],
    "automation": [
        "Automated", "Systematized", "Scripted", "Programmed", "Orchestrated",
        "Scheduled", "Templated", "Codified", "Mechanized", "Streamlined",
        "Roboticized", "Computerized"
    ],
    "documentation": [
        "Documented", "Recorded", "Cataloged", "Annotated", "Detailed",
        "Specified", "Outlined", "Summarized", "Reported", "Communicated",
        "Chronicled", "Transcribed"
    ]
}

# âœ¨ UPGRADED: Global tracking to ensure NO verb repetition across all 12 bullets
_used_verbs_global: Set[str] = set()


def reset_verb_tracking():
    """Reset verb tracking for new resume optimization."""
    global _used_verbs_global
    _used_verbs_global.clear()


def get_diverse_verb(category: str, fallback: str = "Developed") -> str:
    """
    Get a verb that hasn't been used anywhere in the resume.
    âœ¨ UPGRADED: True global uniqueness across all 12 bullets
    """
    global _used_verbs_global
    
    verbs = ACTION_VERBS.get(category, ACTION_VERBS["development"])
    available = [v for v in verbs if v.lower() not in _used_verbs_global]
    
    if not available:
        # Try all categories
        all_verbs = [v for cat in ACTION_VERBS.values() for v in cat]
        available = [v for v in all_verbs if v.lower() not in _used_verbs_global]
    
    if not available:
        # Last resort: use fallback with suffix
        chosen = f"{fallback}"
    else:
        chosen = random.choice(available)
    
    _used_verbs_global.add(chosen.lower())
    log_event(f"âœ… [VERB] Selected: {chosen} (Total used: {len(_used_verbs_global)}/12)")
    return chosen


def get_verb_categories_for_context(company_type: str) -> List[str]:
    """Get appropriate verb categories based on company type."""
    if "research" in company_type.lower():
        return ["research", "analysis", "development", "documentation"]
    elif "industry" in company_type.lower():
        return ["development", "deployment", "optimization", "automation"]
    else:
        return ["development", "analysis", "collaboration", "data_work"]

# ============================================================
# ðŸŽ¯ RESULT PHRASES (Impact without numbers)
# ============================================================

RESULT_PHRASES = {
    "performance": [
        "achieving enhanced model generalization across diverse datasets",
        "resulting in improved prediction accuracy on held-out test data",
        "enabling robust performance under varying input conditions",
        "delivering production-grade model reliability and consistency",
        "attaining competitive benchmark results against established baselines"
    ],
    "efficiency": [
        "enabling faster experimentation and iteration cycles",
        "streamlining the end-to-end development workflow significantly",
        "reducing computational overhead while maintaining output quality",
        "accelerating model training and evaluation throughput",
        "improving overall resource utilization and pipeline efficiency"
    ],
    "quality": [
        "ensuring high-quality and reproducible model outputs",
        "maintaining rigorous quality standards throughout development",
        "achieving consistent and reliable experimental results",
        "delivering enterprise-grade code quality and documentation",
        "meeting stringent production readiness requirements"
    ],
    "scalability": [
        "supporting seamless scaling to larger datasets",
        "enabling distributed processing capabilities for production workloads",
        "facilitating efficient handling of increased data volumes",
        "ensuring system robustness under production-scale demands",
        "accommodating future growth and extensibility requirements"
    ],
    "insight": [
        "uncovering actionable insights from complex data patterns",
        "revealing previously hidden correlations and trends",
        "generating valuable intelligence for downstream applications",
        "providing data-driven recommendations for model improvements",
        "enabling informed decision-making through rigorous analysis"
    ],
    "collaboration": [
        "facilitating cross-functional collaboration and knowledge sharing",
        "enabling seamless integration with existing team workflows",
        "supporting reproducibility and handoff to other team members",
        "improving documentation and codebase maintainability",
        "establishing reusable components for future projects"
    ]
}

_used_result_phrases: Set[str] = set()


def reset_result_phrase_tracking():
    """Reset result phrase tracking."""
    global _used_result_phrases
    _used_result_phrases.clear()


def get_result_phrase(category: str) -> str:
    """Get a result phrase that hasn't been used."""
    global _used_result_phrases
    
    phrases = RESULT_PHRASES.get(category, RESULT_PHRASES["performance"])
    available = [p for p in phrases if p not in _used_result_phrases]
    
    if not available:
        _used_result_phrases.clear()
        available = phrases
    
    chosen = random.choice(available)
    _used_result_phrases.add(chosen)
    return chosen


# ============================================================
# ðŸ”¬ TECHNICAL DEPTH INDICATORS
# ============================================================

TECHNICAL_DEPTH_PHRASES = {
    "ml_techniques": [
        "employing stratified Cross-Validation for robust evaluation",
        "utilizing Grid Search and Bayesian optimization for Hyperparameter Tuning",
        "applying advanced Feature Engineering with domain-specific transformations",
        "implementing custom Data Augmentation strategies for improved generalization",
        "leveraging Ensemble Methods to combine multiple model predictions",
        "conducting systematic Ablation Studies to validate design choices"
    ],
    "dl_techniques": [
        "incorporating Batch Normalization and Dropout for regularization",
        "implementing Learning Rate Scheduling with warm restarts",
        "utilizing Gradient Clipping to stabilize training dynamics",
        "applying Transfer Learning with frozen backbone and fine-tuned heads",
        "employing Attention Mechanisms for improved feature representation",
        "implementing residual connections for gradient flow optimization"
    ],
    "data_techniques": [
        "implementing comprehensive Data Preprocessing pipelines with validation",
        "applying Dimensionality Reduction for efficient feature representation",
        "utilizing robust Outlier Detection and handling strategies",
        "implementing Missing Value Imputation with multiple strategies",
        "applying class balancing techniques for imbalanced datasets",
        "conducting thorough Exploratory Data Analysis for insight generation"
    ],
    "mlops_techniques": [
        "implementing Model Versioning with comprehensive experiment tracking",
        "establishing CI/CD pipelines for automated model validation",
        "utilizing containerization with Docker for reproducible deployments",
        "implementing Feature Store patterns for consistent feature serving",
        "establishing Model Monitoring dashboards for production oversight",
        "applying infrastructure-as-code practices for environment management"
    ],
    "evaluation_techniques": [
        "conducting Precision-Recall analysis for classification performance",
        "implementing comprehensive error analysis and failure mode identification",
        "utilizing statistical significance testing for model comparisons",
        "applying Confusion Matrix analysis for multi-class evaluation",
        "implementing custom evaluation metrics aligned with business objectives",
        "conducting systematic bias and fairness audits"
    ]
}


def get_technical_depth_phrase(category: str) -> str:
    """Get a technical depth phrase for credibility."""
    phrases = TECHNICAL_DEPTH_PHRASES.get(category, TECHNICAL_DEPTH_PHRASES["ml_techniques"])
    return random.choice(phrases)


# ============================================================
# ðŸ“ˆ SKILL PROGRESSION FRAMEWORK
# ============================================================

INTERN_PROGRESSION = {
    "early": {
        "scope": ["assisted", "supported", "contributed to", "participated in"],
        "tasks": ["data preprocessing", "baseline implementation", "literature review", "code documentation"],
        "autonomy": "under guidance of senior engineers",
        "complexity": "foundational components"
    },
    "mid": {
        "scope": ["developed", "implemented", "designed", "built"],
        "tasks": ["model development", "pipeline creation", "experiment execution", "performance analysis"],
        "autonomy": "with mentorship from team leads",
        "complexity": "core system components"
    },
    "late": {
        "scope": ["led", "architected", "spearheaded", "owned"],
        "tasks": ["end-to-end pipeline", "model optimization", "deployment preparation", "technical documentation"],
        "autonomy": "independently with periodic reviews",
        "complexity": "production-ready solutions"
    }
}


def get_progression_context(block_index: int, total_blocks: int = 4) -> Dict[str, Any]:
    """Get appropriate progression context based on position in experience."""
    if block_index == 0:
        return INTERN_PROGRESSION["late"]  # Most recent = most advanced
    elif block_index == total_blocks - 1:
        return INTERN_PROGRESSION["early"]  # Oldest = most basic
    else:
        return INTERN_PROGRESSION["mid"]


# ============================================================
# ðŸ­ BELIEVABILITY CONSTRAINTS
# ============================================================

BELIEVABILITY_RULES = {
    "intern_appropriate": [
        "Focus on learning, contribution, and growth",
        "Avoid claiming sole ownership of major systems",
        "Use collaborative language when appropriate",
        "Mention working with senior engineers or mentors",
        "Focus on specific components rather than entire systems"
    ],
    "scope_indicators": {
        "small": ["component", "module", "feature", "function", "utility"],
        "medium": ["pipeline", "workflow", "system", "service", "framework"],
        "large": ["platform", "infrastructure", "architecture", "ecosystem"]
    },
    "collaboration_phrases": [
        "in collaboration with senior engineers",
        "as part of a cross-functional team",
        "working closely with research mentors",
        "under guidance of technical leads",
        "contributing to team-wide initiatives"
    ]
}


def get_believability_phrase(scope: str = "medium") -> str:
    """Get a believability-enhancing phrase."""
    if random.random() < 0.3:  # 30% chance to add collaboration context
        return random.choice(BELIEVABILITY_RULES["collaboration_phrases"])
    return ""


# ============================================================
# ðŸ“ BULLET STRUCTURE TEMPLATES
# ============================================================

BULLET_TEMPLATES = {
    "action_object_method_result": "{verb} {object} using {method}, {result}",
    "action_method_object_result": "{verb} {method}-based {object}, {result}",
    "action_object_result_method": "{verb} {object} {result} through {method}",
    "collaborative_action": "{verb} {object} in collaboration with {team}, {result}",
}


def get_bullet_template() -> str:
    """Get a random bullet template for variety."""
    templates = list(BULLET_TEMPLATES.values())
    return random.choice(templates)


# ============================================================
# ðŸ”  PROPER CAPITALIZATION MAP
# ============================================================

CAPITALIZATION_MAP: Dict[str, str] = {
    # Programming Languages
    "python": "Python", "java": "Java", "javascript": "JavaScript", "typescript": "TypeScript",
    "c++": "C++", "c#": "C#", "go": "Go", "rust": "Rust", "scala": "Scala", "kotlin": "Kotlin",
    "swift": "Swift", "ruby": "Ruby", "php": "PHP", "r": "R", "matlab": "MATLAB", "sql": "SQL",
    "bash": "Bash", "shell": "Shell", "perl": "Perl", "lua": "Lua", "julia": "Julia",

    # ML/AI Frameworks
    "pytorch": "PyTorch", "tensorflow": "TensorFlow", "keras": "Keras", "scikit-learn": "Scikit-learn",
    "sklearn": "Scikit-learn", "pandas": "Pandas", "numpy": "NumPy", "scipy": "SciPy",
    "matplotlib": "Matplotlib", "seaborn": "Seaborn", "plotly": "Plotly", "opencv": "OpenCV",
    "hugging face": "Hugging Face", "huggingface": "Hugging Face", "transformers": "Transformers",
    "xgboost": "XGBoost", "lightgbm": "LightGBM", "catboost": "CatBoost",
    "spacy": "SpaCy", "nltk": "NLTK", "gensim": "Gensim", "fastai": "FastAI", 
    "jax": "JAX", "flax": "Flax",

    # Cloud & DevOps
    "aws": "AWS", "gcp": "GCP", "azure": "Azure", "docker": "Docker", "kubernetes": "Kubernetes",
    "k8s": "K8s", "jenkins": "Jenkins", "terraform": "Terraform", "ansible": "Ansible",
    "circleci": "CircleCI", "github actions": "GitHub Actions", "gitlab": "GitLab",
    "ec2": "EC2", "s3": "S3", "lambda": "Lambda", "sagemaker": "SageMaker", "emr": "EMR",
    "bigquery": "BigQuery", "redshift": "Redshift", "snowflake": "Snowflake",

    # Databases
    "mysql": "MySQL", "postgresql": "PostgreSQL", "postgres": "PostgreSQL", "mongodb": "MongoDB",
    "redis": "Redis", "elasticsearch": "Elasticsearch", "cassandra": "Cassandra",
    "dynamodb": "DynamoDB", "sqlite": "SQLite", "oracle": "Oracle", "neo4j": "Neo4j",

    # Tools & Platforms
    "git": "Git", "github": "GitHub", "linux": "Linux", "unix": "Unix", "windows": "Windows",
    "jupyter": "Jupyter", "vscode": "VS Code", "intellij": "IntelliJ", "vim": "Vim",
    "mlflow": "MLflow", "wandb": "W&B", "weights & biases": "Weights & Biases",
    "airflow": "Airflow", "kafka": "Kafka", "spark": "Spark", "hadoop": "Hadoop",
    "databricks": "Databricks", "dbt": "Dbt", "prefect": "Prefect", "dagster": "Dagster",
    "grafana": "Grafana", "prometheus": "Prometheus", "datadog": "Datadog",

    # Web Frameworks
    "flask": "Flask", "django": "Django", "fastapi": "FastAPI", "express": "Express",
    "react": "React", "angular": "Angular", "vue": "Vue", "nextjs": "Next.js", "next.js": "Next.js",
    "nodejs": "Node.js", "node.js": "Node.js", "spring": "Spring", "rails": "Rails",

    # ML/AI Concepts
    "ml": "ML", "ai": "AI", "dl": "DL", "nlp": "NLP", "cv": "CV", "rl": "RL",
    "machine learning": "Machine Learning", "deep learning": "Deep Learning",
    "natural language processing": "Natural Language Processing",
    "computer vision": "Computer Vision", "reinforcement learning": "Reinforcement Learning",
    "neural network": "Neural Network", "neural networks": "Neural Networks",
    "cnn": "CNN", "rnn": "RNN", "lstm": "LSTM", "gru": "GRU", "gan": "GAN", "vae": "VAE",
    "bert": "BERT", "gpt": "GPT", "llm": "LLM", "llms": "LLMs",
    "transformer": "Transformer", "transformers": "Transformers",
    "attention mechanism": "Attention Mechanism", "self-attention": "Self-Attention",
    "fine-tuning": "Fine-Tuning", "transfer learning": "Transfer Learning",
    "feature engineering": "Feature Engineering", "hyperparameter tuning": "Hyperparameter Tuning",
    "cross-validation": "Cross-Validation", "gradient descent": "Gradient Descent",
    "backpropagation": "Backpropagation", "batch normalization": "Batch Normalization",
    "dropout": "Dropout", "regularization": "Regularization",
    "supervised learning": "Supervised Learning", "unsupervised learning": "Unsupervised Learning",
    "semi-supervised learning": "Semi-Supervised Learning",
    "classification": "Classification", "regression": "Regression", "clustering": "Clustering",
    "dimensionality reduction": "Dimensionality Reduction", "pca": "PCA", "t-sne": "T-SNE",
    "random forest": "Random Forest", "decision tree": "Decision Tree",
    "support vector machine": "Support Vector Machine", "svm": "SVM",
    "k-nearest neighbors": "K-Nearest Neighbors", "knn": "KNN",
    "naive bayes": "Naive Bayes", "logistic regression": "Logistic Regression",
    "linear regression": "Linear Regression", "gradient boosting": "Gradient Boosting",
    "ensemble methods": "Ensemble Methods", "bagging": "Bagging", "boosting": "Boosting",
    "automl": "AutoML", "mlops": "MLOps", "devops": "DevOps", "ci/cd": "CI/CD",
    "etl": "ETL", "elt": "ELT", "api": "API", "rest": "REST", "graphql": "GraphQL",
    "microservices": "Microservices", "serverless": "Serverless",
    "rag": "RAG", "retrieval-augmented generation": "Retrieval-Augmented Generation",
    "vector database": "Vector Database", "embedding": "Embedding", "embeddings": "Embeddings",
    "prompt engineering": "Prompt Engineering", "langchain": "LangChain",
    "llamaindex": "LlamaIndex", "openai": "OpenAI", "anthropic": "Anthropic",
    "chatgpt": "ChatGPT", "claude": "Claude", "gemini": "Gemini",

    # Data Science
    "data science": "Data Science", "data engineering": "Data Engineering",
    "data analysis": "Data Analysis", "data visualization": "Data Visualization",
    "data pipeline": "Data Pipeline", "data warehouse": "Data Warehouse",
    "data lake": "Data Lake", "data mining": "Data Mining",
    "big data": "Big Data", "analytics": "Analytics",
    "business intelligence": "Business Intelligence", "bi": "BI",
    "a/b testing": "A/B Testing", "ab testing": "A/B Testing", "a-b testing": "A/B Testing",
    "statistical analysis": "Statistical Analysis", "hypothesis testing": "Hypothesis Testing",

    # Company-core / systems topics
    "recommender systems": "Recommender Systems",
    "recommendation systems": "Recommendation Systems",
    "search & ranking": "Search & Ranking",
    "search and ranking": "Search And Ranking",
    "ranking": "Ranking",
    "experimentation": "Experimentation",
    "online experimentation": "Online Experimentation",
    "offline evaluation": "Offline Evaluation",
    "distributed systems": "Distributed Systems",
    "system design": "System Design",
    "large-scale data": "Large-Scale Data",
    "stream processing": "Stream Processing",
    "batch processing": "Batch Processing",
    "feature store": "Feature Store",
    "data modeling": "Data Modeling",

    # Other
    "agile": "Agile", "scrum": "Scrum", "jira": "Jira", "confluence": "Confluence",
    "slack": "Slack", "notion": "Notion", "trello": "Trello",
    "json": "JSON", "xml": "XML", "yaml": "YAML", "csv": "CSV",
    "html": "HTML", "css": "CSS", "sass": "SASS", "less": "LESS",
    "oauth": "OAuth", "jwt": "JWT", "ssl": "SSL", "tls": "TLS", "https": "HTTPS",
    "tcp": "TCP", "udp": "UDP", "http": "HTTP", "websocket": "WebSocket",
    "gpu": "GPU", "cpu": "CPU", "tpu": "TPU", "cuda": "CUDA", "cudnn": "CuDNN",
    "ios": "iOS", "macos": "MacOS",
}


def fix_capitalization(text: str) -> str:
    """Fix capitalization of technical terms while preserving sentence structure."""
    if not text:
        return text

    result = text
    sorted_terms = sorted(CAPITALIZATION_MAP.keys(), key=len, reverse=True)
    for term in sorted_terms:
        correct = CAPITALIZATION_MAP[term]
        pattern = rf"\b{re.escape(term)}\b"
        result = re.sub(pattern, correct, result, flags=re.IGNORECASE)
    return result


def _ensure_first_letter_capital(s: str) -> str:
    """Force first character to uppercase if it's a lowercase letter."""
    s = (s or "").strip()
    if not s:
        return s
    if s[0].isalpha() and s[0].islower():
        return s[0].upper() + s[1:]
    return s


def fix_skill_capitalization(skill: str) -> str:
    """Fix capitalization for a single skill term + enforce first-letter-capital."""
    skill = (skill or "").strip()
    if not skill:
        return ""

    skill_lower = skill.lower()
    if skill_lower in CAPITALIZATION_MAP:
        return CAPITALIZATION_MAP[skill_lower]

    out = fix_capitalization(skill)
    out = _ensure_first_letter_capital(out)
    return out


# ============================================================
# âœ… SKILL VALIDATION using GPT - UPGRADED WITH STRICTER FILTERING
# ============================================================

_validated_skills_cache: Dict[str, bool] = {}


async def is_valid_skill(keyword: str) -> bool:
    """
    Use GPT to validate if a keyword is actually a technical skill.
    âœ¨ UPGRADED: Now filters ISO standards, NIST frameworks, certifications
    Filters out: PhD, MS, ISO 42001, NIST AI RMF, random words, company names, etc.
    """
    global _validated_skills_cache
    
    keyword_lower = keyword.lower().strip()
    if keyword_lower in _validated_skills_cache:
        return _validated_skills_cache[keyword_lower]
    
    # âœ¨ UPGRADED: Fast reject common non-skills + standards/certifications
    non_skills = {
        # Degrees
        "phd", "ph.d", "ms", "m.s", "msc", "m.sc", "bs", "b.s", "bsc", "b.sc",
        "bachelor", "master", "masters", "degree", "university", "college",
        # Time/Experience
        "experience", "years", "year", "month", "months", "week", "weeks",
        "required", "preferred", "plus", "bonus", "nice to have",
        # Qualifiers
        "strong", "excellent", "good", "proficient", "familiar", "advanced", "basic",
        "knowledge", "understanding", "ability", "skills", "skill",
        # âœ¨ NEW: Standards & Certifications
        "iso", "nist", "gdpr", "hipaa", "sox", "pci", "cmmi", "itil",
        "compliance", "certified", "certification", "framework", "standard",
        # âœ¨ NEW: Specific standards
        "iso 42001", "nist ai rmf", "ai rmf", "rmf",
    }
    
    if keyword_lower in non_skills:
        _validated_skills_cache[keyword_lower] = False
        log_event(f"âŒ [SKILL FAST-REJECT] '{keyword}' â†’ Non-skill")
        return False
    
    # âœ¨ NEW: Check if it matches standard/certification patterns
    if re.match(r"^(iso|nist|pci|gdpr)\s+\d+", keyword_lower):
        _validated_skills_cache[keyword_lower] = False
        log_event(f"âŒ [SKILL PATTERN-REJECT] '{keyword}' â†’ Standard pattern")
        return False
    
    # If it's in our capitalization map, it's valid
    if keyword_lower in CAPITALIZATION_MAP:
        _validated_skills_cache[keyword_lower] = True
        return True
    
    # âœ¨ UPGRADED: Ask GPT with stricter validation prompt
    prompt = f"""Is "{keyword}" a HARD TECHNICAL SKILL or ESSENTIAL SOFT SKILL that belongs on a resume?

**ACCEPT (return true):**
- Programming languages (Python, Java, etc.)
- Frameworks & libraries (PyTorch, React, etc.)
- Tools & platforms (Docker, AWS, Git, etc.)
- Technical concepts (Machine Learning, System Design, etc.)
- Databases & data tools (PostgreSQL, Spark, etc.)
- Essential soft skills ONLY: Leadership, Communication, Problem-Solving, Teamwork

**REJECT (return false):**
- Standards & certifications: ISO 42001, NIST AI RMF, GDPR, HIPAA, SOX, PCI, etc.
- Degrees: PhD, MS, Bachelor's, etc.
- Generic qualifiers: "strong", "excellent", "proficient", etc.
- Time periods: years, months, experience
- Vague terms: "knowledge of", "understanding of"
- Frameworks without tools: "Agile Framework" â†’ NO, "Scrum" â†’ YES
- Company names or proprietary tools
- Job requirements: "required", "preferred", "nice to have"

Return STRICT JSON: {{"is_skill": true}} or {{"is_skill": false}}

Keyword: "{keyword}"
"""
    
    try:
        data = await gpt_json(prompt, temperature=0.0)
        is_skill = data.get("is_skill", False)
        _validated_skills_cache[keyword_lower] = bool(is_skill)
        
        # âœ¨ NEW: Enhanced logging
        status = "âœ…" if is_skill else "âŒ"
        log_event(f"{status} [SKILL GPT] '{keyword}' â†’ {is_skill}")
        
        return bool(is_skill)
    except Exception as e:
        log_event(f"âš ï¸ [SKILL VALIDATION] Failed for '{keyword}': {e}")
        # âœ¨ UPGRADED: Default to rejecting if validation fails (safer)
        _validated_skills_cache[keyword_lower] = False
        return False


async def filter_valid_skills(keywords: List[str]) -> List[str]:
    """
    Filter a list of keywords to only include valid skills.
    âœ¨ UPGRADED: Better logging of filtered items
    """
    if not keywords:
        return []
    
    tasks = [is_valid_skill(kw) for kw in keywords]
    results = await asyncio.gather(*tasks)
    
    valid_skills = [kw for kw, is_valid in zip(keywords, results) if is_valid]
    
    removed = set(keywords) - set(valid_skills)
    if removed:
        removed_sample = list(removed)[:5]
        log_event(f"ðŸ§¹ [SKILL FILTER] Removed {len(removed)} non-skills: {', '.join(removed_sample)}")
    
    return valid_skills


# ============================================================
# ðŸ¢ ENHANCED Company Context with Progression & Vocabulary
# ============================================================

COMPANY_CONTEXTS = {
    "ayar labs": {
        "type": "industry_internship",
        "domain": "ML/AI in Semiconductor Industry",
        "context": "Silicon photonics company where ML/AI is applied across semiconductor workflow for yield prediction, process optimization, and quality assurance.",
        "technical_vocabulary": [
            "yield prediction", "process optimization", "wafer inspection",
            "defect classification", "signal integrity", "test data analysis",
            "equipment health monitoring", "production forecasting", "quality metrics"
        ],
        "ml_projects": [
            "ML-based yield prediction using manufacturing sensor data and process parameters",
            "Predictive maintenance system for semiconductor fabrication equipment health",
            "Automated defect classification pipeline for wafer inspection quality control",
            "Time-series forecasting model for production capacity planning optimization",
            "Feature engineering framework for high-dimensional semiconductor test data"
        ],
        "believable_tasks": [
            "Data Preprocessing", "Feature Engineering", "Model Training", "Hyperparameter Tuning",
            "Cross-Validation", "Model Evaluation", "Pipeline Development", "Data Visualization",
            "Statistical Analysis", "Experiment Tracking", "Model Deployment", "Batch Inference"
        ],
        "progression_tasks": {
            "early": ["data cleaning", "EDA", "baseline models", "documentation"],
            "mid": ["feature engineering", "model development", "pipeline creation"],
            "late": ["model optimization", "deployment prep", "production integration"]
        }
    },
    "indian institute of technology indore": {
        "type": "research_internship",
        "domain": "ML/AI Research",
        "context": "Premier research institution conducting cutting-edge ML/AI research with focus on novel architectures and optimization methods.",
        "technical_vocabulary": [
            "state-of-the-art", "baseline comparison", "ablation study",
            "benchmark evaluation", "novel architecture", "convergence analysis",
            "generalization capability", "theoretical foundation", "empirical validation"
        ],
        "ml_projects": [
            "Research on efficient Neural Network architectures for resource-constrained deployment",
            "Investigation of Transfer Learning techniques for cross-domain adaptation",
            "Development of novel Attention Mechanisms for improved sequence modeling",
            "Empirical study of optimization algorithms for Deep Learning convergence",
            "Research on model compression and knowledge distillation techniques"
        ],
        "believable_tasks": [
            "Literature Review", "Baseline Implementation", "Experiment Design", "Ablation Studies",
            "Benchmark Evaluation", "Result Analysis", "Technical Writing", "Paper Reproduction"
        ],
        "progression_tasks": {
            "early": ["literature survey", "baseline reproduction", "data preparation"],
            "mid": ["experiment design", "systematic evaluation", "ablation studies"],
            "late": ["novel contributions", "paper writing", "presentation"]
        }
    },
    "iit indore": {
        "type": "research_internship",
        "domain": "ML/AI Research",
        "context": "Premier research institution conducting ML/AI research.",
        "technical_vocabulary": [
            "state-of-the-art", "baseline comparison", "ablation study",
            "benchmark evaluation", "novel architecture"
        ],
        "ml_projects": [
            "Novel Neural Network architecture research",
            "Transfer Learning and Domain Adaptation studies",
            "Attention mechanisms and Transformer variants"
        ],
        "believable_tasks": [
            "Literature Review", "Baseline Implementation", "Experiment Design", "Ablation Studies"
        ],
        "progression_tasks": {
            "early": ["literature survey", "baseline reproduction"],
            "mid": ["experiment design", "evaluation"],
            "late": ["novel contributions", "documentation"]
        }
    },
    "national institute of technology jaipur": {
        "type": "research_internship",
        "domain": "Applied ML Research",
        "context": "Engineering institution focusing on practical ML applications to real-world problems.",
        "technical_vocabulary": [
            "practical application", "real-world dataset", "engineering constraints",
            "system integration", "performance benchmarking", "scalability analysis",
            "robustness testing", "deployment considerations"
        ],
        "ml_projects": [
            "Applied Machine Learning for time-series forecasting in engineering systems",
            "Development of anomaly detection methods for industrial monitoring applications",
            "Classification system for pattern recognition in sensor data streams",
            "Ensemble methods research for improved prediction reliability",
            "Feature selection study for high-dimensional engineering datasets"
        ],
        "believable_tasks": [
            "Data Collection", "Data Cleaning", "Exploratory Analysis", "Feature Extraction",
            "Model Selection", "Training Pipelines", "Error Analysis", "Documentation"
        ],
        "progression_tasks": {
            "early": ["data collection", "preprocessing", "EDA"],
            "mid": ["model implementation", "evaluation", "iteration"],
            "late": ["optimization", "documentation", "handoff"]
        }
    },
    "nit jaipur": {
        "type": "research_internship",
        "domain": "Applied ML Research",
        "context": "Engineering institution focusing on practical ML applications.",
        "technical_vocabulary": [
            "practical application", "real-world dataset", "engineering constraints"
        ],
        "ml_projects": [
            "Time-series analysis and forecasting models",
            "Anomaly detection for industrial systems",
            "Regression models for engineering tasks"
        ],
        "believable_tasks": [
            "Data Collection", "Data Cleaning", "Exploratory Analysis", "Feature Extraction"
        ],
        "progression_tasks": {
            "early": ["data collection", "preprocessing"],
            "mid": ["model implementation", "evaluation"],
            "late": ["optimization", "documentation"]
        }
    }
}


def get_company_context(company_name: str) -> Dict[str, Any]:
    name_lower = (company_name or "").lower().strip()
    for key, ctx in COMPANY_CONTEXTS.items():
        if key in name_lower or name_lower in key:
            return ctx
    return {
        "type": "internship",
        "domain": "ML/AI",
        "context": "Technical internship applying Machine Learning and Data Science.",
        "technical_vocabulary": ["model development", "data analysis", "pipeline"],
        "ml_projects": ["ML Model Development", "Data Pipeline Creation"],
        "believable_tasks": ["Model Development", "Data Analysis", "Testing", "Documentation"],
        "progression_tasks": {
            "early": ["learning", "documentation"],
            "mid": ["implementation", "testing"],
            "late": ["optimization", "delivery"]
        }
    }


# ============================================================
# ðŸ¢ Company Core Expectations (target employer)
# ============================================================

COMPANY_CORE_FALLBACKS: Dict[str, Dict[str, Any]] = {
    "netflix": {
        "core_areas": ["Recommender Systems", "Search & Ranking", "Experimentation", "Large-Scale Data"],
        "core_keywords": ["Recommender Systems", "Search & Ranking", "A/B Testing", "Spark", "Scala", "Data Pipelines", "Offline Evaluation"],
    },
    "google": {
        "core_areas": ["System Design", "Scalability", "Distributed Systems", "Experimentation"],
        "core_keywords": ["System Design", "Distributed Systems", "Scalability", "A/B Testing", "Data Structures", "Algorithms"],
    },
    "meta": {
        "core_areas": ["Experimentation", "Ranking", "Large-Scale Data", "Distributed Systems"],
        "core_keywords": ["A/B Testing", "Ranking", "Distributed Systems", "Spark", "Data Pipelines", "Online Experimentation"],
    },
    "amazon": {
        "core_areas": ["Scalability", "Distributed Systems", "Operational Excellence", "Data-driven Decisions"],
        "core_keywords": ["Distributed Systems", "Scalability", "System Design", "Monitoring", "Data Pipelines"],
    },
    "microsoft": {
        "core_areas": ["Cloud Computing", "Distributed Systems", "AI/ML", "Product Development"],
        "core_keywords": ["Azure", "Distributed Systems", "Machine Learning", "System Design", "Cloud Architecture"],
    },
    "apple": {
        "core_areas": ["Privacy-Preserving ML", "On-Device ML", "User Experience", "System Optimization"],
        "core_keywords": ["On-Device ML", "Privacy", "Core ML", "System Optimization", "User Experience"],
    },
}

_company_core_cache: Dict[str, Dict[str, Any]] = {}


async def extract_company_core_requirements(
    target_company: str,
    target_role: str,
    jd_text: str,
) -> Dict[str, Any]:
    """
    Uses ChatGPT API to infer company expectations NOT always in the JD.
    âœ¨ UPGRADED: Now explicitly excludes standards/certifications
    """
    ckey = (target_company or "").strip().lower()
    rkey = (target_role or "").strip().lower()
    cache_key = f"{ckey}__{rkey}"
    if cache_key in _company_core_cache:
        return _company_core_cache[cache_key]

    if not ckey or ckey in {"company", "unknown"}:
        out = {
            "core_areas": ["System Design", "Experimentation", "Distributed Systems"],
            "core_keywords": ["System Design", "Distributed Systems", "A/B Testing", "Data Pipelines", "Scalability"],
            "notes": "Generic big-tech expectations used.",
        }
        _company_core_cache[cache_key] = out
        return out

    json_schema = (
        '{\n'
        '  "core_areas": ["..."],\n'
        '  "core_keywords": ["..."],\n'
        '  "notes": "1-2 sentence justification"\n'
        '}'
    )

    # âœ¨ UPGRADED: Explicit exclusion of standards/certifications
    prompt = (
        "You are building an ATS-focused resume optimizer.\n"
        "Infer the KEY COMPANY EXPECTATIONS for the target employer that are often NOT explicitly stated in the JD.\n\n"
        f"Target Company: {target_company}\n"
        f"Target Role: {target_role}\n\n"
        "Rules:\n"
        "- Return STRICT JSON ONLY in this format:\n"
        f"{json_schema}\n"
        "- core_areas: 3-6 high-level areas (2-4 words each).\n"
        "- core_keywords: 8-14 resume-friendly skills/topics/tools commonly expected.\n"
        "- âœ¨ NEW: Do NOT include standards (ISO, NIST), certifications, or compliance terms.\n"
        "- Do NOT invent proprietary internal tool names.\n"
        "- Keep tokens short (1-4 words).\n\n"
        "JD (for context only; do not restrict to it):\n"
        f"{jd_text[:2500]}"
    )

    try:
        data = await gpt_json(prompt, temperature=0.0)
        core_areas = data.get("core_areas", []) or []
        core_kw = data.get("core_keywords", []) or []
        notes = (data.get("notes", "") or "").strip()

        def _clean_list(lst: Iterable[Any]) -> List[str]:
            out_list: List[str] = []
            seen: Set[str] = set()
            for x in lst:
                s = re.sub(r"[^\w\-\+\.#\/ \(\)&]", "", str(x)).strip()
                s = re.sub(r"\s+", " ", s)
                if not s:
                    continue
                s = fix_skill_capitalization(s)
                key = s.lower()
                if key not in seen:
                    seen.add(key)
                    out_list.append(s)
            return out_list

        core_areas = _clean_list(core_areas)[:8]
        core_kw = _clean_list(core_kw)[:18]

        if not core_kw:
            fb = COMPANY_CORE_FALLBACKS.get(ckey, {})
            core_areas = fb.get("core_areas", core_areas) or core_areas
            core_kw = fb.get("core_keywords", core_kw) or core_kw

        out = {"core_areas": core_areas, "core_keywords": core_kw, "notes": notes}
        _company_core_cache[cache_key] = out
        log_event(f"ðŸ¢ [COMPANY CORE] {target_company} areas={len(core_areas)} keywords={len(core_kw)}")
        return out

    except Exception as e:
        log_event(f"âš ï¸ [COMPANY CORE] Failed: {e}")
        fb = COMPANY_CORE_FALLBACKS.get(ckey, {})
        out = {
            "core_areas": fb.get("core_areas", ["System Design", "Experimentation", "Distributed Systems"]),
            "core_keywords": fb.get("core_keywords", ["System Design", "Distributed Systems", "A/B Testing", "Data Pipelines", "Scalability"]),
            "notes": "Fallback company-core profile used due to API failure.",
        }
        _company_core_cache[cache_key] = out
        return out


# ============================================================
# ðŸ”’ LaTeX-safe utils
# ============================================================

LATEX_ESC = {
    "#": r"\#", "%": r"\%", "$": r"\$", "&": r"\&",
    "_": r"\_", "{": r"\{", "}": r"\}",
}

UNICODE_NORM = {
    "â€“": "-", "â€”": "-", "âˆ’": "-", "â€¢": "-", "Â·": "-", "â—": "-",
    "â†’": "->", "â‡’": "=>", "â†”": "<->", "Ã—": "x", "Â°": " degrees ",
    "\u00A0": " ", "\uf0b7": "-", "\x95": "-",
}


def latex_escape_text(s: str) -> str:
    if not s or not isinstance(s, str):
        return ""
    for a, b in UNICODE_NORM.items():
        s = s.replace(a, b)
    specials = ["%", "$", "&", "_", "#", "{", "}"]
    for ch in specials:
        s = re.sub(rf"(?<!\\){re.escape(ch)}", LATEX_ESC[ch], s)
    s = re.sub(r"(?<!\\)\^", r"\^{}", s)
    s = re.sub(r"[ \t]+", " ", s).strip()
    s = re.sub(r"\\(?![a-zA-Z#$%&_{}^])", "", s)
    return s


def strip_all_macros_keep_text(s: str) -> str:
    prev = None
    while prev != s:
        prev = s
        s = re.sub(r"\\[a-zA-Z]+\{([^{}]*)\}", r"\1", s)
    s = re.sub(r"\\[a-zA-Z]+", "", s)
    s = s.replace("{", "").replace("}", "")
    for a, b in UNICODE_NORM.items():
        s = s.replace(a, b)
    return s.strip()


# ============================================================
# ðŸ“ BULLET LENGTH VALIDATION
# ============================================================

MIN_BULLET_WORDS = 18
MAX_BULLET_WORDS = 24
IDEAL_BULLET_WORDS = 21


def get_word_count(text: str) -> int:
    return len((text or "").split())


def is_valid_bullet_length(text: str) -> bool:
    count = get_word_count(text)
    return MIN_BULLET_WORDS <= count <= MAX_BULLET_WORDS


def adjust_bullet_length(text: str) -> str:
    """Truncate if too long; otherwise leave."""
    words = (text or "").split()
    if len(words) > MAX_BULLET_WORDS:
        truncated = words[:MAX_BULLET_WORDS]
        result = " ".join(truncated).rstrip(".,;:") + "."
        return result
    return text


# ============================================================
# ðŸ§° LaTeX Parsing Utils
# ============================================================

def find_resume_items(block: str) -> List[Tuple[int, int, int, int]]:
    out: List[Tuple[int, int, int, int]] = []
    i = 0
    macro = r"\resumeItem"
    n = len(macro)
    while True:
        i = block.find(macro, i)
        if i < 0:
            break
        j = i + n
        while j < len(block) and block[j].isspace():
            j += 1
        if j >= len(block) or block[j] != "{":
            i = j
            continue
        open_b = j
        depth, k = 0, open_b
        while k < len(block):
            if block[k] == "{":
                depth += 1
            elif block[k] == "}":
                depth -= 1
                if depth == 0:
                    out.append((i, open_b, k, k + 1))
                    i = k + 1
                    break
            k += 1
        else:
            break
    return out


def replace_resume_items(block: str, replacements: List[str]) -> str:
    items = find_resume_items(block)
    if not items:
        return block
    if len(replacements) < len(items):
        replacements = replacements + [None] * (len(items) - len(replacements))
    out: List[str] = []
    last = 0
    for (start, open_b, close_b, end), newtxt in zip(items, replacements):
        out.append(block[last:open_b + 1])
        out.append(newtxt if newtxt is not None else block[open_b + 1:close_b])
        out.append(block[close_b:end])
        last = end
    out.append(block[last:])
    return "".join(out)


def section_rx(name: str) -> re.Pattern:
    return re.compile(
        rf"(\\section\*?\{{\s*{re.escape(name)}\s*\}}[\s\S]*?)(?=\\section\*?\{{|\\end\{{document\}}|$)",
        re.IGNORECASE,
    )


# ============================================================
# ðŸ§  GPT Helper
# ============================================================

def _json_from_text(text: str, default: Any):
    m = re.search(r"\{[\s\S]*\}", text or "")
    if not m:
        return default
    try:
        return json.loads(m.group(0))
    except Exception:
        return default


async def gpt_json(prompt: str, temperature: float = 0.0, model: str = "gpt-4o-mini") -> dict:
    client = get_openai_client()
    kwargs: Dict[str, Any] = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": temperature,
        "timeout": 120,
    }

    try:
        kwargs["response_format"] = {"type": "json_object"}
        resp = client.chat.completions.create(**kwargs)
    except TypeError:
        kwargs.pop("response_format", None)
        resp = client.chat.completions.create(**kwargs)

    content = (resp.choices[0].message.content or "").strip()
    return _json_from_text(content or "{}", {})


# ============================================================
# ðŸ§  JD Analysis - UPGRADED
# ============================================================

async def extract_company_role(jd_text: str) -> Tuple[str, str]:
    prompt = (
        'Return STRICT JSON: {"company":"â€¦","role":"â€¦"}\n'
        "Use the official company short name and the exact job title.\n"
        f"JD:\n{jd_text}"
    )
    try:
        data = await gpt_json(prompt, temperature=0.0)
        return data.get("company", "Company"), data.get("role", "Role")
    except Exception as e:
        log_event(f"âš ï¸ [JD PARSE] Failed: {e}")
        return "Company", "Role"


async def extract_keywords_with_priority(jd_text: str) -> Dict[str, Any]:
    """
    âœ¨ UPGRADED: Now explicitly excludes standards/certifications in prompt
    """
    prompt = f"""Analyze this job description and extract ALL technical keywords with correct capitalization.

JOB DESCRIPTION:
{jd_text}

Return STRICT JSON:
{{
    "must_have": ["Python","PyTorch","SQL","Machine Learning"],
    "should_have": ["Docker","AWS","Kubernetes","MLOps"],
    "nice_to_have": ["Git","Linux","Agile"],
    "key_responsibilities": ["5-7 main job duties"],
    "domain_context": "brief domain description"
}}

âœ¨ IMPORTANT: 
- Extract ONLY hard technical skills (programming languages, frameworks, tools, platforms)
- DO NOT include: ISO standards, NIST frameworks, certifications, compliance terms
- DO NOT include: degrees (PhD, MS), time periods, generic qualifiers
- Be comprehensive but strict about what counts as a resume skill
"""

    try:
        data = await gpt_json(prompt, temperature=0.0)
        must_have = [fix_skill_capitalization(k) for k in data.get("must_have", [])]
        should_have = [fix_skill_capitalization(k) for k in data.get("should_have", [])]
        nice_to_have = [fix_skill_capitalization(k) for k in data.get("nice_to_have", [])]
        responsibilities = list(data.get("key_responsibilities", []))
        domain = data.get("domain_context", "Technology")

        seen: Set[str] = set()

        def dedup(lst: List[str]) -> List[str]:
            out: List[str] = []
            for item in lst:
                item = str(item).strip()
                if item and item.lower() not in seen:
                    seen.add(item.lower())
                    out.append(item)
            return out

        must_have = dedup(must_have)
        should_have = dedup(should_have)
        nice_to_have = dedup(nice_to_have)

        all_keywords = must_have + should_have + nice_to_have
        log_event(f"ðŸ’¡ [JD KEYWORDS] must={len(must_have)}, should={len(should_have)}, nice={len(nice_to_have)}")

        return {
            "must_have": must_have,
            "should_have": should_have,
            "nice_to_have": nice_to_have,
            "all_keywords": all_keywords,
            "responsibilities": responsibilities,
            "domain": domain,
        }

    except Exception as e:
        log_event(f"âš ï¸ [JD KEYWORDS] Failed: {e}")
        return {
            "must_have": [], "should_have": [], "nice_to_have": [],
            "all_keywords": [], "responsibilities": [], "domain": "Technology",
        }


async def extract_coursework_gpt(jd_text: str, max_courses: int = 24) -> List[str]:
    prompt = (
        f"From the JD, choose up to {max_courses} highly relevant university courses. "
        'Return STRICT JSON: {"courses":["Machine Learning","Deep Learning","Data Structures"]}\n'
        f"JD:\n{jd_text}"
    )
    try:
        data = await gpt_json(prompt, temperature=0.0)
        courses = data.get("courses", []) or []
        out: List[str] = []
        seen: Set[str] = set()
        for c in courses:
            c = fix_capitalization(re.sub(r"\s+", " ", str(c)).strip())
            c = _ensure_first_letter_capital(c)
            if c and c.lower() not in seen:
                seen.add(c.lower())
                out.append(c)
        return out[:max_courses]
    except Exception as e:
        log_event(f"âš ï¸ [JD COURSES] Failed: {e}")
        return []


# ============================================================
# ðŸŽ“ Replace Coursework
# ============================================================

def replace_relevant_coursework_distinct(body_tex: str, courses: List[str], max_per_line: int = 6) -> str:
    seen: Set[str] = set()
    uniq: List[str] = []
    for c in courses:
        c = fix_capitalization(re.sub(r"\s+", " ", str(c)).strip())
        c = _ensure_first_letter_capital(c)
        if c and c.lower() not in seen:
            seen.add(c.lower())
            uniq.append(c)

    line_pat = re.compile(r"(\\item\s*\\textbf\{Relevant Coursework:\})([^\n]*)")
    matches = list(line_pat.finditer(body_tex))
    if not matches:
        return body_tex

    chunks: List[List[str]] = []
    if len(matches) == 1:
        chunks.append(uniq[:max_per_line])
    else:
        split_idx = (len(uniq) + 1) // 2
        chunks = [uniq[:split_idx][:max_per_line], uniq[split_idx:split_idx + max_per_line]]

    out: List[str] = []
    last = 0
    for i, m in enumerate(matches):
        out.append(body_tex[last:m.start()])
        if i < len(chunks):
            payload = ", ".join(latex_escape_text(x) for x in chunks[i])
            out.append(m.group(1) + " " + payload)
        else:
            out.append(m.group(0))
        last = m.end()
    out.append(body_tex[last:])
    return "".join(out)


# ============================================================
# ðŸ§± Skills Section
# ============================================================

def render_skills_section_flat(skills: List[str]) -> str:
    if not skills:
        return ""

    seen: Set[str] = set()
    unique_skills: List[str] = []
    for s in skills:
        s = fix_skill_capitalization(str(s).strip())
        if not s:
            continue
        if s.lower() not in seen:
            seen.add(s.lower())
            unique_skills.append(s)

    skills_content = ", ".join(latex_escape_text(s) for s in unique_skills)

    return (
        r"\section{Skills}" + "\n"
        r"\begin{itemize}[leftmargin=0.15in, label={}]" + "\n"
        r"  \item \small{" + skills_content + r"}" + "\n"
        r"\end{itemize}"
    )


async def replace_skills_section(body_tex: str, skills: List[str]) -> str:
    new_block = render_skills_section_flat(skills)
    if not new_block:
        return body_tex

    pattern = re.compile(
        r"(\\section\*?\{Skills\}[\s\S]*?)(?=%-----------|\\section\*?\{|\\end\{document\})",
        re.IGNORECASE,
    )
    if re.search(pattern, body_tex):
        return re.sub(pattern, lambda _: new_block + "\n", body_tex)

    m = re.search(r"%-----------TECHNICAL SKILLS-----------", body_tex, re.IGNORECASE)
    if m:
        return body_tex[:m.end()] + "\n" + new_block + "\n" + body_tex[m.end():]

    return body_tex


async def generate_credible_bullets(
    jd_text: str,
    experience_company: str,
    target_company: str,
    target_role: str,
    company_core_keywords: List[str],
    must_use_keywords: List[str],
    should_use_keywords: List[str],
    responsibilities: List[str],
    used_keywords: Set[str],
    block_index: int,
    bullet_start_position: int,  # âœ¨ NEW: Absolute bullet position (0-11)
    total_blocks: int = 4,
    num_bullets: int = 3,
) -> Tuple[List[str], Set[str]]:
    """
    Generate ENHANCED resume bullets with:
    - âœ¨ UPGRADED: Unique action verbs (NO repetition across all 12 bullets)
    - âœ¨ UPGRADED: Different sentence structures for each bullet
    - âœ¨ UPGRADED: 4 numbers total across resume (positions 2,6,7,10)
    - âœ¨ UPGRADED: 4 different number categories
    - âœ¨ UPGRADED: 2 hero points (positions 2,6) with comparison numbers
    """
    exp_context = get_company_context(experience_company)
    progression = get_progression_context(block_index, total_blocks)
    
    # âœ¨ NEW: Check which bullets in this block get quantification
    quantified_bullets_in_block = []
    for i in range(num_bullets):
        bullet_pos = bullet_start_position + i
        if should_quantify_bullet(bullet_pos):
            category = get_quantification_category(bullet_pos, jd_text)
            quantified_bullets_in_block.append((i, category))  # (local_index, category)
    
    # Get diverse verb categories for this company type
    verb_categories = get_verb_categories_for_context(exp_context.get("type", "internship"))
    
    # âœ¨ NEW: Pre-select 3 unique verbs for this block
    suggested_verbs = []
    for cat in (verb_categories * 3)[:num_bullets]:  # Ensure we have enough
        verb = get_diverse_verb(cat)
        suggested_verbs.append(verb)
    
    # Get technical depth phrase
    tech_depth = get_technical_depth_phrase("ml_techniques")
    
    # Get result phrase
    result_phrase = get_result_phrase("performance")
    
    # Get believability phrase
    believability = get_believability_phrase()

    available_must = [fix_skill_capitalization(k) for k in must_use_keywords if k.lower() not in used_keywords][:6]
    available_should = [fix_skill_capitalization(k) for k in should_use_keywords if k.lower() not in used_keywords][:4]

    core_pool = [fix_skill_capitalization(k) for k in (company_core_keywords or [])]
    core_pool = [k for k in core_pool if k.lower() not in used_keywords][:6]

    keywords_for_block = core_pool[:3] + available_must + available_should
    keywords_for_block = [k for k in keywords_for_block if k]

    keywords_str = ", ".join(keywords_for_block[:10]) if keywords_for_block else "Python, Machine Learning"
    resp_str = "; ".join(responsibilities[:3]) if responsibilities else "Model Development; Evaluation; Deployment"

    core_focus_str = ", ".join(core_pool[:4]) if core_pool else ""
    core_rule = (
        f"- Naturally include target-company core areas: {core_focus_str}\n"
        if core_focus_str else ""
    )

    # Get company-specific vocabulary
    tech_vocab = exp_context.get("technical_vocabulary", [])
    vocab_str = ", ".join(tech_vocab[:5]) if tech_vocab else ""

    # âœ¨ UPGRADED: Build quantification instructions based on bullet positions
    quant_instructions = []
    for local_idx, category in quantified_bullets_in_block:
        is_hero = (bullet_start_position + local_idx) in HERO_POSITIONS
        if is_hero:
            quant_instructions.append(
                f"   â€¢ Bullet {local_idx + 1}: HERO POINT with comparison (from X% to Y%) - most impressive achievement"
            )
        else:
            if category == "count_scale":
                quant_instructions.append(
                    f"   â€¢ Bullet {local_idx + 1}: Include COUNT metric (e.g., '10,347 samples', '15K+ records')"
                )
            elif category == "metric_achievement":
                quant_instructions.append(
                    f"   â€¢ Bullet {local_idx + 1}: Include ML METRIC (e.g., 'F1 score of 0.87', 'precision of 0.93')"
                )
            elif category == "percent_improvement":
                quant_instructions.append(
                    f"   â€¢ Bullet {local_idx + 1}: Include PERCENTAGE improvement (e.g., '23.7% improvement')"
                )
    
    if quant_instructions:
        quant_instruction = f"""
ðŸŽ¯ QUANTIFICATION REQUIREMENTS FOR THIS BLOCK:
{chr(10).join(quant_instructions)}
   â€¢ Other bullets: NO numbers (use qualitative impact phrases)
   â€¢ All numbers must end in ODD digits (e.g., 23.7%, 10,347, 0.87)
   â€¢ NO rounding (avoid 50%, 60%, 1000 - use 47%, 63%, 1,247)
"""
    else:
        quant_instruction = """
ðŸŽ¯ NO quantification for bullets in this block.
   â€¢ Focus on technical methodology and qualitative impact
"""

    # âœ¨ UPGRADED: Sentence structure diversity templates
    structure_templates = [
        "{verb} {object} using {method}, {result}",
        "{verb} {method}-based {object} to {result}",
        "Leveraged {method} to {verb_lower} {object}, {result}",
        "{verb} {object} through {method} implementation, {result}",
        "Utilized {method} for {verb_gerund} {object}, {result}",
        "{verb} comprehensive {object} incorporating {method}, {result}",
    ]

    prompt = f"""Write EXACTLY {num_bullets} HIGHLY CREDIBLE resume bullet points for an INTERN at "{experience_company}",
tailored for applying to "{target_company}" ({target_role}).

ðŸŽ¯ CRITICAL REQUIREMENTS FOR CREDIBILITY:
0. USE: INDIAN ACCENT IN LANGUAGE and USA SPELLING STANDARDS THROUGHOUT.

1. LENGTH: Each bullet MUST be EXACTLY 18-22 words (count carefully!)

2. SKILLS TO USE: Each bullet MUST naturally integrate 2-3 skills from: {keywords_str}

3. âœ¨ ACTION VERBS: Use these PRE-ASSIGNED verbs (NO substitution, NO repetition):
   - Bullet 1: {suggested_verbs[0]}
   - Bullet 2: {suggested_verbs[1]}
   - Bullet 3: {suggested_verbs[2]}
   â€¢ These verbs are globally unique across the entire resume (never used before)

4. âœ¨ SENTENCE STRUCTURES: Use DIFFERENT structures for each bullet:
   â€¢ Vary: verb placement, clause order, phrase connections
   â€¢ Example structures: {' | '.join(structure_templates[:3])}

5. TECHNICAL DEPTH: Show HOW you did things, not just WHAT:
   - Example technique reference: "{tech_depth}"
   - Include specific methodologies, not vague claims

{quant_instruction}

6. BELIEVABILITY FOR INTERN LEVEL:
   - Scope: {progression['scope'][0]} / {progression['scope'][1]} level work
   - Autonomy: {progression['autonomy']}
   - Task complexity: {progression['complexity']}
   {f'- Collaboration: {believability}' if believability else ''}

7. DOMAIN VOCABULARY: Use industry terms naturally:
   - Company domain: {exp_context['domain']}
   - Relevant terms: {vocab_str}

{core_rule}

EXPERIENCE CONTEXT:
- Company Type: {exp_context['type']}
- Domain: {exp_context['domain']}

JOB RESPONSIBILITIES TO ALIGN WITH:
{resp_str}

âœ¨ GOOD EXAMPLES WITH DIVERSE STRUCTURES:
{"- HERO: 'Engineered PyTorch classification pipeline with Cross-Validation and Hyperparameter Tuning, improving model accuracy from 67% to 91% through systematic optimization cycles.'" if any(i in HERO_POSITIONS for i, _ in quantified_bullets_in_block) else ""}
- "Developed automated Feature Engineering framework using Pandas and Scikit-learn, enabling consistent data transformation for downstream Machine Learning models."
- "Leveraged TensorFlow and MLflow to implement model training workflow, facilitating reproducible research and systematic performance comparison across experiments."

âŒ BAD EXAMPLES:
- Starting multiple bullets with same verb
- Using rounded numbers (50%, 1000)
- Vague impacts without methodology
- Repetitive sentence patterns

Return STRICT JSON with EXACTLY {num_bullets} bullets:
{{"bullets": ["bullet1", "bullet2", "bullet3"]}}
"""

    try:
        data = await gpt_json(prompt, temperature=0.3)
        bullets = data.get("bullets", []) or []

        cleaned: List[str] = []
        newly_used: Set[str] = set()

        for local_idx, b in enumerate(bullets[:num_bullets]):
            b = str(b).strip()
            b = fix_capitalization(b)
            
            # âœ¨ UPGRADED: Check if this specific bullet should have quantification
            should_have_number = any(idx == local_idx for idx, _ in quantified_bullets_in_block)
            
            if not should_have_number:
                # Remove any quantification
                b = re.sub(r'\d+\.?\d*%', '', b)
                b = re.sub(r'\d+x', '', b)
                b = re.sub(r'\d+,?\d*\s+(?:samples|records|minutes|hours)', '', b)
                b = re.sub(r'(?:F1|f1)\s+score\s+of\s+\d+\.\d+', '', b)
                b = re.sub(r'from\s+\d+%?\s+to\s+\d+%?', '', b)
                b = re.sub(r'\s+', ' ', b).strip()

            b = adjust_bullet_length(b)
            b = latex_escape_text(b)

            if b:
                cleaned.append(b)
                for kw in keywords_for_block:
                    if kw.lower() in b.lower():
                        newly_used.add(kw.lower())

        # Enhanced fallback bullets with correct verbs
        while len(cleaned) < num_bullets:
            idx = len(cleaned)
            verb = suggested_verbs[idx]  # Use pre-assigned verb
            kw1 = fix_skill_capitalization(keywords_for_block[idx % max(1, len(keywords_for_block))]) if keywords_for_block else "Python"
            kw2 = fix_skill_capitalization(keywords_for_block[(idx + 1) % max(1, len(keywords_for_block))]) if len(keywords_for_block) > 1 else "Machine Learning"
            
            # Check if this fallback should have quantification
            should_have_number = any(i == idx for i, _ in quantified_bullets_in_block)
            
            if should_have_number:
                category = next(cat for i, cat in quantified_bullets_in_block if i == idx)
                quant_phrase = generate_quantified_phrase(category, jd_text)
                fallback = f"{verb} {kw1}-based analytical workflow with {kw2} integration, {quant_phrase} through systematic optimization."
            else:
                fallback = f"{verb} {kw1}-based analytical workflow with {kw2} integration, enabling systematic evaluation and improved reproducibility."
            
            fallback = fix_capitalization(fallback)
            cleaned.append(latex_escape_text(fallback))
            newly_used.add(kw1.lower())
            newly_used.add(kw2.lower())

        return cleaned[:num_bullets], newly_used

    except Exception as e:
        log_event(f"âš ï¸ [BULLETS] Generation failed for {experience_company}: {e}")
        # Fallback with correct verbs
        fallbacks = []
        for idx in range(num_bullets):
            verb = suggested_verbs[idx]
            fallback = f"{verb} Machine Learning model development and Data Pipeline implementation supporting research objectives with reliable engineering practices."
            fallbacks.append(latex_escape_text(fallback))
        return fallbacks, set()

async def rewrite_experience_with_skill_alignment(
    tex_content: str,
    jd_text: str,
    jd_info: Dict[str, Any],
    target_company: str,
    target_role: str,
    company_core_keywords: List[str],
) -> Tuple[str, Set[str]]:
    # Reset tracking for new resume
    reset_verb_tracking()
    reset_result_phrase_tracking()
    reset_quantification_tracking()
    
    must_have = jd_info.get("must_have", []) or []
    should_have = jd_info.get("should_have", []) or []
    responsibilities = jd_info.get("responsibilities", []) or []

    exp_used_keywords: Set[str] = set()

    num_blocks = 4
    must_per_block = max(3, len(must_have) // num_blocks + 1)
    should_per_block = max(2, len(should_have) // num_blocks + 1)

    exp_pat = section_rx("Experience")
    out: List[str] = []
    pos = 0
    block_index = 0
    absolute_bullet_position = 0  # âœ¨ NEW: Track position across all bullets (0-11)

    for m in exp_pat.finditer(tex_content):
        out.append(tex_content[pos:m.start()])
        section = m.group(1)

        s_tag, e_tag = r"\resumeItemListStart", r"\resumeItemListEnd"
        rebuilt: List[str] = []
        i = 0

        while True:
            a = section.find(s_tag, i)
            if a < 0:
                rebuilt.append(section[i:])
                break

            b = section.find(e_tag, a)
            if b < 0:
                rebuilt.append(section[i:])
                break

            rebuilt.append(section[i:a])

            # Candidate experience company
            if block_index == 0:
                exp_company = "Ayar Labs"
            elif block_index == 1:
                exp_company = "Indian Institute of Technology Indore"
            elif block_index == 2:
                exp_company = "National Institute of Technology Jaipur"
            else:
                exp_company = "Indian Institute of Technology Indore"

            start_must = block_index * must_per_block
            end_must = min(start_must + must_per_block, len(must_have))
            block_must = must_have[start_must:end_must]

            unused_must = [k for k in must_have if k.lower() not in exp_used_keywords]
            block_must = list(dict.fromkeys(block_must + unused_must[:2]))

            start_should = block_index * should_per_block
            end_should = min(start_should + should_per_block, len(should_have))
            block_should = should_have[start_should:end_should]

            core_slice = company_core_keywords[(block_index * 2):(block_index * 2 + 3)] if company_core_keywords else []
            block_should = list(dict.fromkeys(block_should + core_slice))

            # âœ¨ UPGRADED: Pass absolute bullet position
            new_bullets, newly_used = await generate_credible_bullets(
                jd_text=jd_text,
                experience_company=exp_company,
                target_company=target_company,
                target_role=target_role,
                company_core_keywords=company_core_keywords,
                must_use_keywords=block_must,
                should_use_keywords=block_should,
                responsibilities=responsibilities,
                used_keywords=exp_used_keywords,
                block_index=block_index,
                bullet_start_position=absolute_bullet_position,  # âœ¨ NEW
                total_blocks=num_blocks,
                num_bullets=3,
            )

            exp_used_keywords.update(newly_used)

            new_block = s_tag + "\n"
            for bullet in new_bullets:
                new_block += f"    \\resumeItem{{{bullet}}}\n"
            new_block += "  " + e_tag

            rebuilt.append(new_block)
            block_index += 1
            absolute_bullet_position += 3  # âœ¨ NEW: Increment by bullets per block
            i = b + len(e_tag)

        out.append("".join(rebuilt))
        pos = m.end()

    out.append(tex_content[pos:])

    must_covered = len([k for k in must_have if k.lower() in exp_used_keywords])
    
    # âœ¨ UPGRADED: Enhanced logging
    log_event(f"ðŸ“Š [EXP COVERAGE] Must-have: {must_covered}/{len(must_have)}")
    log_event(f"ðŸŽ² [QUANTIFICATION] Positions: {QUANTIFIED_POSITIONS}, Hero: {HERO_POSITIONS}")
    log_event(f"ðŸŽ¯ [NUMBERS USED] Percent: {_used_numbers_by_category['percent']}")
    log_event(f"ðŸŽ¯ [NUMBERS USED] Count: {_used_numbers_by_category['count']}")
    log_event(f"ðŸŽ¯ [NUMBERS USED] Metric: {_used_numbers_by_category['metric']}")
    log_event(f"ðŸŽ¯ [NUMBERS USED] Comparison: {_used_numbers_by_category['comparison']}")
    log_event(f"âœ… [VERBS] Total unique: {len(_used_verbs_global)}/12")

    return "".join(out), exp_used_keywords

# ============================================================
# ðŸ“„ PDF Helpers
# ============================================================

def _pdf_page_count(pdf_bytes: Optional[bytes]) -> int:
    if not pdf_bytes:
        return 0
    return len(re.findall(rb"/Type\s*/Page\b", pdf_bytes))


_EDU_SPLIT_ANCHOR = re.compile(r"(%-----------EDUCATION-----------)|\\section\*?\{\s*Education\s*\}", re.IGNORECASE)


def _split_preamble_body(tex: str) -> Tuple[str, str]:
    m = _EDU_SPLIT_ANCHOR.search(tex or "")
    if not m:
        return "", re.sub(r"\\end\{document\}\s*$", "", tex or "")
    start = m.start()
    preamble = (tex or "")[:start]
    body = re.sub(r"\\end\{document\}\s*$", "", (tex or "")[start:])
    return preamble, body


def _merge_tex(preamble: str, body: str) -> str:
    out = (str(preamble).strip() + "\n\n" + str(body).strip()).rstrip()
    out = re.sub(r"\\end\{document\}\s*$", "", out).rstrip()
    out += "\n\\end{document}\n"
    return out


# ============================================================
# âœ‚ï¸ Page Trimming
# ============================================================

ACHIEVEMENT_SECTION_NAMES = [
    "Achievements", "Awards & Achievements", "Achievements & Awards",
    "Awards", "Honors & Awards", "Honors", "Certifications",
]


def remove_one_achievement_bullet(tex_content: str) -> Tuple[str, bool]:
    for sec in ACHIEVEMENT_SECTION_NAMES:
        pat = section_rx(sec)
        m = pat.search(tex_content)
        if not m:
            continue
        full = m.group(1)
        items = find_resume_items(full)
        if items:
            s, _, _, e = items[-1]
            new_sec = full[:s] + full[e:]
            log_event(f"âœ‚ï¸ [TRIM] Removed bullet from '{sec}'")
            return tex_content[:m.start()] + new_sec + tex_content[m.end():], True
    return tex_content, False


def remove_last_bullet_from_sections(tex_content: str, sections: Tuple[str, ...] = ("Projects", "Experience")) -> Tuple[str, bool]:
    for sec in sections:
        pat = section_rx(sec)
        last_m = None
        for match in pat.finditer(tex_content):
            last_m = match
        if last_m:
            full = last_m.group(1)
            items = find_resume_items(full)
            if items:
                s, _, _, e = items[-1]
                new_sec = full[:s] + full[e:]
                log_event(f"âœ‚ï¸ [TRIM] Removed bullet from '{sec}'")
                return tex_content[:last_m.start()] + new_sec + tex_content[last_m.end():], True
    return tex_content, False


# ============================================================
# ðŸ“Š Coverage Calculation
# ============================================================

def compute_coverage(tex_content: str, keywords: List[str]) -> Dict[str, Any]:
    plain = strip_all_macros_keep_text(tex_content).lower()
    present: Set[str] = set()
    missing: Set[str] = set()
    for kw in keywords:
        kw_lower = str(kw).lower().strip()
        if kw_lower and kw_lower in plain:
            present.add(kw_lower)
        elif kw_lower:
            missing.add(kw_lower)
    total = max(1, len(present) + len(missing))
    return {"ratio": len(present) / total, "present": sorted(present), "missing": sorted(missing), "total": total}


# ============================================================
# ðŸš€ Main Optimizer - UPGRADED
# ============================================================

async def optimize_resume(
    base_tex: str,
    jd_text: str,
    target_company: str,
    target_role: str,
    extra_keywords: Optional[str] = None,
) -> Tuple[str, Dict[str, Any]]:
    """
    âœ¨ UPGRADED: Now with unique number tracking and stricter validation
    """
    log_event("ðŸŸ¨ [OPTIMIZE] Starting ENHANCED optimization with skill validation & UNIQUE quantification")

    # 1) JD keywords
    jd_info = await extract_keywords_with_priority(jd_text)

    # 2) Company-core expectations
    company_core = await extract_company_core_requirements(target_company, target_role, jd_text)
    core_keywords = [fix_skill_capitalization(k) for k in (company_core.get("core_keywords", []) or [])]

    # 3) VALIDATE SKILLS - Filter out non-skills
    log_event("ðŸ” [SKILL VALIDATION] Starting STRICT validation...")
    
    all_keywords_raw = list(jd_info.get("all_keywords", []) or [])
    for k in core_keywords:
        if k and k.lower() not in [x.lower() for x in all_keywords_raw]:
            all_keywords_raw.append(k)
    
    # Validate all keywords
    validated_keywords = await filter_valid_skills(all_keywords_raw)
    
    # Update jd_info with validated keywords
    jd_info["must_have"] = await filter_valid_skills(jd_info.get("must_have", []))
    jd_info["should_have"] = await filter_valid_skills(jd_info.get("should_have", []))
    jd_info["nice_to_have"] = await filter_valid_skills(jd_info.get("nice_to_have", []))
    jd_info["all_keywords"] = validated_keywords
    
    # Validate core keywords
    core_keywords = await filter_valid_skills(core_keywords)
    jd_info["company_core_keywords"] = core_keywords
    
    all_keywords = validated_keywords

    # 4) Extra keywords
    extra_list: List[str] = []
    if extra_keywords:
        for token in re.split(r"[,\n;]+", extra_keywords):
            t = fix_skill_capitalization(token.strip())
            if t and t.lower() not in [x.lower() for x in extra_list]:
                extra_list.append(t)
        
        # Validate extra keywords
        extra_list = await filter_valid_skills(extra_list)
        
    if extra_list:
        jd_info["extra_keywords"] = extra_list
        for k in extra_list:
            if k.lower() not in [x.lower() for x in all_keywords]:
                all_keywords.append(k)
    else:
        jd_info["extra_keywords"] = []

    log_event(f"ðŸ“Š [KEYWORDS] JD={len(jd_info.get('all_keywords', []))} + CORE={len(core_keywords)} + EXTRA={len(extra_list)} â†’ TOTAL={len(all_keywords)}")

    # 5) Coursework
    courses = await extract_coursework_gpt(jd_text, max_courses=24)

    # 6) Split preamble/body
    preamble, body = _split_preamble_body(base_tex)

    # 7) Coursework replace
    body = replace_relevant_coursework_distinct(body, courses, max_per_line=8)
    log_event("âœ… [COURSEWORK] Updated")

    # 8) Rewrite experience with enhanced bullet generation + UNIQUE quantification
    body, exp_used_keywords = await rewrite_experience_with_skill_alignment(
        body,
        jd_text,
        jd_info,
        target_company=target_company,
        target_role=target_role,
        company_core_keywords=core_keywords,
    )
    log_event(f"âœ… [EXPERIENCE] {len(exp_used_keywords)} keywords used with UNIQUE quantification")

    # 9) Skills section - VALIDATED ONLY
    skills_list: List[str] = [fix_skill_capitalization(k) for k in exp_used_keywords]

    for kw in jd_info.get("must_have", []) or []:
        kw_fixed = fix_skill_capitalization(kw)
        if kw_fixed.lower() not in [s.lower() for s in skills_list]:
            skills_list.append(kw_fixed)

    for kw in jd_info.get("nice_to_have", []) or []:
        kw_fixed = fix_skill_capitalization(kw)
        if kw_fixed.lower() not in [s.lower() for s in skills_list]:
            skills_list.append(kw_fixed)

    for kw in core_keywords:
        kw_fixed = fix_skill_capitalization(kw)
        if kw_fixed.lower() not in [s.lower() for s in skills_list]:
            skills_list.append(kw_fixed)

    for kw in extra_list:
        kw_fixed = fix_skill_capitalization(kw)
        if kw_fixed.lower() not in [s.lower() for s in skills_list]:
            skills_list.append(kw_fixed)
    
    # Final validation of skills list
    skills_list = await filter_valid_skills(skills_list)

    body = await replace_skills_section(body, skills_list)
    log_event(f"âœ… [SKILLS] {len(skills_list)} validated skills")

    # 10) Merge back
    final_tex = _merge_tex(preamble, body)

    # 11) Coverage
    coverage = compute_coverage(final_tex, all_keywords)
    log_event(f"ðŸ“Š [COVERAGE] {coverage['ratio']:.1%}")
    
    # âœ¨ NEW: Log unique numbers used
    all_numbers_used = (
        list(_used_numbers_by_category['percent']) +
        list(_used_numbers_by_category['count']) +
        list(_used_numbers_by_category['metric']) +
        list(_used_numbers_by_category['comparison'])
    )
    log_event(f"ðŸŽ² [UNIQUE NUMBERS] Used: {all_numbers_used}")

    return final_tex, {
        "jd_info": jd_info,
        "company_core": company_core,
        "all_keywords": all_keywords,
        "coverage": coverage,
        "exp_used_keywords": list(exp_used_keywords),
        "skills_list": skills_list,
        "unique_numbers_used": all_numbers_used,  # âœ¨ NEW
    }


# ============================================================
# ðŸš€ API Endpoint - UPGRADED (COMPLETION)
# ============================================================

@router.post("/")
@router.post("/run")
@router.post("/submit")
async def optimize_endpoint(
    jd_text: str = Form(...),
    use_humanize: bool = Form(False),  # Parameter kept for API compatibility but ignored
    base_resume_tex: Optional[UploadFile] = File(None),
    extra_keywords: Optional[str] = Form(None),
):
    try:
        # HUMANIZE IS COMPLETELY DISABLED - ignore the parameter
        _ = use_humanize  # Explicitly ignore

        jd_text = (jd_text or "").strip()
        if not jd_text:
            raise HTTPException(status_code=400, detail="jd_text is required.")

        # Load base resume
        raw_tex = ""
        if base_resume_tex is not None:
            tex_bytes = await base_resume_tex.read()
            if tex_bytes:
                tex = tex_bytes.decode("utf-8", errors="ignore")
                raw_tex = secure_tex_input(base_resume_tex.filename or "upload.tex", tex)

        if not raw_tex:
            default_path = getattr(config, "DEFAULT_BASE_RESUME", None)
            if isinstance(default_path, (str, bytes)):
                default_path = Path(default_path)
            if not default_path or not isinstance(default_path, Path) or not default_path.exists():
                raise HTTPException(status_code=500, detail="Default base resume not found")
            raw_tex = default_path.read_text(encoding="utf-8")
            log_event(f"ðŸ“„ Using default base: {default_path}")

        target_company, target_role = await extract_company_role(jd_text)

        optimized_tex, info = await optimize_resume(
            raw_tex,
            jd_text,
            target_company=target_company,
            target_role=target_role,
            extra_keywords=extra_keywords,
        )

        safe_company = safe_filename(target_company)
        safe_role = safe_filename(target_role)

        # Compile OPTIMIZED PDF
        cur_tex = optimized_tex
        final_tex = render_final_tex(cur_tex)

        try:
            pdf_bytes_optimized = compile_latex_safely(final_tex)
            if not pdf_bytes_optimized:
                debug_path = Path(f"/tmp/debug_failed_{safe_company}_{safe_role}.tex")
                debug_path.write_text(final_tex, encoding="utf-8")
                raise HTTPException(status_code=500, detail="LaTeX compilation failed.")
        except HTTPException:
            raise
        except Exception as e:
            debug_path = Path(f"/tmp/debug_failed_{safe_company}_{safe_role}.tex")
            debug_path.write_text(final_tex, encoding="utf-8")
            raise HTTPException(status_code=500, detail=f"LaTeX compilation failed: {str(e)}")

        # Trim if needed
        cur_pdf_bytes = pdf_bytes_optimized
        pages = _pdf_page_count(cur_pdf_bytes)
        trim_count = 0
        MAX_TRIMS = 50

        while pages > 1 and trim_count < MAX_TRIMS:
            cur_tex, removed = remove_one_achievement_bullet(cur_tex)
            if not removed:
                cur_tex, removed = remove_last_bullet_from_sections(cur_tex, ("Projects", "Experience"))
            if not removed:
                break
            trim_count += 1
            final_tex = render_final_tex(cur_tex)
            cur_pdf_bytes = compile_latex_safely(final_tex)
            pages = _pdf_page_count(cur_pdf_bytes)

        optimized_tex_final = cur_tex
        pdf_bytes_optimized = cur_pdf_bytes

        coverage = info["coverage"]

        # Save files
        paths = build_output_paths(target_company, target_role)
        opt_path = paths["optimized"]
        saved_paths: List[str] = []

        if pdf_bytes_optimized:
            opt_path.parent.mkdir(parents=True, exist_ok=True)
            opt_path.write_bytes(pdf_bytes_optimized)
            saved_paths.append(str(opt_path))
            log_event(f"ðŸ’¾ [SAVE] Optimized â†’ {opt_path}")

        # âœ¨ UPGRADED: Return includes unique numbers used
        return JSONResponse({
            "company_name": target_company,
            "role": target_role,
            "eligibility": {
                "score": coverage["ratio"],
                "present": coverage["present"],
                "missing": coverage["missing"],
                "total": coverage["total"],
                "verdict": "Strong fit" if coverage["ratio"] >= 0.7 else "Good fit" if coverage["ratio"] >= 0.5 else "Needs improvement",
            },
            "company_core": info.get("company_core", {}),
            "optimized": {
                "tex": render_final_tex(optimized_tex_final),
                "pdf_b64": base64.b64encode(pdf_bytes_optimized or b"").decode("ascii"),
                "filename": str(opt_path) if pdf_bytes_optimized else "",
            },
            # Humanized fields kept for API compatibility but empty
            "humanized": {
                "tex": "",
                "pdf_b64": "",
                "filename": "",
            },
            "tex_string": render_final_tex(optimized_tex_final),
            "pdf_base64": base64.b64encode(pdf_bytes_optimized or b"").decode("ascii"),
            "pdf_base64_humanized": None,
            "saved_paths": saved_paths,
            "coverage_ratio": coverage["ratio"],
            "coverage_present": coverage["present"],
            "coverage_missing": coverage["missing"],
            "coverage_history": [],
            "did_humanize": False,  # Always False now
            "extra_keywords": info.get("jd_info", {}).get("extra_keywords", []),
            "skills_list": info.get("skills_list", []),
            "unique_numbers_used": info.get("unique_numbers_used", []),  # âœ¨ NEW: Report unique numbers
        })

    except Exception as e:
        log_event(f"ðŸ’¥ [PIPELINE] Failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))-e 


-e # ===== FILE: ./api/models_router.py =====

# ============================================================
#  ASTRA v2.1.2 â€” models_router.py
#  Exposes model catalogs + pricing for the frontend picker.
#  Reads from backend.core.config (AVAILABLE_MODELS, MODEL_PRICING, etc.)
# ============================================================

from __future__ import annotations

from typing import Dict, Any, List
from fastapi import APIRouter, HTTPException

from backend.core import config

router = APIRouter(prefix="/api/models", tags=["models"])


def _providers() -> List[str]:
    """Stable, sorted provider list for deterministic UI rendering."""
    return sorted(getattr(config, "AVAILABLE_MODELS", {}).keys())


def _available() -> Dict[str, Any]:
    """Provider -> list of models or modes."""
    return getattr(config, "AVAILABLE_MODELS", {})


def _pricing() -> Dict[str, Any]:
    """Provider -> pricing dict."""
    return getattr(config, "MODEL_PRICING", {})


def _aliases() -> Dict[str, str]:
    """Optional alias map (human label -> model id)."""
    return getattr(config, "MODEL_ALIASES", {})


@router.get("")
async def list_models():
    """
    Aggregate endpoint consumed by the frontend to render model pickers.
    """
    return {
        "default_model": getattr(config, "DEFAULT_MODEL", ""),
        "providers": _providers(),
        "available": _available(),
        "pricing": _pricing(),
        "aliases": _aliases(),  # safe even if empty
        "version": config.APP_VERSION,
    }


@router.get("/openai")
async def list_openai():
    """
    Return only OpenAI models and their pricing.
    """
    available = _available().get("openai", [])
    pricing = _pricing().get("openai", {})
    return {
        "provider": "openai",
        "models": available,
        "pricing": pricing,
        "default": getattr(config, "DEFAULT_MODEL", ""),
        "aliases": _aliases(),
        "version": config.APP_VERSION,
    }


@router.get("/aihumanize")
async def list_aihumanize():
    """
    Return AIHumanize modes (styles/modes, not token-metered models)
    and the display pricing/plans info if present.
    """
    available = _available().get("aihumanize", [])
    pricing = _pricing().get("aihumanize", {})
    return {
        "provider": "aihumanize",
        "modes": available,
        "pricing": pricing,  # e.g. {"modes":[...], "plans": {...}, "unit": "subscription"}
        "version": config.APP_VERSION,
    }


@router.get("/provider/{name}")
async def list_by_provider(name: str):
    """
    Generic provider fetch. Helpful for future providers.
    """
    key = name.lower().strip()
    available = _available()
    pricing = _pricing()

    if key not in available:
        raise HTTPException(status_code=404, detail=f"Provider '{key}' not found")

    return {
        "provider": key,
        "available": available.get(key, []),
        "pricing": pricing.get(key, {}),
        "version": config.APP_VERSION,
    }


@router.get("/pricing")
async def pricing_only():
    """
    Raw pricing object for UI tables.
    """
    return {
        "pricing": _pricing(),
        "version": config.APP_VERSION,
    }


@router.get("/aliases")
async def aliases_only():
    """
    Optional alias map (human label -> model id).
    """
    return {
        "aliases": _aliases(),
        "version": config.APP_VERSION,
    }
-e 


-e # ===== FILE: ./api/mastermind.py =====

"""
============================================================
 HIREX v2.1.0 â€” mastermind.py
 ------------------------------------------------------------
 MasterMind AI Assistant API
 â€¢ Context-aware reasoning and Q&A engine
 â€¢ Supports multi-turn sessions (filesystem store)
 â€¢ Integrates cleanly with SuperHuman/Talk modules
 â€¢ Persona, tone, and model controls

 Author: Sri Akash Kadali
============================================================
"""

from __future__ import annotations

import json
import os
import time
import uuid
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from fastapi import APIRouter, Form, HTTPException, Query
from fastapi.responses import JSONResponse
from openai import AsyncOpenAI

from backend.core import config
from backend.core.utils import log_event
from backend.core.security import secure_tex_input

router = APIRouter(prefix="/api/mastermind", tags=["mastermind"])
openai_client = AsyncOpenAI(api_key=config.OPENAI_API_KEY)

# ---------------------------------------------
# Defaults
# ---------------------------------------------
DEFAULT_MODEL = getattr(config, "MASTERMINDS_MODEL", getattr(config, "DEFAULT_MODEL", "gpt-4o-mini"))
STORE_DIR: Path = Path(getattr(config, "MASTERMINDS_PATH", (Path("data") / "mastermind_sessions")))
STORE_DIR.mkdir(parents=True, exist_ok=True)

# ============================================================
# ðŸ—‚ Filesystem session store (fallback-safe)
# ============================================================

@dataclass
class Session:
    id: str
    meta: Dict[str, Any]
    messages: List[Dict[str, str]]
    created_at: str
    updated_at: str

def _session_path(session_id: str) -> Path:
    return STORE_DIR / f"{session_id}.json"

def _new_session_id() -> str:
    return f"mm_{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}_{uuid.uuid4().hex[:6]}"

def _read_json(path: Path) -> Optional[Dict[str, Any]]:
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return None

def start_session(meta: Dict[str, Any]) -> Dict[str, Any]:
    sid = _new_session_id()
    now = datetime.utcnow().isoformat()
    sess = Session(id=sid, meta=meta or {}, messages=[], created_at=now, updated_at=now)
    _session_path(sid).write_text(json.dumps(asdict(sess), ensure_ascii=False, indent=2), encoding="utf-8")
    return asdict(sess)

def load_session(session_id: str) -> Optional[Dict[str, Any]]:
    p = _session_path(session_id)
    return _read_json(p)

def append_message(session_id: str, msg: Dict[str, str]) -> Dict[str, Any]:
    p = _session_path(session_id)
    data = _read_json(p) or {"id": session_id, "meta": {}, "messages": [], "created_at": datetime.utcnow().isoformat()}
    data.setdefault("messages", []).append(msg)
    data["updated_at"] = datetime.utcnow().isoformat()
    p.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    return data

def list_sessions() -> List[Dict[str, Any]]:
    files = sorted(STORE_DIR.glob("*.json"), key=lambda x: x.stat().st_mtime, reverse=True)
    out: List[Dict[str, Any]] = []
    for f in files:
        data = _read_json(f)
        if not data:
            continue
        out.append({
            "id": data.get("id"),
            "meta": data.get("meta", {}),
            "created_at": data.get("created_at"),
            "updated_at": data.get("updated_at"),
            "message_count": len(data.get("messages", [])),
        })
    return out

# ============================================================
# ðŸ§  Utility: truncate long history by chars
# ============================================================
def _trim_messages(msgs: List[Dict[str, str]], max_chars: int = 9000) -> List[Dict[str, str]]:
    """
    Keep only the latest messages up to max_chars (on content),
    preserving order, to control context size.
    """
    joined = ""
    kept: List[Dict[str, str]] = []
    for m in reversed(msgs):
        text = str(m.get("content", "") or "")
        if len(joined) + len(text) > max_chars:
            break
        kept.insert(0, m)
        joined += text
    return kept

def _resp_text(resp) -> str:
    """Robust extraction for OpenAI Responses API output."""
    try:
        t = getattr(resp, "output_text", None)
        if t:
            return str(t).strip()
    except Exception:
        pass
    try:
        return str(resp.output[0].content[0].text).strip()
    except Exception:
        return ""


# ============================================================
# ðŸš€ Endpoint: Start a new MasterMind session
# ============================================================
@router.post("/start")
async def start_session_api(
    persona: str = Form("General"),
    model: str = Form(DEFAULT_MODEL),
    purpose: str = Form("interactive reasoning"),
):
    if not config.OPENAI_API_KEY:
        raise HTTPException(status_code=400, detail="OPENAI_API_KEY missing in environment.")
    meta = {"persona": persona, "model": model, "purpose": purpose}
    data = start_session(meta)
    log_event("mastermind_session_started", {"persona": persona, "model": model})
    return JSONResponse({"session": data})


# ============================================================
# ðŸ§© Endpoint: Continue conversation / respond
# ============================================================
@router.post("/chat")
async def mastermind_chat(
    session_id: str = Form(...),
    prompt: str = Form(...),
    tone: str = Form("balanced"),
    model: str = Form(DEFAULT_MODEL),
    persona: str = Form("General"),
    temperature: float = Form(0.6),
    max_ctx_chars: int = Form(9000),
):
    if not config.OPENAI_API_KEY:
        raise HTTPException(status_code=400, detail="OPENAI_API_KEY missing in environment.")

    # 1ï¸âƒ£ Load or initialize session
    data = load_session(session_id)
    if not data:
        data = start_session({"persona": persona, "model": model})

    history: List[Dict[str, str]] = _trim_messages(data.get("messages", []), max_chars=int(max_ctx_chars))

    # 2ï¸âƒ£ Build AI prompt context
    system_prompt = (
        f"You are MasterMind â€” an intelligent, concise reasoning assistant inside HIREX. "
        f"You adopt the persona of '{persona}' and respond in a {tone} tone. "
        "Answer clearly and practically, focusing on career, resumes, job search, or technical reasoning. "
        "Keep answers compact and precise. Markdown allowed. Avoid repetition."
    )

    messages = [{"role": "system", "content": system_prompt}, *history, {"role": "user", "content": prompt}]

    # 3ï¸âƒ£ Store user message immediately
    append_message(session_id, {"role": "user", "content": prompt})

    # 4ï¸âƒ£ Query the model
    try:
        resp = await openai_client.responses.create(
            model=model,
            input=messages,
            temperature=float(temperature),
            max_output_tokens=800,
        )
        reply_text = _resp_text(resp) or "No response."
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"LLM request failed: {e}")

    # 5ï¸âƒ£ Sanitize for LaTeX safety
    safe_reply = secure_tex_input(reply_text)

    # 6ï¸âƒ£ Append assistant reply
    append_message(session_id, {"role": "assistant", "content": safe_reply})

    # 7ï¸âƒ£ Log event
    log_event(
        "mastermind_chat",
        {
            "session_id": session_id,
            "persona": persona,
            "tone": tone,
            "model": model,
            "chars": len(reply_text),
        },
    )

    return JSONResponse(
        {
            "reply": safe_reply,
            "persona": persona,
            "tone": tone,
            "model": model,
            "timestamp": datetime.utcnow().isoformat(),
        }
    )


# ============================================================
# ðŸ“œ Endpoint: Retrieve session history
# ============================================================
@router.get("/history")
async def get_session_history(session_id: str = Query(..., description="MasterMind session id")):
    """Fetch conversation messages for a given session."""
    data = load_session(session_id)
    if not data:
        raise HTTPException(status_code=404, detail="Session not found")
    return {"session": data}


# ============================================================
# ðŸ—‚ï¸ Endpoint: List all sessions
# ============================================================
@router.get("/sessions")
async def list_sessions_api():
    """List all MasterMind sessions with metadata."""
    return {"sessions": list_sessions()}


# ============================================================
# ðŸ§¹ Endpoint: Reset / delete a session
# ============================================================
@router.delete("/session")
async def delete_session_api(session_id: str = Query(..., description="MasterMind session id")):
    """Delete a specific session JSON file."""
    p = _session_path(session_id)
    if not p.exists():
        raise HTTPException(status_code=404, detail="Session not found")
    try:
        p.unlink()
        log_event("mastermind_session_deleted", {"id": session_id})
        return {"deleted": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Delete failed: {e}")
-e 


-e # ===== FILE: ./api/utils_router.py =====

# ============================================================
#  ASTRA v2.1.2 â€” Utility & Diagnostics API (FINAL)
#  ------------------------------------------------------------
#  Endpoints:
#   â€¢ Health-ish ping / version / safe config subset
#   â€¢ Logging (frontend analytics)
#   â€¢ Text helpers (escape/unescape)
#   â€¢ Base64 encode/decode utilities
#   â€¢ Safe filename & slug helpers
#   â€¢ Recent Contexts (deduped per Company__Role)
#   â€¢ History + status dashboard support
#  Author: Sri Akash Kadali
# ============================================================

from __future__ import annotations

import base64
import json
import re
import platform
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from fastapi import APIRouter, Form, HTTPException, Query

from backend.core import config
from backend.core.utils import log_event, safe_filename
from backend.core.security import secure_tex_input

router = APIRouter(prefix="/api/utils", tags=["utils"])

CONTEXT_DIR: Path = config.get_contexts_dir()
LOG_PATH: Path = Path(config.LOG_PATH)  # use configured path only

# ============================================================
# âš™ï¸ 1) PING / VERSION / CONFIG
# ============================================================
@router.get("/ping")
async def ping():
    """Lightweight liveness probe (distinct from /health)."""
    return {
        "status": "ok",
        "service": "ASTRA Core API",
        "time": datetime.utcnow().isoformat() + "Z",
        "platform": platform.system(),
        "python": platform.python_version(),
    }


@router.get("/version")
async def get_version():
    """Return the current ASTRA version and model defaults."""
    return {
        "version": config.APP_VERSION,
        "default_model": getattr(config, "DEFAULT_MODEL", "gpt-4o-mini"),
        "talk_summary_model": getattr(config, "TALK_SUMMARY_MODEL", "gpt-4o-mini"),
        "talk_answer_model": getattr(
            config, "TALK_ANSWER_MODEL", getattr(config, "DEFAULT_MODEL", "gpt-4o-mini")
        ),
        "superhuman_local": getattr(config, "SUPERHUMAN_LOCAL_ENABLED", True),
        "build_time": datetime.utcnow().isoformat() + "Z",
    }


@router.get("/config")
async def get_config():
    """Expose a safe subset of configuration variables for frontend diagnostics."""
    safe_keys = [
        "APP_VERSION",
        "DEFAULT_MODEL",
        "TALK_SUMMARY_MODEL",
        "TALK_ANSWER_MODEL",
        "SUPERHUMAN_LOCAL_ENABLED",
        "BASE_COVERLETTER_PATH",
        "MASTERMINDS_PATH",
        "LOG_PATH",
        "HISTORY_PATH",
        "API_BASE_URL",
    ]
    safe_data: Dict[str, Any] = {}
    for k in safe_keys:
        v = getattr(config, k, None)
        safe_data[k] = str(v) if isinstance(v, Path) else v
    return {"config": safe_data}

# ============================================================
# ðŸ§¾ 2) FRONTEND LOGGING & ANALYTICS
# ============================================================
@router.post("/log")
async def log_frontend_event(
    msg: str = Form(...),
    page: str = Form("unknown"),
    version: str = Form("unknown"),
    origin: str = Form("client"),
    level: str = Form("info"),
):
    """Receives debug or analytic events from the frontend (UI telemetry)."""
    meta = {
        "msg": msg,
        "page": page,
        "version": version,
        "origin": origin,
        "level": level,
        "timestamp": datetime.utcnow().isoformat() + "Z",
    }
    log_event("frontend_log", meta)
    return {"logged": True, "time": meta["timestamp"]}

# ============================================================
# ðŸ§© 3) TEXT UTILITIES
# ============================================================
@router.post("/escape")
async def escape_latex(text: str = Form(...)):
    """Return LaTeX-safe escaped string."""
    try:
        escaped = secure_tex_input(text)
        return {"escaped": escaped}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Escape failed: {e}") from e


@router.post("/unescape")
async def unescape_latex(text: str = Form(...)):
    """Reverse minimal LaTeX escapes for readability."""
    try:
        unescaped = (
            text.replace(r"\#", "#")
            .replace(r"\%", "%")
            .replace(r"\$", "$")
            .replace(r"\&", "&")
            .replace(r"\_", "_")
            .replace(r"\{", "{")
            .replace(r"\}", "}")
        )
        return {"unescaped": unescaped}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Unescape failed: {e}") from e

# ============================================================
# ðŸ“¦ 4) ENCODING / DECODING HELPERS
# ============================================================
@router.post("/b64encode")
async def b64encode_data(raw: str = Form(...)):
    """Base64 encode a plain string."""
    try:
        encoded = base64.b64encode(raw.encode("utf-8")).decode("utf-8")
        return {"base64": encoded, "len": len(encoded)}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Encode failed: {e}") from e


@router.post("/b64decode")
async def b64decode_data(encoded: str = Form(...)):
    """Base64 decode a string."""
    try:
        decoded = base64.b64decode(encoded.encode("utf-8")).decode("utf-8", errors="ignore")
        return {"decoded": decoded, "len": len(decoded)}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Decode failed: {e}") from e

# ============================================================
# ðŸ—‚ï¸ 5) FILENAME + SANITIZATION HELPERS
# ============================================================
@router.post("/safe_filename")
async def make_safe_filename(name: str = Form(...)):
    """Return a filesystem-safe version of the given filename."""
    safe = safe_filename(name)
    return {"input": name, "safe_name": safe}


@router.post("/slugify")
async def slugify_string(name: str = Form(...)):
    """Return a lowercase slugified string safe for URLs or filenames."""
    slug = re.sub(r"[^a-zA-Z0-9]+", "-", name.strip().lower()).strip("-")
    return {"slug": slug}

# ============================================================
# ðŸ§­ 6) RECENT CONTEXTS (deduped per Company__Role)
# ============================================================
def _updated_at(d: Dict[str, Any], default_ts: float) -> float:
    try:
        ts_raw = d.get("updated_at") or d.get("saved_at") or ""
        if isinstance(ts_raw, str):
            ts = ts_raw.rstrip("Z")
            if ts:
                return datetime.fromisoformat(ts).timestamp()
    except Exception:
        pass
    return default_ts


def _coerce_key(d: Dict[str, Any], p: Optional[Path]) -> str:
    if d.get("key"):
        return str(d["key"]).strip()
    c, r = (d.get("company") or "").strip(), (d.get("role") or "").strip()
    if c and r:
        return f"{safe_filename(c)}__{safe_filename(r)}"
    return p.stem if p else ""


def _compact_meta(d: Dict[str, Any], key: str) -> Dict[str, Any]:
    return {
        "key": key,
        "title": d.get("title_for_memory") or d.get("title") or f"{d.get('company','')} â€” {d.get('role','')}",
        "company": d.get("company"),
        "role": d.get("role"),
        "updated_at": d.get("updated_at") or d.get("saved_at"),
        "has_optimized": bool(((d.get("optimized") or {}).get("tex")) or d.get("resume_tex")),
        "has_humanized": bool(((d.get("humanized") or {}).get("tex")) or d.get("humanized_tex")),
        "has_cover_letter": bool((d.get("cover_letter") or {}).get("tex")),
    }


@router.get("/recent")
async def recent_contexts(
    limit: int = Query(50, ge=1, le=500),
    dedupe: bool = Query(True, description="Collapse multiple files to the latest per (Company__Role)"),
):
    """
    List recent JD/resume contexts saved by the app.
    Mirrors context_store's behavior so frontend pages (Talk, Dashboard)
    can render a clean, de-duplicated 'ðŸ“œ JD + Resume History'.
    """
    if not CONTEXT_DIR.exists():
        return {"items": []}

    entries: List[Tuple[str, Path, Dict[str, Any], float]] = []
    for p in CONTEXT_DIR.glob("*.json"):
        try:
            data = json.loads(p.read_text(encoding="utf-8"))
        except Exception:
            data = {}
        key = _coerce_key(data, p)
        ts = _updated_at(data, p.stat().st_mtime)
        entries.append((key, p, data, ts))

    if dedupe:
        # choose the single newest per key
        latest_by_key: Dict[str, Tuple[Path, Dict[str, Any], float]] = {}
        for key, p, d, ts in entries:
            cur = latest_by_key.get(key)
            if (cur is None) or (ts > cur[2]):
                latest_by_key[key] = (p, d, ts)
        rows = sorted(latest_by_key.items(), key=lambda kv: kv[1][2], reverse=True)[:limit]
        items = [_compact_meta(d, _coerce_key(d, p)) for (_k, (p, d, _)) in rows]
    else:
        rows2 = sorted(entries, key=lambda t: t[3], reverse=True)[:limit]
        items = [_compact_meta(d, _coerce_key(d, p)) for (_k, p, d, _ts) in rows2]

    return {"items": items}

# ============================================================
# ðŸ§­ 7) HISTORY / LOG RETRIEVAL
# ============================================================
def _read_jsonl(path: Path, limit: int) -> List[Dict[str, Any]]:
    if not path.exists():
        return []
    try:
        with open(path, "r", encoding="utf-8") as f:
            lines = f.readlines()[-limit:]
        out: List[Dict[str, Any]] = []
        for line in reversed(lines):
            try:
                obj = json.loads(line)
                if isinstance(obj, dict):
                    out.append(obj)
            except Exception:
                continue
        return out
    except Exception:
        return []


@router.get("/history")
async def get_history(limit: int = Query(100, ge=1, le=1000)):
    """Return the most recent event logs for diagnostics or dashboard."""
    events = _read_jsonl(LOG_PATH, limit)
    return {"count": len(events), "events": events}

# ============================================================
# ðŸ§  8) SYSTEM STATUS SUMMARY (Mini Dashboard)
# ============================================================
@router.get("/status")
async def get_status():
    """
    Lightweight system snapshot used by the dashboard sidebar.
    Provides event totals, last log timestamp, and environment details.
    """
    total, last_event = 0, None

    if LOG_PATH.exists():
        try:
            with open(LOG_PATH, "r", encoding="utf-8") as f:
                lines = f.readlines()
                total = len(lines)
                if lines:
                    try:
                        last_event = json.loads(lines[-1])
                    except Exception:
                        last_event = None
        except Exception:
            last_event = None

    return {
        "status": "ok",
        "total_events": total,
        "last_event": last_event,
        "app_version": config.APP_VERSION,
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "platform": platform.system(),
    }

# ============================================================
# ðŸ§ª 9) SELF-TEST: ENCODE-DECODE ROUNDTRIP
# ============================================================
@router.post("/selftest")
async def self_test(text: str = Form(...)):
    """Perform a simple base64 encode-decode validation."""
    try:
        encoded = base64.b64encode(text.encode("utf-8")).decode("utf-8")
        decoded = base64.b64decode(encoded.encode("utf-8")).decode("utf-8")
        return {
            "input": text,
            "encoded": encoded[:50] + ("..." if len(encoded) > 50 else ""),
            "decoded_match": decoded == text,
            "timestamp": datetime.utcnow().isoformat() + "Z",
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Self-test failed: {e}") from e
-e 


-e # ===== FILE: ./api/latex_parse.py =====

"""
HIREX â€¢ api/latex_parse.py
Lightweight Resume Parser (Raw-Preserve Mode)
Extracts sections from LaTeX or text resumes with zero cleaning or normalization.
Also provides a safe (no-escape) cover-letter body injector with BODY anchors.

Purpose: Provide unaltered LaTeX/text blocks for AI-based optimization.
Author: Sri Akash Kadali
"""

from __future__ import annotations

import re
from typing import Dict, List, Any


# ============================================================
# âš™ï¸ Section Extraction Utilities
# ============================================================
def extract_section(tex: str, section_name: str) -> str:
    """
    Extracts raw LaTeX section content between \section{<section_name>}
    (or \section*{<section_name>}) and the next section, or a plaintext
    header line that looks like Title Case.

    No stripping or cleanup is applied.
    """
    # Accept \section or \section*, and a plain text header line
    pattern = (
        rf"(?:\\section\*?\{{{re.escape(section_name)}\}}"      # \section{Name} or \section*{Name}
        rf"|^(?:{re.escape(section_name)})\s*$)"                # or plain line "Name"
        r"(.*?)"                                                # capture content non-greedily
        r"(?=(?:\\section|\n[A-Z][A-Za-z ]+\n|$))"              # until next section/header or EOF
    )
    m = re.search(pattern, tex, flags=re.DOTALL | re.IGNORECASE | re.MULTILINE)
    return m.group(1) if m else ""


# ============================================================
# ðŸ§  Main Parser (No Cleaning, No Normalization)
# ============================================================
def parse_latex_resume(tex_content: str) -> Dict[str, Any]:
    """
    Parses a LaTeX or plain-text resume into structured JSON form.
    All text is preserved as-is (no trimming, reformatting, or escaping).

    Extracts:
      - Education
      - Skills
      - Experience
      - Projects
      - Achievements
    """
    tex = tex_content.replace("\r", "")

    education_block    = extract_section(tex, "Education")
    skills_block       = extract_section(tex, "Skills")
    experience_block   = extract_section(tex, "Experience")
    projects_block     = extract_section(tex, "Projects")
    achievements_block = extract_section(tex, "Achievements")

    return {
        "education": _extract_bullets(education_block) or _split_lines(education_block),
        "skills": _parse_skills(skills_block),
        "experience": _parse_experience(experience_block),
        "projects": _parse_experience(projects_block),
        "achievements": _extract_bullets(achievements_block) or _split_lines(achievements_block),
    }


# ============================================================
# ðŸ§© Helper Parsers (Preserve Original Text)
# ============================================================
def _split_lines(block: str) -> List[str]:
    """Split section into lines â€” keeps all original spacing and symbols."""
    return [ln for ln in (block or "").splitlines() if ln.strip()]


def _extract_bullets(section: str) -> List[str]:
    """Extract bullet lines without reformatting or cleanup."""
    if not section:
        return []
    # \item, \item[] â€¦, and plain bullets -, â€¢
    bullets = re.findall(r"\\item(?:\[[^\]]*\])?\s+(.*)", section)
    if not bullets:
        bullets = re.findall(r"^[\-\u2022]\s+(.*)$", section, flags=re.MULTILINE)  # - or â€¢
    return [b for b in bullets if str(b).strip()]


def _parse_experience(section: str) -> List[Dict[str, Any]]:
    """
    Extract Experience/Projects entries minimally.
    Preserves LaTeX formatting and avoids stripping or normalization.

    Supports common patterns:
      1) \textbf{Role} \hfill \textit{Company} \hfill Date
      2) \textbf{Company} \hfill \textit{Role} \hfill Date
      followed by an itemize block.
    """
    entries: List[Dict[str, Any]] = []
    if not section:
        return entries

    # Pattern 1: Role then Company
    pat_role_company = re.compile(
        r"\\textbf\{(?P<title>.*?)\}\s*\\hfill\s*(?:\\textit|\\emph)\{(?P<company>.*?)\}"
        r"(?:\s*\\hfill\s*(?P<date>[^\n]*))?"
        r"(?P<body>.*?)\\end\{itemize\}",
        flags=re.DOTALL,
    )

    # Pattern 2: Company then Role
    pat_company_role = re.compile(
        r"\\textbf\{(?P<company>.*?)\}\s*\\hfill\s*(?:\\textit|\\emph)\{(?P<title>.*?)\}"
        r"(?:\s*\\hfill\s*(?P<date>[^\n]*))?"
        r"(?P<body>.*?)\\end\{itemize\}",
        flags=re.DOTALL,
    )

    # Try roleâ†’company first; if none, try companyâ†’role
    matches = list(pat_role_company.finditer(section)) or list(pat_company_role.finditer(section))
    for m in matches:
        bullets = _extract_bullets(m.group("body"))
        entries.append({
            "company": m.group("company"),
            "title": m.group("title"),
            "date": (m.group("date") or "").strip(),
            "bullets": bullets,
        })

    if entries:
        return entries

    # Plain text fallback (preserves spacing)
    blocks = re.split(r"\n(?=[A-Z].*\d{4})", section)
    for block in blocks:
        lines = [ln for ln in block.splitlines() if ln.strip()]
        if not lines:
            continue

        header = lines[0]
        date_match = re.search(r"\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec|[A-Za-z]+)?\.?\s*\d{4}.*\d{4}\b", header)
        date = date_match.group(0) if date_match else ""

        title, company = "", ""
        if " at " in header:
            title, company = header.split(" at ", 1)
        elif " - " in header:
            parts = header.split(" - ", 1)
            title = parts[0]
            company = parts[1]

        bullets = [ln for ln in lines[1:] if not re.match(r"^[A-Z][A-Za-z ]+$", ln)]
        entries.append({
            "company": company or "Unknown",
            "title": title or "Role",
            "date": date,
            "bullets": bullets,
        })
    return entries


def _parse_skills(section: str) -> Dict[str, List[str]]:
    """Extracts Skills lines as-is (no lowercase, trimming, or formatting)."""
    if not section:
        return {}
    lines = [l for l in section.splitlines() if l.strip()]
    skills_dict: Dict[str, List[str]] = {}
    for line in lines:
        if ":" in line:
            key, val = line.split(":", 1)
            values = [v.strip() for v in val.split(",") if v.strip()]
            if values:
                skills_dict[key.strip()] = values
    return skills_dict


# ============================================================
# âœ‰ï¸ Cover-Letter Body Injector (No Escaping)
#  - Inserts body between BODY anchors if present
#  - Else injects just before \end{document}
#  - Strips accidental preamble/closing from body but does not escape/clean
# ============================================================
def inject_cover_body(base_tex: str, body_tex: str) -> str:
    if base_tex is None:
        base_tex = ""
    if body_tex is None:
        body_tex = ""

    # Strip preamble and closing from the body (keep raw content)
    body = re.sub(r"\\documentclass[\s\S]*?\\begin\{document\}", "", body_tex, flags=re.IGNORECASE)
    body = re.sub(r"\\end\{document\}\s*$", "", body, flags=re.IGNORECASE).strip()

    # Prefer explicit anchors
    anchor_rx = r"(%-+BODY-START-+%)(.*?)(%-+BODY-END-+%)"
    if re.search(anchor_rx, base_tex, flags=re.DOTALL):
        return re.sub(anchor_rx, lambda m: f"{m.group(1)}\n{body}\n{m.group(3)}", base_tex, flags=re.DOTALL)

    # Otherwise, inject right before \end{document}
    if re.search(r"\\end\{document\}\s*$", base_tex, flags=re.IGNORECASE):
        return re.sub(r"\\end\{document\}\s*$",
                      f"\n% (Auto-inserted by HIREX)\n{body}\n\\end{{document}}\n",
                      base_tex, flags=re.IGNORECASE)

    # Fallback: append a closing tag
    return base_tex.rstrip() + f"\n\n% (Auto-inserted by HIREX)\n{body}\n\\end{{document}}\n"


# ============================================================
# ðŸ§ª Local Test
# ============================================================
if __name__ == "__main__":
    sample_resume = r"""
    \documentclass{article}
    \begin{document}

    %-----------EDUCATION-----------
    \section{Education}
    University of Maryland, College Park, United States CGPA: 3.55/4
    Master of Science in Applied Machine Learning August 2024 - May 2026
    â€¢ Relevant Coursework:

    %-----------EXPERIENCE-----------
    \section{Experience}
    \textbf{Machine Learning Intern} \hfill \textit{IIT Indore} \hfill May 2023 â€“ Dec 2023
    \begin{itemize}
      \item Developed DeBERTa-based architecture for hate-speech detection.
      \item Improved accuracy using contrastive learning.
      \item Enhanced features with emotion embeddings.
    \end{itemize}

    \end{document}
    """

    from pprint import pprint
    pprint(parse_latex_resume(sample_resume))

    # Cover-letter injection quick check
    base = r"""
    \documentclass{article}
    \begin{document}
    Dear Hiring Manager,

    %-----------BODY-START-----------
    %-----------BODY-END-------------

    Sincerely,\\
    Your Name
    \end{document}
    """
    body = r"""\documentclass{article}\begin{document}
    This is my injected body. \LaTeX{} intact.
    \end{document}"""
    print("\n--- Injected Cover Letter ---")
    print(inject_cover_body(base, body))
-e 


-e # ===== FILE: ./api/humanize.py =====

"""
HIREX â€¢ api/humanize.py (v2.1.2)
Integrates with AIHumanize.io for tone-only rewriting of Experience & Project bullets.
Targets only \resumeItem{...} entries, with strong LaTeX sanitization to avoid
preamble duplication or document corruption. Concurrency + retry hardened.

Author: Sri Akash Kadali
"""

from __future__ import annotations

import os
import re
import json
import asyncio
from dataclasses import dataclass
from typing import List, Tuple, Optional, Dict, Any

import httpx
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field

from backend.core import config
from backend.core.utils import log_event
from backend.core.security import secure_tex_input


# ============================================================
# âš™ï¸ Configuration
# ============================================================

AIHUMANIZE_REWRITE_URL = "https://aihumanize.io/api/v1/rewrite"

# Prefer config-provided mappings/defaults (from core/config.py)
_AIH_MODE_ID: Dict[str, str] = getattr(
    config, "AIHUMANIZE_MODE_ID", {"quality": "0", "balance": "1", "enhanced": "2"}
)
_HUMANIZE_MODE_DEFAULT: str = str(getattr(config, "HUMANIZE_MODE_DEFAULT", "balance")).lower()
_HUMANIZE_DEFAULT_ON: bool = bool(getattr(config, "HUMANIZE_DEFAULT_ON", True))
_LOCAL_ENABLED: bool = bool(getattr(config, "SUPERHUMAN_LOCAL_ENABLED", False))

# Client limits & retries
MAX_CONCURRENT = int(os.getenv("AIHUMANIZE_MAX_CONCURRENT", "60"))
TIMEOUT_SEC = float(os.getenv("AIHUMANIZE_TIMEOUT_SEC", "2000.0"))
RETRIES = int(os.getenv("AIHUMANIZE_RETRIES", "2"))

# FastAPI router (optional for direct API usage)
router = APIRouter(prefix="/api/humanize", tags=["humanize"])


# ============================================================
# ðŸ§½ LaTeX Sanitizer
# ============================================================

_BAD_PREAMBLE_PATTERNS = [
    r"(?i)\\documentclass(\[[^\]]*\])?\{[^}]*\}",
    r"(?i)\\usepackage(\[[^\]]*\])?\{[^}]*\}",
    r"(?i)\\begin\{document\}",
    r"(?i)\\end\{document\}",
    r"(?i)\\(new|renew)command\*?\{[^}]*\}\{[^}]*\}",
    r"(?i)\\input\{[^}]*\}",
]
_FALLBACK_TAG_RE = re.compile(r"^\[LOCAL-FALLBACK:[^\]]+\]\s*", re.IGNORECASE)

def _escape_unescaped_percent(s: str) -> str:
    # Turn bare % into \% to avoid commenting out the remainder of the line
    return re.sub(r"(?<!\\)%", r"\\%", s)

def _strip_md_fences(s: str) -> str:
    return s.replace("```latex", "").replace("```", "")

def clean_humanized_text(text: str, *, latex_safe: bool = True) -> str:
    """
    Remove dangerous LaTeX preamble/commands and markdown fences.
    Strip any accidental fallback labels. Keep content intact.
    """
    cleaned = text or ""
    cleaned = _strip_md_fences(cleaned)
    cleaned = _FALLBACK_TAG_RE.sub("", cleaned)

    for pat in _BAD_PREAMBLE_PATTERNS:
        cleaned = re.sub(pat, "", cleaned)

    # Remove leading LaTeX comments or decorative headers commonly injected
    cleaned = re.sub(r"(?m)^\s*%.*$", "", cleaned)

    # Normalize whitespace
    cleaned = re.sub(r"[ \t]+", " ", cleaned)
    cleaned = re.sub(r"\n{3,}", "\n\n", cleaned).strip()

    # Escape stray %
    if latex_safe:
        cleaned = _escape_unescaped_percent(cleaned)
        cleaned = secure_tex_input(cleaned)

    # Final safety check: if we still see preamble markers, reject
    if re.search(r"\\documentclass|\\usepackage|\\begin\{document\}|\\end\{document\}", cleaned, re.I):
        log_event("humanize_sanitizer_reject", {"reason": "preamble_detected"})
        return ""

    return cleaned


# ============================================================
# ðŸ”Ž Bullet Extraction (brace-aware)
# ============================================================

@dataclass
class BulletSpan:
    start: int
    end: int
    content: str

def _find_resume_items(tex: str) -> List[BulletSpan]:
    """
    Find \resumeItem{...} ranges with a simple brace-depth scan,
    so nested braces within the bullet are tolerated.
    """
    key = r"\resumeItem{"
    spans: List[BulletSpan] = []
    i = 0
    n = len(tex)
    while i < n:
        j = tex.find(key, i)
        if j == -1:
            break
        k = j + len(key)  # content starts here
        depth = 1
        p = k
        while p < n and depth > 0:
            ch = tex[p]
            if ch == "{":
                depth += 1
            elif ch == "}":
                depth -= 1
            p += 1
        if depth == 0:
            content = tex[k : p - 1]
            spans.append(BulletSpan(start=k, end=p - 1, content=content))
            i = p
        else:
            # Unbalanced; bail
            break
    return spans


# ============================================================
# ðŸŒ AIHumanize Client
# ============================================================

def _resolve_mode_id(mode: str) -> str:
    m = (mode or "").lower().strip()
    if m in _AIH_MODE_ID:
        return _AIH_MODE_ID[m]
    # accept tone synonyms
    if m in {"formal", "academic", "quality"}:
        return _AIH_MODE_ID.get("quality", "0")
    if m in {"balanced", "confident", "balance"}:
        return _AIH_MODE_ID.get("balance", "1")
    if m in {"conversational", "enhanced"}:
        return _AIH_MODE_ID.get("enhanced", "2")
    return _AIH_MODE_ID.get(_HUMANIZE_MODE_DEFAULT, "1")

def _header_variants(key: str) -> List[Dict[str, str]]:
    base = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "User-Agent": "Mozilla/5.0",
    }
    key = (key or "").strip()
    return [
        dict(base, **{"Authorization": key}),
        dict(base, **{"Authorization": f"Bearer {key}"}),
        dict(base, **{"X-API-KEY": key}),
    ]

async def _rewrite_bullet(
    client: httpx.AsyncClient,
    bullet_text: str,
    idx: int,
    mode_id: str,
    mail: str,
) -> str:
    """
    Call AIHumanize for a single bullet with retry + sanitize.
    Preserves metrics and percent signs by design (post-sanitizer escapes).
    """
    payload = {"model": mode_id, "mail": mail, "data": bullet_text}

    for attempt in range(RETRIES + 1):
        for headers in _header_variants(config.HUMANIZE_API_KEY):
            try:
                r = await client.post(AIHUMANIZE_REWRITE_URL, headers=headers, json=payload)
                # try JSON parse; if invalid JSON, surface HTTP error
                try:
                    data = r.json()
                except json.JSONDecodeError:
                    r.raise_for_status()
                    raise HTTPException(status_code=502, detail="Humanize returned invalid JSON.")

                if isinstance(data, dict) and int(data.get("code", r.status_code)) == 200 and data.get("data"):
                    candidate = clean_humanized_text(str(data["data"]).strip(), latex_safe=True)
                    if candidate:
                        # Resume bullets should be one line; avoid trailing period
                        candidate = candidate.replace("\n", " ").strip().rstrip(".")
                        log_event("aihumanize_bullet_ok", {"idx": idx, "len": len(candidate), "attempt": attempt})
                        return candidate
                    else:
                        # unsafe â†’ revert to original
                        log_event("aihumanize_bullet_revert_unsafe", {"idx": idx, "attempt": attempt})
                        return bullet_text
                else:
                    # Unexpected shape or non-200 code; try next header/attempt
                    log_event("aihumanize_bad_response", {"idx": idx, "attempt": attempt, "resp": data})
            except Exception as e:
                log_event("aihumanize_bullet_error", {"idx": idx, "attempt": attempt, "error": str(e)})
        # exponential backoff between attempts
        await asyncio.sleep(0.5 * (2 ** attempt))

    log_event("aihumanize_bullet_fallback", {"idx": idx})
    return bullet_text


# ============================================================
# ðŸ§© Local (optional) tone-only stub â€” tagless and minimal
# ============================================================

def _local_tone_only(text: str) -> str:
    """
    Minimal, safe, tagless cleanup used only if SUPERHUMAN_LOCAL_ENABLED is True
    and remote Humanize is unavailable. Keeps numbers/metrics intact.
    """
    t = text or ""
    # normalize whitespace
    t = re.sub(r"[ \t]+", " ", t).strip()
    # tiny clarity nips (do not touch numbers, symbols)
    t = re.sub(r"\bu\b", "you", t, flags=re.IGNORECASE)
    t = re.sub(r"\bim\b", "I am", t, flags=re.IGNORECASE)
    # single line, no trailing period for bullets
    t = t.replace("\n", " ").rstrip(".")
    return clean_humanized_text(t, latex_safe=True)


# ============================================================
# ðŸ§  Public Core: Humanize all \resumeItem bullets
# ============================================================

async def humanize_resume_items(
    tex_content: str,
    mode: str = None,
    email: Optional[str] = None,
) -> Tuple[str, int, int]:
    """
    Humanize all \resumeItem{...} bullets concurrently.

    Returns:
        (new_tex, total_found, total_rewritten)
    """
    # Honor "Humanize always on" default; fail fast if disabled
    if not _HUMANIZE_DEFAULT_ON:
        raise RuntimeError("Humanize is disabled by configuration (HUMANIZE_DEFAULT_ON=false).")

    spans = _find_resume_items(tex_content or "")
    total_found = len(spans)
    if total_found == 0:
        log_event("aihumanize_no_bullets", {})
        return tex_content, 0, 0

    # Credentials
    has_creds = bool(config.HUMANIZE_API_KEY and config.HUMANIZE_MAIL)
    use_local = (not has_creds) and _LOCAL_ENABLED

    # Resolve mode and mail
    mode_id = _resolve_mode_id(mode or _HUMANIZE_MODE_DEFAULT)
    mail = (email or config.HUMANIZE_MAIL or "").strip()

    limits = httpx.Limits(max_keepalive_connections=MAX_CONCURRENT, max_connections=MAX_CONCURRENT)
    timeout = httpx.Timeout(TIMEOUT_SEC)
    sem = asyncio.Semaphore(MAX_CONCURRENT)

    rewritten_texts: List[str] = []

    if has_creds:
        async with httpx.AsyncClient(limits=limits, timeout=timeout, headers={"User-Agent": "Mozilla/5.0", "Accept": "application/json"}) as client:
            async def _task(idx: int, content: str) -> str:
                async with sem:
                    c = content.strip()
                    if not c:
                        return content
                    return await _rewrite_bullet(client, c, idx, mode_id, mail)

            rewritten_texts = await asyncio.gather(
                *[_task(i + 1, b.content) for i, b in enumerate(spans)], return_exceptions=False
            )
    elif use_local:
        # Local tagless cleanup per bullet
        rewritten_texts = [_local_tone_only(b.content) for b in spans]
    else:
        raise RuntimeError("HUMANIZE_API_KEY/HUMANIZE_MAIL missing and local fallback disabled.")

    # Rebuild the LaTeX safely by slicing with recorded spans
    out_parts: List[str] = []
    last = 0
    total_rewritten = 0
    for (span, new_txt) in zip(spans, rewritten_texts):
        out_parts.append(tex_content[last:span.start])
        safe_new = (new_txt or "").strip().rstrip(".")
        if safe_new != span.content.strip():
            total_rewritten += 1
        out_parts.append(safe_new)
        last = span.end
    out_parts.append(tex_content[last:])

    new_tex = "".join(out_parts)

    # Final safety: strip accidental preamble fragments and normalize whitespace
    for pat in _BAD_PREAMBLE_PATTERNS:
        new_tex = re.sub(pat, "", new_tex)
    new_tex = re.sub(r"\n{3,}", "\n\n", new_tex).strip()

    log_event("aihumanize_complete", {"found": total_found, "rewritten": total_rewritten, "mode": mode or _HUMANIZE_MODE_DEFAULT})
    return new_tex, total_found, total_rewritten


# ============================================================
# ðŸŒ FastAPI endpoints (optional, convenient for frontend)
# ============================================================

class BulletsReq(BaseModel):
    tex_content: str = Field(..., description="LaTeX content containing \\resumeItem{...} bullets.")
    mode: Optional[str] = Field(None, description="quality | balance | enhanced | synonyms accepted")
    email: Optional[str] = Field(None, description="Account email for AIHumanize (optional override).")

@router.post("/bullets")
async def api_humanize_bullets(req: BulletsReq):
    """
    Rewrites only \\resumeItem{...} bullets inside the provided LaTeX string.
    Returns sanitized LaTeX. Requires HUMANIZE_API_KEY/HUMANIZE_MAIL or enabled local fallback.
    """
    try:
        new_tex, found, rewritten = await humanize_resume_items(req.tex_content, mode=req.mode, email=req.email)
        return {
            "ok": True,
            "tex_content": new_tex,
            "found": found,
            "rewritten": rewritten,
            "mode": (req.mode or _HUMANIZE_MODE_DEFAULT),
        }
    except RuntimeError as e:
        raise HTTPException(status_code=503, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=502, detail=f"AIHumanize processing failed: {e}")


# ============================================================
# ðŸ§ª Local CLI test
# ============================================================

if __name__ == "__main__":
    async def _run():
        sample_tex = r"""
        \resumeItem{worked on python scripts for data processing}
        \resumeItem{helped team with docker deployments}
        \resumeItem{deployed 3 APIs with 99\% uptime}
        """
        try:
            out, found, rewritten = await humanize_resume_items(sample_tex, mode="balance")
            print("\n=== Found:", found, "Rewritten:", rewritten, "===\n")
            print(out)
        except Exception as e:
            print("Local test error:", e)

    asyncio.run(_run())
-e 


-e # ===== FILE: ./api/coverletter.py =====

# ============================================================
#  HIREX v3.2.0 â€” Authentic Cover Letter Generation
#  ------------------------------------------------------------
#  KEY UPGRADES:
#   â€¢ Genuine company-specific opening hooks
#   â€¢ NO academic mentions (GPA, graduation, coursework)
#   â€¢ Natural product knowledge signals
#   â€¢ Professional tone without hyperbole
#   â€¢ Authentic insider understanding
#   â€¢ No forced "recruiter-stopping" language
# ============================================================

from __future__ import annotations

import base64
import json
import re
import threading
import random
from datetime import datetime
from typing import Tuple, Optional, Dict, Any, List, Set

import httpx
from fastapi import APIRouter, Form, HTTPException
from fastapi.responses import JSONResponse
from openai import OpenAI

from backend.core import config
from backend.core.utils import log_event, safe_filename, ensure_dir
from backend.core.compiler import compile_latex_safely
from backend.core.security import secure_tex_input

try:
    from backend.api.render_tex import render_final_tex
except Exception:
    from api.render_tex import render_final_tex

try:
    from backend.api.latex_parse import inject_cover_body as _shared_inject
except Exception:
    try:
        from api.latex_parse import inject_cover_body as _shared_inject
    except Exception:
        _shared_inject = None

router = APIRouter(prefix="/api/coverletter", tags=["coverletter"])

_openai_lock = threading.Lock()
_openai_client: Optional[OpenAI] = None


def _get_openai_client() -> OpenAI:
    global _openai_client
    if _openai_client is not None:
        return _openai_client
    with _openai_lock:
        if _openai_client is None:
            _openai_client = OpenAI(api_key=config.OPENAI_API_KEY)
    return _openai_client


_DEFAULT_OAI_MODEL = "gpt-4o-mini"
_EXTRACT_MODEL = getattr(config, "COVERLETTER_EXTRACT_MODEL", None) or _DEFAULT_OAI_MODEL
_DRAFT_MODEL = getattr(config, "COVERLETTER_MODEL", None) or _DEFAULT_OAI_MODEL
_INTELLIGENCE_MODEL = "gpt-4o-mini"

_DISABLE_SHARED_INJECTOR = True


# ============================================================
# ðŸŽ¯ COMPANY-SPECIFIC HOOKS (Natural, not forced)
# ============================================================

COMPANY_KILLER_HOOKS = {
    "netflix": {
        "product_insights": [
            "Netflix's recommendation engine personalizing content for 230M+ subscribers demonstrates ML at scale",
            "The technical challenge of A/B testing across Netflix's entire product surface interests me",
            "Netflix's shift to an ad-supported tier while maintaining personalization quality represents an interesting ML challenge",
            "Netflix's work on streaming quality optimization shows strong technical execution"
        ],
        "insider_knowledge": [
            "Netflix's 'context not control' culture aligns with how I approach building systems",
            "The challenge of maintaining recommendation quality while expanding into new verticals is compelling",
            "Netflix's experimentation platform running thousands of tests simultaneously represents the scale I want to work at"
        ],
        "recent_moves": [
            "Netflix's expansion into gaming presents new personalization challenges",
            "The focus on sustainable growth through multiple revenue streams shows strategic thinking"
        ]
    },
    "google": {
        "product_insights": [
            "Google Search's integration of AI-generated summaries represents a significant infrastructure challenge",
            "The evolution from PageRank to modern ML-powered ranking systems is technically fascinating",
            "Gemini's integration across Google products demonstrates complex system design"
        ],
        "insider_knowledge": [
            "Google's 'launch and iterate' culture while maintaining reliability for billions resonates with me",
            "The technical rigor of Google's design doc culture influences how I approach architecture",
            "Google's commitment to responsible AI development aligns with my values"
        ],
        "recent_moves": [
            "Google's AI search integration shows strategic technical execution",
            "Cloud's growth trajectory competing with AWS is compelling"
        ]
    },
    "meta": {
        "product_insights": [
            "Meta's Feed ranking evolution from chronological to ML-driven shows recommendation systems at scale",
            "The technical challenge of Reels competing with different user intents is interesting",
            "Meta's integrity systems at billions-of-posts scale represent significant ML challenges"
        ],
        "insider_knowledge": [
            "Meta's 'Move Fast' culture balanced with responsibility for 3B+ users is compelling",
            "The PyTorch ecosystem Meta open-sourced has been valuable to my work",
            "Meta's AI-first strategy shows technical adaptability"
        ],
        "recent_moves": [
            "Threads' rapid growth demonstrated Meta's infrastructure capabilities",
            "Llama model releases show commitment to advancing the field"
        ]
    },
    "amazon": {
        "product_insights": [
            "Amazon's recommendation systems hiding sophisticated ML behind simple UX is elegant",
            "The optimization challenges of same-day delivery across millions of products is compelling",
            "AWS serving both startups and enterprises demonstrates strong platform design"
        ],
        "insider_knowledge": [
            "Amazon's 'working backwards' approach aligns with how I think about system design",
            "The two-pizza team structure enabling innovation pace is interesting",
            "Amazon's 'Dive Deep' principle matches my belief in understanding implementation details"
        ],
        "recent_moves": [
            "AWS Bedrock making foundation models accessible shows platform thinking",
            "Healthcare expansion opens new ML application areas"
        ]
    },
    "microsoft": {
        "product_insights": [
            "Copilot's integration across Microsoft 365 represents significant AI deployment at scale",
            "Azure's growth trajectory shows strong execution",
            "GitHub Copilot's accuracy improvements demonstrate ML iteration velocity"
        ],
        "insider_knowledge": [
            "Microsoft's 'growth mindset' transformation created an appealing culture",
            "The OpenAI partnership positioning Microsoft in AI leadership was strategic",
            "Microsoft's enterprise AI deployment represents unique challenges"
        ],
        "recent_moves": [
            "Copilot becoming unified across products shows ambitious vision",
            "Gaming expansion with AI opens new technical areas"
        ]
    },
    "apple": {
        "product_insights": [
            "Apple Intelligence running ML on-device while maintaining privacy is a compelling technical constraint",
            "The Neural Engine evolution shows long-term ML silicon investment",
            "Face ID working across conditions with zero cloud dependency is elegant engineering"
        ],
        "insider_knowledge": [
            "Apple's privacy-first ML approach aligns with my values around user trust",
            "Vertical integration enabling ML optimization from silicon to software is unique",
            "Apple's focused product philosophy resonates with my approach"
        ],
        "recent_moves": [
            "Vision Pro's spatial computing presents interesting ML challenges",
            "Apple Intelligence's quality-first rollout shows principled execution"
        ]
    },
    "stripe": {
        "product_insights": [
            "Stripe's API design became the standard for fintech APIs",
            "The fraud detection challenge of instant approval while blocking fraud is interesting ML",
            "Stripe Atlas shows infrastructure thinking beyond core payments"
        ],
        "insider_knowledge": [
            "Stripe's written culture where ideas win on merit appeals to me",
            "The 'increase GDP of the internet' mission is compelling",
            "Stripe's developer-first approach building products engineers love matches my values"
        ],
        "recent_moves": [
            "Embedded finance expansion broadens the problem space",
            "Revenue recognition products show end-to-end financial stack vision"
        ]
    },
    "airbnb": {
        "product_insights": [
            "Airbnb's search ranking balancing guest and host fairness is interesting multi-objective optimization",
            "Smart Pricing helping hosts while maintaining platform trust is elegant ML",
            "Trust and Safety at scale across millions of properties is compelling"
        ],
        "insider_knowledge": [
            "Airbnb's 'Belong Anywhere' mission resonates with me",
            "The design-driven culture producing better products is appealing",
            "Airbnb's transparent culture builds trust"
        ],
        "recent_moves": [
            "Experiences expansion diversifies the ML challenges",
            "AI trip planning hints at broader platform vision"
        ]
    },
    "uber": {
        "product_insights": [
            "Uber's marketplace balancing wait times and earnings in real-time is optimization at scale",
            "ETA prediction accuracy improvements show ML iteration",
            "Dynamic pricing balancing supply and demand combines economics and ML"
        ],
        "insider_knowledge": [
            "Uber's global-scale reliability during peak events shows strong infrastructure",
            "The transition to profitable operations required technical efficiency",
            "Uber's multi-modal future is a compelling platform play"
        ],
        "recent_moves": [
            "Advertising business represents new ML challenges",
            "Autonomous vehicle partnerships show forward thinking"
        ]
    },
    "linkedin": {
        "product_insights": [
            "LinkedIn's job matching at scale has real career impact",
            "Feed ranking balancing professional content with engagement is challenging",
            "Skills-based hiring replacing credentials is a worthy mission"
        ],
        "insider_knowledge": [
            "LinkedIn's 'Members First' philosophy is compelling",
            "The Economic Graph vision is ambitious",
            "LinkedIn Learning integration with skills gaps is interesting"
        ],
        "recent_moves": [
            "AI-powered job tools are changing recruiting",
            "Creator monetization expands the platform"
        ]
    },
    "spotify": {
        "product_insights": [
            "Discover Weekly's personalization is ML done well",
            "Audio ML challenges across music, podcasts, and audiobooks are interesting",
            "Collaborative filtering at 500M+ users is impressive scale"
        ],
        "insider_knowledge": [
            "Spotify's squad model balancing autonomy with coherence is good organizational design",
            "The artist-friendly stance while building sustainable business shows balance",
            "Data-informed but not data-driven culture leaves room for creativity"
        ],
        "recent_moves": [
            "AI DJ represents next evolution of personalization",
            "Audiobooks expansion diversifies content challenges"
        ]
    },
    "databricks": {
        "product_insights": [
            "The Lakehouse architecture is elegant technical vision",
            "MLflow becoming the standard shows successful open-source strategy",
            "Unity Catalog's data governance scope is ambitious"
        ],
        "insider_knowledge": [
            "Databricks' open-source DNA builds genuine community",
            "The 'data plus AI' positioning is clear differentiation",
            "Publishing research while building products is valuable"
        ],
        "recent_moves": [
            "Mosaic ML acquisition shows full AI stack vision",
            "Serverless compute reduces friction"
        ]
    },
    "snowflake": {
        "product_insights": [
            "Snowflake's consumption pricing aligns incentives well",
            "Data sharing without copying enables new business models",
            "Snowpark bringing code to data shows architectural thinking"
        ],
        "insider_knowledge": [
            "Snowflake's engineering excellence in performance is notable",
            "The Data Cloud vision is ambitious infrastructure",
            "Customer obsession reflected in NPS is cultural strength"
        ],
        "recent_moves": [
            "Native apps create interesting ecosystem",
            "AI/ML features show strategic expansion"
        ]
    }
}


def get_killer_hook(company: str, hook_type: str = "product_insights") -> str:
    """Get a company-specific opening hook."""
    company_lower = company.lower().strip()
    
    for key, hooks in COMPANY_KILLER_HOOKS.items():
        if key in company_lower or company_lower in key:
            hook_list = hooks.get(hook_type, hooks.get("product_insights", []))
            if hook_list:
                return random.choice(hook_list)
    
    return ""


# ============================================================
# ðŸ¢ DEEP COMPANY INTELLIGENCE DATABASE
# ============================================================

COMPANY_INTELLIGENCE = {
    "netflix": {
        "culture_keywords": ["Freedom & Responsibility", "context not control", "highly aligned loosely coupled", "keeper test", "candor"],
        "tech_focus": ["Recommender Systems", "Personalization", "A/B Testing at Scale", "Content Delivery", "Streaming Infrastructure"],
        "engineering_values": ["data-driven decisions", "experimentation culture", "ownership mentality", "impact over activity"],
        "recent_focus": ["gaming expansion", "ad-supported tier", "live events", "content efficiency"],
        "challenges": ["subscriber growth in mature markets", "content cost optimization", "competition from Disney+/HBO"],
        "insider_phrases": ["member experience", "title discovery", "personalization at scale", "streaming quality"],
        "hiring_priorities": ["ML infrastructure", "experimentation platforms", "content algorithms", "data pipelines"],
        "products_to_reference": ["recommendation engine", "A/B testing platform", "streaming infrastructure", "content personalization"]
    },
    "google": {
        "culture_keywords": ["Googleyness", "think big", "user first", "10x thinking", "psychological safety"],
        "tech_focus": ["Scalability", "Distributed Systems", "AI/ML Infrastructure", "Search Quality", "Cloud Platform"],
        "engineering_values": ["code quality", "design docs", "peer review culture", "technical excellence"],
        "recent_focus": ["Gemini AI", "Cloud growth", "Search AI integration", "Pixel ecosystem"],
        "challenges": ["AI competition with OpenAI/Microsoft", "advertising revenue pressure", "regulatory scrutiny"],
        "insider_phrases": ["Noogler", "OKRs", "launch and iterate", "10x improvement"],
        "hiring_priorities": ["AI/ML", "Cloud infrastructure", "Privacy engineering", "Mobile development"],
        "products_to_reference": ["Search", "Gemini", "Cloud Platform", "YouTube", "Android"]
    },
    "meta": {
        "culture_keywords": ["Move Fast", "Be Bold", "Focus on Impact", "Be Open", "Build Social Value"],
        "tech_focus": ["Social Graph", "Ranking Systems", "AR/VR", "Messaging Infrastructure", "Ads Optimization"],
        "engineering_values": ["ship early ship often", "hackathons", "bootcamp culture", "impact metrics"],
        "recent_focus": ["AI assistants", "Threads growth", "Reels monetization", "Llama models"],
        "challenges": ["privacy regulations", "TikTok competition", "metaverse ROI questions"],
        "insider_phrases": ["family of apps", "integrity systems", "social impact", "meaningful connections"],
        "hiring_priorities": ["AI/ML", "Integrity/Safety", "Infrastructure", "AR/VR"],
        "products_to_reference": ["Instagram", "WhatsApp", "Messenger", "Threads", "Llama"]
    },
    "amazon": {
        "culture_keywords": ["Customer Obsession", "Ownership", "Bias for Action", "Dive Deep", "Deliver Results"],
        "tech_focus": ["AWS Services", "Supply Chain ML", "Alexa/Voice", "Retail Optimization", "Logistics"],
        "engineering_values": ["working backwards", "two-pizza teams", "operational excellence", "frugality"],
        "recent_focus": ["AWS AI services", "same-day delivery", "healthcare expansion", "advertising growth"],
        "challenges": ["labor relations", "AWS competition", "retail margins"],
        "insider_phrases": ["PR/FAQ", "6-pager", "bar raiser", "Day 1 mentality", "mechanisms"],
        "hiring_priorities": ["AWS", "ML/AI", "Supply chain", "Advertising"],
        "products_to_reference": ["AWS", "Prime", "Alexa", "One Medical", "Bedrock"]
    },
    "microsoft": {
        "culture_keywords": ["Growth Mindset", "Customer Obsessed", "Diverse and Inclusive", "One Microsoft"],
        "tech_focus": ["Azure Cloud", "Microsoft 365", "AI/Copilot", "Gaming/Xbox", "Developer Tools"],
        "engineering_values": ["learn-it-all not know-it-all", "customer empathy", "responsible AI"],
        "recent_focus": ["Copilot integration", "Azure OpenAI", "Gaming", "Teams platform"],
        "challenges": ["cloud competition with AWS", "AI integration", "gaming market share"],
        "insider_phrases": ["growth mindset", "customer zero", "inclusive design"],
        "hiring_priorities": ["AI/ML", "Azure", "Security", "Developer experience"],
        "products_to_reference": ["Copilot", "Azure", "GitHub", "Teams", "Xbox"]
    },
    "apple": {
        "culture_keywords": ["Think Different", "Simplicity", "Privacy as Human Right", "Excellence"],
        "tech_focus": ["On-Device ML", "Privacy-Preserving AI", "Hardware-Software Integration", "User Experience"],
        "engineering_values": ["attention to detail", "user privacy", "vertical integration", "craftsmanship"],
        "recent_focus": ["Vision Pro", "Apple Intelligence", "Services growth", "Sustainability"],
        "challenges": ["China market", "AI catch-up", "services growth"],
        "insider_phrases": ["DRI", "surprise and delight", "it just works"],
        "hiring_priorities": ["ML on-device", "Privacy engineering", "AR/VR", "Health tech"],
        "products_to_reference": ["iPhone", "Vision Pro", "Apple Intelligence", "Neural Engine"]
    },
    "stripe": {
        "culture_keywords": ["Users First", "Move with Urgency", "Think Rigorously", "Trust and Amplify"],
        "tech_focus": ["Payment Infrastructure", "Financial APIs", "Fraud Detection", "Developer Experience"],
        "engineering_values": ["write like you code", "rigor in thinking", "long-term orientation"],
        "recent_focus": ["Embedded finance", "Global expansion", "Revenue recognition"],
        "challenges": ["fintech competition", "regulatory complexity", "enterprise sales"],
        "insider_phrases": ["increase GDP of internet", "payment rails", "developer love"],
        "hiring_priorities": ["Infrastructure", "ML/Fraud", "Platform", "International"],
        "products_to_reference": ["Payments API", "Radar", "Atlas", "Connect", "Billing"]
    },
    "airbnb": {
        "culture_keywords": ["Belong Anywhere", "Champion the Mission", "Be a Host", "Embrace Adventure"],
        "tech_focus": ["Search & Ranking", "Pricing Algorithms", "Trust & Safety", "Payments"],
        "engineering_values": ["customer empathy", "design-driven", "data-informed"],
        "recent_focus": ["Experiences expansion", "Long-term stays", "AI trip planning"],
        "challenges": ["regulatory battles", "hotel competition", "host supply"],
        "insider_phrases": ["belonging", "host community", "guest journey"],
        "hiring_priorities": ["ML/Search", "Trust & Safety", "Payments", "Mobile"],
        "products_to_reference": ["Search ranking", "Smart Pricing", "Experiences", "AirCover"]
    },
    "uber": {
        "culture_keywords": ["Build Globally", "Celebrate Differences", "Act Like Owners", "Persevere"],
        "tech_focus": ["Marketplace Optimization", "ETA Prediction", "Route Optimization", "Fraud Detection"],
        "engineering_values": ["data-driven", "experimentation", "reliability at scale"],
        "recent_focus": ["Delivery growth", "Advertising", "Freight"],
        "challenges": ["driver supply", "profitability", "regulatory issues"],
        "insider_phrases": ["marketplace balance", "rider experience", "driver earnings"],
        "hiring_priorities": ["ML/Optimization", "Maps", "Marketplace", "Delivery"],
        "products_to_reference": ["Rides", "Eats", "Freight", "Advertising platform"]
    },
    "linkedin": {
        "culture_keywords": ["Members First", "Relationships Matter", "Be Open Honest Constructive", "Act Like Owner"],
        "tech_focus": ["Feed Ranking", "Job Matching", "Graph Systems", "Economic Graph"],
        "engineering_values": ["test and learn", "member value", "data-driven"],
        "recent_focus": ["AI features", "Creator economy", "Skills-based hiring"],
        "challenges": ["engagement growth", "premium conversion", "content quality"],
        "insider_phrases": ["economic graph", "member value", "professional identity"],
        "hiring_priorities": ["AI/ML", "Feed", "Search", "Infrastructure"],
        "products_to_reference": ["Feed", "Jobs", "Learning", "Sales Navigator"]
    },
    "spotify": {
        "culture_keywords": ["Innovative", "Collaborative", "Sincere", "Passionate", "Playful"],
        "tech_focus": ["Audio ML", "Personalization", "Content Delivery", "Creator Tools"],
        "engineering_values": ["squad model", "autonomous teams", "data-informed"],
        "recent_focus": ["Podcasts", "Audiobooks", "AI DJ", "Creator monetization"],
        "challenges": ["profitability", "music licensing costs", "podcast ROI"],
        "insider_phrases": ["Discover Weekly", "audio-first", "creator ecosystem"],
        "hiring_priorities": ["ML/Personalization", "Audio", "Ads", "Payments"],
        "products_to_reference": ["Discover Weekly", "AI DJ", "Wrapped", "Podcast platform"]
    },
    "databricks": {
        "culture_keywords": ["Customer Obsessed", "Unity", "Ownership", "Open Source First"],
        "tech_focus": ["Lakehouse", "Delta Lake", "MLflow", "Spark", "Data Engineering"],
        "engineering_values": ["open source contribution", "technical excellence", "customer impact"],
        "recent_focus": ["Unity Catalog", "Serverless", "AI/ML platform"],
        "challenges": ["Snowflake competition", "enterprise adoption"],
        "insider_phrases": ["Lakehouse", "data + AI", "open source"],
        "hiring_priorities": ["Platform", "ML/AI", "Security", "Enterprise"],
        "products_to_reference": ["Lakehouse", "Delta Lake", "MLflow", "Unity Catalog"]
    },
    "snowflake": {
        "culture_keywords": ["Put Customers First", "Integrity Always", "Think Big", "Be Excellent"],
        "tech_focus": ["Data Cloud", "Data Sharing", "Snowpark", "Data Marketplace"],
        "engineering_values": ["engineering excellence", "customer focus", "innovation"],
        "recent_focus": ["Snowpark", "Native apps", "AI/ML features"],
        "challenges": ["Databricks competition", "consumption concerns"],
        "insider_phrases": ["Data Cloud", "Snowpark", "data sharing economy"],
        "hiring_priorities": ["Platform", "ML/AI", "Security", "Performance"],
        "products_to_reference": ["Data Cloud", "Snowpark", "Marketplace", "Cortex"]
    }
}

DEFAULT_COMPANY_INTELLIGENCE = {
    "culture_keywords": ["innovation", "collaboration", "excellence", "customer focus"],
    "tech_focus": ["scalable systems", "data-driven decisions", "modern architecture"],
    "engineering_values": ["code quality", "team collaboration", "continuous learning"],
    "recent_focus": ["digital transformation", "AI/ML adoption", "cloud migration"],
    "challenges": ["scaling efficiently", "talent retention", "market competition"],
    "insider_phrases": [],
    "hiring_priorities": ["engineering", "product", "data"],
    "products_to_reference": []
}


def get_company_intelligence(company_name: str) -> Dict[str, Any]:
    """Get deep intelligence about a company."""
    company_lower = (company_name or "").lower().strip()
    
    for key, intel in COMPANY_INTELLIGENCE.items():
        if key in company_lower or company_lower in key:
            return intel
    
    for key, intel in COMPANY_INTELLIGENCE.items():
        if any(word in company_lower for word in key.split()):
            return intel
    
    return DEFAULT_COMPANY_INTELLIGENCE


# ============================================================
# ðŸ’¡ VALUE PROPOSITION GENERATOR
# ============================================================

VALUE_PROPOSITIONS = {
    "ml_engineer": [
        "bring production ML systems from prototype to scale",
        "bridge the gap between research insights and deployed models",
        "build data pipelines that enable rapid experimentation",
        "implement ML infrastructure that accelerates team velocity"
    ],
    "data_scientist": [
        "translate complex data patterns into actionable business insights",
        "design experiments that drive measurable product improvements",
        "build analytical frameworks that inform strategic decisions",
        "develop predictive models that optimize key metrics"
    ],
    "software_engineer": [
        "architect systems that scale gracefully under load",
        "write maintainable code that teams can build upon",
        "drive technical decisions with long-term thinking",
        "build infrastructure that enables product velocity"
    ],
    "data_engineer": [
        "design data architectures that support real-time analytics",
        "build pipelines that ensure data quality at scale",
        "create infrastructure that democratizes data access",
        "implement systems that reduce time-to-insight"
    ],
    "default": [
        "contribute technical depth with collaborative spirit",
        "drive measurable impact through systematic problem-solving",
        "bring both execution capability and strategic thinking",
        "build solutions that balance innovation with reliability"
    ]
}


def get_value_propositions(role: str) -> List[str]:
    """Get role-specific value propositions."""
    role_lower = role.lower()
    
    if "ml" in role_lower or "machine learning" in role_lower:
        return VALUE_PROPOSITIONS["ml_engineer"]
    elif "data scientist" in role_lower or "analytics" in role_lower:
        return VALUE_PROPOSITIONS["data_scientist"]
    elif "data engineer" in role_lower:
        return VALUE_PROPOSITIONS["data_engineer"]
    elif "software" in role_lower or "backend" in role_lower or "fullstack" in role_lower:
        return VALUE_PROPOSITIONS["software_engineer"]
    else:
        return VALUE_PROPOSITIONS["default"]


# ============================================================
# ðŸ”¬ TECHNICAL DEPTH SIGNALS
# ============================================================

TECHNICAL_DEPTH_SIGNALS = {
    "ml": [
        "implemented custom loss functions for domain-specific optimization",
        "designed feature stores for real-time ML serving",
        "built A/B testing frameworks for model evaluation",
        "optimized inference latency for production deployment"
    ],
    "data": [
        "architected data pipelines processing terabytes daily",
        "implemented data quality frameworks with automated monitoring",
        "designed schema evolution strategies for backward compatibility",
        "built real-time streaming pipelines with exactly-once semantics"
    ],
    "systems": [
        "designed distributed systems handling millions of requests",
        "implemented caching strategies reducing latency significantly",
        "built fault-tolerant architectures with graceful degradation",
        "optimized database queries for high-throughput workloads"
    ],
    "general": [
        "led technical design reviews and architecture decisions",
        "implemented monitoring and alerting for production systems",
        "built CI/CD pipelines for automated deployment",
        "contributed to open-source projects in the ecosystem"
    ]
}


def get_technical_depth_signals(role: str, jd_keywords: List[str]) -> List[str]:
    """Get role-appropriate technical depth signals."""
    role_lower = role.lower()
    jd_lower = " ".join(jd_keywords).lower()
    
    if "ml" in role_lower or "machine learning" in jd_lower:
        return TECHNICAL_DEPTH_SIGNALS["ml"]
    elif "data engineer" in role_lower or "pipeline" in jd_lower:
        return TECHNICAL_DEPTH_SIGNALS["data"]
    elif "backend" in role_lower or "distributed" in jd_lower:
        return TECHNICAL_DEPTH_SIGNALS["systems"]
    else:
        return TECHNICAL_DEPTH_SIGNALS["general"]


# ============================================================
# ðŸ”’ LaTeX & Text Utilities
# ============================================================

def _json_from_text(text: str, default: dict) -> dict:
    if not text:
        return default
    m = re.search(r"\{[\s\S]*\}", text)
    if not m:
        return default
    try:
        return json.loads(m.group(0))
    except Exception:
        return default


def _latex_escape_light(text: str) -> str:
    if not text:
        return ""
    text = text.replace("&", " and ")
    repl = {
        "%": r"\%", "$": r"\$", "#": r"\#", "_": r"\_",
        "{": r"\{", "}": r"\}", "~": r"\string~", "^": r"\string^",
        "\\": r"\textbackslash{}",
    }
    out = "".join(repl.get(ch, ch) for ch in text)
    return re.sub(r"[ \t]{2,}", " ", out).strip()


def _strip_academic_content(text: str) -> str:
    """Remove all academic mentions - GPA, graduation, coursework, degree dates."""
    if not text:
        return ""
    
    # Remove GPA mentions
    text = re.sub(r"\bGPA\b[:\s]*\d+(\.\d+)?(/\d+(\.\d+)?)?", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\b\d+(\.\d+)?\s*(GPA|CGPA)\b", "", text, flags=re.IGNORECASE)
    
    # Remove graduation year/date mentions
    text = re.sub(r"\b(graduat(ed?|ing|ion))\s*(in|from|date)?\s*\d{4}\b", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\b(class of|expected|graduating)\s*\d{4}\b", "", text, flags=re.IGNORECASE)
    
    # Remove coursework mentions
    text = re.sub(r"\b(relevant\s+)?coursework\b[:\s]*[^.]*\.", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\bcourses?\s+(include|including|such as)[^.]*\.", "", text, flags=re.IGNORECASE)
    
    # Remove degree mentions with dates
    text = re.sub(r"\b(bachelor'?s?|master'?s?|ph\.?d\.?|b\.?s\.?|m\.?s\.?)\s*(degree)?\s*(in\s+\w+)?\s*,?\s*\d{4}", "", text, flags=re.IGNORECASE)
    
    # Remove university + year combinations
    text = re.sub(r"\buniversity[^,]*,?\s*\d{4}", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\bcollege[^,]*,?\s*\d{4}", "", text, flags=re.IGNORECASE)
    
    # Clean up double spaces and punctuation
    text = re.sub(r"\s+,", ",", text)
    text = re.sub(r",\s*,", ",", text)
    text = re.sub(r"\s{2,}", " ", text)
    text = re.sub(r"\.\s*\.", ".", text)
    
    return text.strip()


def _strip_star_labels(text: str) -> str:
    if not text:
        return ""
    text = re.sub(
        r"(?i)\(\s*(?:situation|task|actions?|result(?:\s+and\s+impact)?|impact)"
        r"(?:\s*/\s*(?:task|actions?|result|impact))?\s*\)",
        "", text,
    )
    text = re.sub(
        r"(?im)^\s*(?:situation(?:\s*/\s*task)?|task|actions?|result(?:\s+and\s+impact)?|impact)\s*[:\-]\s*",
        "", text,
    )
    text = re.sub(r"[ \t]{2,}", " ", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()


def _normalize_body_whitespace(text: str) -> str:
    if not text:
        return ""
    text = re.sub(r"(\w)-\s*\n\s*(\w)", r"\1\2", text)
    text = re.sub(r"([A-Za-z])\s*\n\s*([A-Za-z])", r"\1\2", text)
    text = re.sub(r"(?<!\n)\n(?!\n)", " ", text)
    return re.sub(r"[ \t]{2,}", " ", text).strip()


def _debullettify_and_dedash(text: str) -> str:
    if not text:
        return ""
    text = re.sub(r"\(\s*[0-9]{1,2}\s*\)\s*", "", text)
    text = re.sub(r"(^|[.?!]\s+)\d{1,2}[.)]\s*", r"\1", text)
    text = re.sub(r"\s*(?:â€”|â€“|--)\s*", ", ", text)
    text = re.sub(r"\s-\s", ", ", text)
    text = re.sub(r"\s*,\s*,\s*", ", ", text)
    text = re.sub(r"[ \t]{2,}", " ", text)
    return text.strip()


def _postprocess_body(text: str) -> str:
    text = secure_tex_input(text or "")
    text = _strip_academic_content(text)
    text = _strip_star_labels(text)
    text = _normalize_body_whitespace(text)
    text = _debullettify_and_dedash(text)
    return _latex_escape_light(text)


async def chat_text(system: str, user: str, model: str) -> str:
    client = _get_openai_client()
    resp = client.chat.completions.create(
        model=model,
        messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
    )
    return (resp.choices[0].message.content or "").strip()


async def chat_json(user_prompt: str, model: str) -> dict:
    client = _get_openai_client()
    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": user_prompt}],
            response_format={"type": "json_object"},
        )
        content = (resp.choices[0].message.content or "").strip()
        try:
            return json.loads(content)
        except Exception:
            return _json_from_text(content, {})
    except Exception:
        resp = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": user_prompt}],
        )
        content = (resp.choices[0].message.content or "").strip()
        return _json_from_text(content, {})


# ============================================================
# ðŸ§  ADVANCED COMPANY INTELLIGENCE EXTRACTION
# ============================================================

async def extract_deep_company_intel(
    jd_text: str,
    company: str,
    role: str
) -> Dict[str, Any]:
    """Extract deep company intelligence from JD + known database."""
    
    base_intel = get_company_intelligence(company)
    
    prompt = f"""Analyze this job description and extract SPECIFIC details.

COMPANY: {company}
ROLE: {role}

JOB DESCRIPTION:
{jd_text[:4000]}

Return STRICT JSON:
{{
    "team_name": "specific team/org name if mentioned",
    "team_mission": "what this specific team does",
    "tech_stack": ["specific technologies mentioned"],
    "key_projects": ["specific projects/products mentioned"],
    "business_impact": "what business problem this role solves",
    "unique_challenges": ["specific technical challenges mentioned"],
    "required_expertise": ["must-have skills"],
    "insider_terminology": ["company-specific terms used"]
}}

Extract REAL details from the JD, not generic statements.
"""

    try:
        jd_intel = await chat_json(prompt, model=_INTELLIGENCE_MODEL)
    except Exception as e:
        log_event("intel_extraction_fail", {"error": str(e)})
        jd_intel = {}
    
    return {
        **base_intel,
        "team_name": jd_intel.get("team_name", ""),
        "team_mission": jd_intel.get("team_mission", ""),
        "jd_tech_stack": jd_intel.get("tech_stack", []),
        "key_projects": jd_intel.get("key_projects", []),
        "business_impact": jd_intel.get("business_impact", ""),
        "unique_challenges": jd_intel.get("unique_challenges", []),
        "required_expertise": jd_intel.get("required_expertise", []),
        "insider_terminology": jd_intel.get("insider_terminology", []) + base_intel.get("insider_phrases", [])
    }


async def extract_resume_highlights(resume_text: str) -> Dict[str, Any]:
    """Extract key highlights from resume (NO academic content)."""
    
    if not (resume_text or "").strip():
        return {"highlights": [], "skills": [], "experiences": [], "achievements": []}
    
    prompt = f"""Extract the MOST IMPRESSIVE PROFESSIONAL highlights from this resume.

RESUME:
{resume_text[:5000]}

Return STRICT JSON:
{{
    "top_achievements": ["3-5 most impressive WORK achievements with context"],
    "technical_skills": ["key technical skills demonstrated in projects"],
    "leadership_signals": ["leadership/ownership examples from work"],
    "quantified_results": ["results with numbers/metrics from work"],
    "company_names": ["companies worked at"],
    "project_highlights": ["key projects with outcomes"]
}}

IMPORTANT:
- Focus ONLY on work experience and projects
- DO NOT include GPA, graduation dates, coursework, or academic achievements
- DO NOT mention university names unless it's about research WORK
- Focus on PROFESSIONAL, SPECIFIC achievements only
"""

    try:
        return await chat_json(prompt, model=_INTELLIGENCE_MODEL)
    except Exception:
        return {"highlights": [], "skills": [], "experiences": [], "achievements": []}


async def extract_company_role(jd_text: str) -> Tuple[str, str]:
    jd_excerpt = (jd_text or "").strip()[:5000]
    prompt = (
        "Extract the company name and exact role title from the job description.\n"
        'Return STRICT JSON: {"company":"â€¦","role":"â€¦"}.\n'
        f"JD:\n{jd_excerpt}"
    )
    try:
        data = await chat_json(prompt, model=_EXTRACT_MODEL)
        company = (data.get("company") or "Company").strip()
        role = (data.get("role") or "Role").strip()
        return company, role
    except Exception as e:
        log_event("coverletter_extract_fail", {"error": str(e)})
        return "Company", "Role"


# ============================================================
# ðŸ“ AUTHENTIC COVER LETTER DRAFTING
# ============================================================

_LENGTH_BANDS = {"short": (120, 180), "standard": (200, 300), "long": (320, 420)}

_BUZZ_BANNED = [
    "passionate", "dynamic", "cutting edge", "team player", "synergy",
    "results-driven", "fast-paced", "leverage synergies", "mission inspires me",
    "innovative work", "perfect fit", "dream job", "always wanted to",
    "since childhood", "grateful for any opportunity", "humbly request",
    "excited to apply", "thrilled", "honored", "privileged", "astonish",
    "astonishing", "blown away", "game-changer", "revolutionary"
]

_ACADEMIC_BANNED = [
    "gpa", "cgpa", "graduated", "graduating", "graduation", "coursework",
    "courses", "degree", "bachelor", "master", "phd", "university studies",
    "academic", "transcript", "cum laude", "dean's list", "honors"
]

_WORD = re.compile(r"[A-Za-z0-9][A-Za-z0-9\-\./_+]*")
_SENT_SPLIT = re.compile(r"(?<=[.!?])\s+")
_STOPWORDS = set("a an the and or but if while for with to of in on by from as at into over under is are was were be been being this that these those i you he she they we it".split())


def _tokenize(text: str) -> List[str]:
    return [t.lower() for t in _WORD.findall(text or "")]


def _extract_terms(text: str) -> Set[str]:
    terms = set()
    for tok in set(_WORD.findall(text or "")):
        raw = tok.strip()
        if not raw or raw.lower() in _STOPWORDS or len(raw) < 2:
            continue
        terms.add(raw)
    return terms


def _clean_text_local(s: str, banned_phrases: Optional[List[str]] = None) -> str:
    txt = (s or "").replace("&", " and ").replace("â€”", ", ").replace("â€“", ", ").strip()
    txt = re.sub(r"^\s*(?:[#`>\-\*â€¢]|\d+[.)])\s+", "", txt, flags=re.MULTILINE)
    
    # Combine all banned phrases
    banned = set((banned_phrases or []) + _BUZZ_BANNED + _ACADEMIC_BANNED)
    for b in sorted(banned, key=len, reverse=True):
        txt = re.sub(rf"\b{re.escape(b)}\b", "", txt, flags=re.IGNORECASE)
    
    # Remove academic content patterns
    txt = _strip_academic_content(txt)
    
    txt = re.sub(r"[\[\]\{\}]+", "", txt)
    txt = re.sub(r"\s+,", ",", txt)
    txt = re.sub(r"\s{2,}", " ", txt).strip()
    return txt


def _enforce_word_band_local(text: str, length: str) -> str:
    lo, hi = _LENGTH_BANDS.get(length, (200, 300))
    words = text.split()
    if lo <= len(words) <= hi:
        return text
    sentences = _SENT_SPLIT.split(text.strip())
    out: List[str] = []
    for s in sentences:
        candidate = " ".join(out + [s]).strip()
        if len(candidate.split()) <= hi:
            out.append(s)
        else:
            break
    return " ".join(out).strip()


def _shape_paragraphs(text: str, mode: str) -> str:
    sents = [s.strip() for s in _SENT_SPLIT.split(text.strip()) if s.strip()]
    if not sents:
        return text.strip()
    if mode == "short":
        cut = max(1, min(len(sents) - 1, len(sents) // 3))
        return " ".join(sents[:cut]).strip() + "\n\n" + " ".join(sents[cut:]).strip()
    n = len(sents)
    i1 = max(1, min(n - 2, n // 5))
    i2 = max(i1 + 1, min(n - 1, (n * 4) // 5))
    return (
        " ".join(sents[:i1]).strip() + "\n\n" +
        " ".join(sents[i1:i2]).strip() + "\n\n" +
        " ".join(sents[i2:]).strip()
    )


async def draft_killer_cover_body(
    jd_text: str,
    resume_text: str,
    company: str,
    role: str,
    tone: str,
    length: str,
    company_intel: Dict[str, Any],
    resume_highlights: Dict[str, Any],
) -> str:
    """
    Generate a compelling, authentic cover letter with:
    - Genuine company-specific opening
    - NO academic mentions
    - Professional experience focus
    - Natural, authentic tone
    """
    
    tone = (tone or "balanced").strip().lower()
    length = (length or "standard").strip().lower()
    if length not in _LENGTH_BANDS:
        length = "standard"
    
    has_resume = bool((resume_text or "").strip())
    
    # Tone guidance
    tone_guidance = {
        "confident": "confident and direct, but not arrogant",
        "balanced": "professional yet conversational",
        "humble": "genuine and thoughtful",
        "conversational": "natural and authentic"
    }.get(tone, "professional yet conversational")
    
    # Get company-specific elements (optional, not forced)
    killer_hook = get_killer_hook(company, "product_insights")
    insider_hook = get_killer_hook(company, "insider_knowledge")
    culture_keywords = company_intel.get("culture_keywords", [])
    tech_focus = company_intel.get("tech_focus", [])
    products = company_intel.get("products_to_reference", [])
    unique_challenges = company_intel.get("unique_challenges", [])
    business_impact = company_intel.get("business_impact", "")
    team_name = company_intel.get("team_name", "")
    
    # Resume highlights (professional only)
    top_achievements = resume_highlights.get("top_achievements", [])
    technical_skills = resume_highlights.get("technical_skills", [])
    quantified_results = resume_highlights.get("quantified_results", [])
    
    length_hint = {
        "short": "Target 150-180 words in 2 paragraphs.",
        "standard": "Target 220-280 words in 3 paragraphs.",
        "long": "Target 350-400 words in 3-4 paragraphs.",
    }[length]
    
    sys_prompt = f"""You are writing an authentic, compelling cover letter for {company}.

TONE: {tone_guidance}

GOAL: Write naturally, demonstrating genuine understanding of {company} and connecting your experience to their needs.

ðŸ’¡ COMPANY CONTEXT (reference naturally if relevant):
- Culture: {', '.join(culture_keywords[:3]) if culture_keywords else 'professional excellence'}
- Tech focus: {', '.join(tech_focus[:3]) if tech_focus else 'modern technology'}
- Products: {', '.join(products[:3]) if products else company + ' products'}
{f'- Inspiration: {killer_hook}' if killer_hook else ''}
{f'- Culture insight: {insider_hook}' if insider_hook else ''}
{f'- Team: {team_name}' if team_name else ''}
{f'- Business impact: {business_impact}' if business_impact else ''}

ðŸ’ª YOUR STRENGTHS (WORK EXPERIENCE ONLY):
- Achievements: {'; '.join(top_achievements[:2]) if top_achievements else 'strong background'}
- Skills: {', '.join(technical_skills[:5]) if technical_skills else 'relevant technical skills'}
- Results: {'; '.join(quantified_results[:2]) if quantified_results else 'measurable impact'}

STRUCTURE:

PARAGRAPH 1 - Opening (3-4 sentences):
- Why this role at {company} genuinely interests you
- Reference something specific about their work (if you know it)
- Connect your background naturally
- Be specific but AUTHENTIC - no forced insider knowledge

PARAGRAPH 2 - Evidence (4-5 sentences):
- Your strongest relevant achievement from WORK
- How your experience relates to their needs
- Specific technical accomplishments (not academic)
- Demonstrate problem-solving and impact

PARAGRAPH 3 - Forward + Close (3 sentences):
- What you'd contribute
- Confident but not presumptuous close
- Express interest in conversation

RULES:
1. NO academic content (GPA, graduation, coursework, university)
2. Be specific but AUTHENTIC - no fake insider knowledge
3. {length_hint}
4. Natural tone - write like explaining interest to a colleague
5. No clichÃ©s: "passionate", "dream job", "perfect fit", "excited", "astonishing"
6. Professional experience only
7. First-person singular, confident but humble
8. Use "and" not "&", no em-dashes

OUTPUT: Just body paragraphs, no salutation/signature.
"""

    user_prompt = f"""Write the cover letter body for:

ROLE: {role}
COMPANY: {company}

JOB DESCRIPTION:
{jd_text[:4000]}

{"RESUME (professional experience):" if has_resume else ""}
{resume_text[:4000] if has_resume else "Focus on general professional capability aligned with JD."}

Write naturally and authentically. Be specific where you can, general where you must.
"""

    draft = await chat_text(sys_prompt, user_prompt, model=_DRAFT_MODEL)
    body = _clean_text_local(draft)
    
    # Validate and repair if needed
    body = await _validate_and_repair_authentic(
        body, company, role, jd_text, resume_text,
        company_intel, resume_highlights, length, tone
    )
    
    body = _shape_paragraphs(body, length)
    body = _enforce_word_band_local(body, length)
    
    return _postprocess_body(body)


async def _validate_and_repair_authentic(
    body: str,
    company: str,
    role: str,
    jd_text: str,
    resume_text: str,
    company_intel: Dict[str, Any],
    resume_highlights: Dict[str, Any],
    length: str,
    tone: str,
    max_repairs: int = 2
) -> str:
    """Validate and repair the cover letter for quality (softened validation)."""
    
    issues = []
    body_lower = body.lower()
    
    # Check for banned clichÃ©s
    for cliche in _BUZZ_BANNED:
        if cliche.lower() in body_lower:
            issues.append(f"Contains clichÃ©: '{cliche}'")
    
    # Check for academic content
    for academic in _ACADEMIC_BANNED:
        if academic.lower() in body_lower:
            issues.append(f"Contains academic content: '{academic}'")
    
    # Check company name is mentioned
    if company.lower() not in body_lower:
        issues.append("Company name not mentioned")
    
    # Soft check for product/feature reference (not required, just suggested)
    products = company_intel.get("products_to_reference", [])
    product_mentioned = any(p.lower() in body_lower for p in products if p)
    if products and not product_mentioned and len(products) > 0:
        log_event("cover_letter_suggestion", {
            "suggestion": f"Consider mentioning: {', '.join(products[:2])}"
        })
    
    # Check opening mentions company
    first_para = body.split('\n\n')[0] if body else ""
    if company.lower() not in first_para.lower():
        issues.append("Opening paragraph should mention company")
    
    # Check for forward-looking content
    if not re.search(r"\b(first|initial|early|would|will|contribute|drive|bring)\b", body_lower):
        issues.append("Missing forward-looking value statement")
    
    # Only repair if there are actual issues
    if issues and max_repairs > 0:
        repair_prompt = f"""Rewrite this cover letter to fix these issues:
{chr(10).join(f'- {i}' for i in issues)}

Current draft:
{body}

CRITICAL REQUIREMENTS:
- Company: {company}
- Role: {role}
- Opening paragraph should mention {company} naturally
- NO academic content (GPA, graduation, coursework, university)
- NO clichÃ©s (passionate, excited, dream job, astonishing, etc.)
- Add forward-looking contribution if missing
- Keep it {length} length
- Maintain natural, authentic tone

Return only the improved body paragraphs.
"""
        try:
            repaired = await chat_text(
                "You are improving a cover letter to be more authentic and professional.",
                repair_prompt,
                model=_DRAFT_MODEL
            )
            return await _validate_and_repair_authentic(
                _clean_text_local(repaired),
                company, role, jd_text, resume_text,
                company_intel, resume_highlights, length, tone,
                max_repairs - 1
            )
        except Exception:
            pass
    
    return body


# ============================================================
# âœ¨ Humanize via internal service
# ============================================================

async def humanize_text(body_text: str, tone: str) -> str:
    api_base = (getattr(config, "API_BASE_URL", "") or "").rstrip("/") or "http://127.0.0.1:8000"
    url = f"{api_base}/api/superhuman/rewrite"
    payload = {"text": body_text, "mode": "coverletter", "tone": tone, "latex_safe": True}
    try:
        async with httpx.AsyncClient(timeout=120.0) as client:
            r = await client.post(url, json=payload)
        r.raise_for_status()
        data = r.json()
        result = data.get("rewritten") or data.get("text") or body_text
        return _strip_academic_content(result)
    except Exception as e:
        log_event("superhuman_handoff_fail", {"error": str(e)})
        return body_text


# ============================================================
# ðŸ“„ Header & Template Injection
# ============================================================

def _fill_header_fields(
    tex: str,
    *,
    company: str,
    role: str,
    candidate: str,
    date_str: str,
    email: str = "",
    phone: str = "",
    citystate: str = "",
) -> str:
    def esc(v: str) -> str:
        return _latex_escape_light(secure_tex_input(v or ""))

    subst = {
        "COMPANY": company, 
        "ROLE": role, 
        "CANDIDATE_NAME": candidate,
        "NAME": candidate, 
        "DATE": date_str, 
        "EMAIL": email,
        "PHONE": phone, 
        "CITYSTATE": citystate if citystate else "",
    }
    
    for k, v in subst.items():
        # Skip empty values to avoid showing placeholder text
        if v or k in ["COMPANY", "ROLE", "CANDIDATE_NAME", "DATE"]:
            tex = tex.replace(f"{{{{{k}}}}}", esc(v))
            tex = tex.replace(f"%<<{k}>>%", esc(v))
        else:
            # Remove placeholders for empty optional fields
            tex = tex.replace(f"{{{{{k}}}}}", "")
            tex = tex.replace(f"%<<{k}>>%", "")

    patterns = {
        r"(\\def\\Company\{)(.*?)(\})": company,
        r"(\\def\\Role\{)(.*?)(\})": role,
        r"(\\def\\CandidateName\{)(.*?)(\})": candidate,
        r"(\\def\\Date\{)(.*?)(\})": date_str,
    }
    for pat, val in patterns.items():
        tex = re.sub(pat, lambda m: f"{m.group(1)}{esc(val)}{m.group(3)}", tex, flags=re.I)

    return tex


def _inject_between_salutation_and_signoff(base_tex: str, body_tex: str) -> Optional[str]:
    pat = r"(Dear[^\n]*?,\s*\n)([\s\S]*?)(\n\s*Sincerely,\s*\\\\[\s\S]*?$)"
    if re.search(pat, base_tex, flags=re.I):
        return re.sub(pat, lambda m: f"{m.group(1)}{body_tex}\n{m.group(3)}", base_tex, flags=re.I)
    return None


def inject_body_into_template(base_tex: str, body_tex: str) -> str:
    swapped = _inject_between_salutation_and_signoff(base_tex, body_tex)
    if swapped is not None:
        return swapped

    safe_body = re.sub(r"\\documentclass[\s\S]*?\\begin\{document\}", "", body_tex or "", flags=re.I)
    safe_body = re.sub(r"\\end\{document\}\s*$", "", safe_body, flags=re.I).strip()

    anchor_pat = r"(%-+BODY-START-+%)(.*?)(%-+BODY-END-+%)"
    if re.search(anchor_pat, base_tex, flags=re.S):
        return re.sub(anchor_pat, lambda m: f"{m.group(1)}\n{safe_body}\n{m.group(3)}", base_tex, flags=re.S)

    if re.search(r"\\end\{document\}\s*$", base_tex, flags=re.I):
        return re.sub(
            r"\\end\{document\}\s*$",
            lambda m: f"\n{safe_body}\n\\end{{document}}\n",
            base_tex, flags=re.I,
        )

    return base_tex.rstrip() + f"\n\n{safe_body}\n\\end{{document}}\n"


# ============================================================
# ðŸš€ MAIN ENDPOINT - AUTHENTIC VERSION
# ============================================================

@router.post("")
async def generate_coverletter(
    jd_text: str = Form(...),
    resume_tex: str = Form(""),
    use_humanize: bool = Form(True),
    tone: str = Form("balanced"),
    length: str = Form("standard"),
):
    """
    Generate an authentic, compelling cover letter.
    
    Features:
    - Genuine company-specific opening hooks
    - NO academic content (GPA, graduation, coursework)
    - Professional experience focus
    - Natural, conversational tone
    - Company-specific insights without hyperbole
    - No forced "insider knowledge"
    """
    
    if not (config.OPENAI_API_KEY or "").strip():
        raise HTTPException(status_code=400, detail="OPENAI_API_KEY missing.")
    if not (jd_text or "").strip():
        raise HTTPException(status_code=400, detail="jd_text is required.")

    # Step 1: Extract company and role
    company, role = await extract_company_role(jd_text)
    log_event("coverletter_start", {"company": company, "role": role})

    # Step 2: Extract deep company intelligence
    company_intel = await extract_deep_company_intel(jd_text, company, role)
    log_event("company_intel_extracted", {
        "company": company,
        "hooks_available": bool(get_killer_hook(company)),
        "insider_terms_count": len(company_intel.get("insider_terminology", []))
    })

    # Step 3: Extract resume highlights (professional only)
    resume_highlights = await extract_resume_highlights(resume_tex)

    # Step 4: Generate authentic cover letter body
    body_text = await draft_killer_cover_body(
        jd_text=jd_text,
        resume_text=resume_tex,
        company=company,
        role=role,
        tone=tone,
        length=length,
        company_intel=company_intel,
        resume_highlights=resume_highlights,
    )

    # Step 5: Humanize if requested
    if use_humanize:
        body_text = await humanize_text(body_text, tone)
        body_text = _postprocess_body(body_text)

    # Step 6: Inject into LaTeX template
    base_path = config.BASE_COVERLETTER_PATH
    try:
        with open(base_path, encoding="utf-8") as f:
            base_tex = f.read()
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail=f"Template not found: {base_path}")

    today_str = datetime.now().strftime("%B %d, %Y")
    candidate = getattr(config, "CANDIDATE_NAME", "Sri Akash Kadali")
    applicant_email = getattr(config, "APPLICANT_EMAIL", "kadali18@umd.edu")
    applicant_phone = getattr(config, "APPLICANT_PHONE", "+1 240-726-9356")
    applicant_city = getattr(config, "APPLICANT_CITYSTATE", "")  # Empty by default

    base_tex = _fill_header_fields(
        base_tex,
        company=company,
        role=role,
        candidate=candidate,
        date_str=today_str,
        email=applicant_email,
        phone=applicant_phone,
        citystate=applicant_city,
    )

    try:
        injected = inject_body_into_template(base_tex, body_text)
    except re.error as e:
        log_event("inject_error", {"error": str(e)})
        injected = f"{base_tex}\n\n{body_text}\n"
        if not injected.strip().endswith("\\end{document}"):
            injected += "\n\\end{document}\n"

    final_tex = render_final_tex(injected)
    pdf_bytes = compile_latex_safely(final_tex) or b""
    pdf_b64 = base64.b64encode(pdf_bytes).decode("utf-8")

    # Save files
    company_slug = safe_filename(company)
    role_slug = safe_filename(role)
    context_key = f"{company_slug}__{role_slug}"

    out_pdf_path = config.get_sample_coverletter_pdf_path(company, role)
    ensure_dir(out_pdf_path.parent)
    if pdf_bytes:
        out_pdf_path.write_bytes(pdf_bytes)

    # Save context
    ctx_dir = config.get_contexts_dir()
    ensure_dir(ctx_dir)
    ctx_path = ctx_dir / f"{context_key}.json"

    existing: Dict[str, Any] = {}
    if ctx_path.exists():
        try:
            existing = json.loads(ctx_path.read_text(encoding="utf-8"))
        except Exception:
            existing = {}

    context_payload = {
        **existing,
        "key": context_key,
        "company": company,
        "role": role,
        "jd_text": jd_text,
        "company_intel": {
            "culture_keywords": company_intel.get("culture_keywords", []),
            "tech_focus": company_intel.get("tech_focus", []),
            "insider_terms": company_intel.get("insider_terminology", [])[:5],
            "hook_used": bool(get_killer_hook(company)),
        },
        "cover_letter": {
            "tex": final_tex,
            "pdf_path": str(out_pdf_path),
            "pdf_b64": pdf_b64,
            "tone": tone,
            "length": length,
            "humanized": bool(use_humanize),
        },
        "updated_at": datetime.utcnow().isoformat() + "Z",
    }
    ctx_path.write_text(json.dumps(context_payload, ensure_ascii=False, indent=2), encoding="utf-8")

    log_event("coverletter_generated", {
        "company": company,
        "role": role,
        "tone": tone,
        "length": length,
        "humanized": use_humanize,
        "hook_used": bool(get_killer_hook(company)),
        "chars": len(body_text),
    })

    return JSONResponse({
        "company": company,
        "role": role,
        "tone": tone,
        "use_humanize": use_humanize,
        "tex_string": final_tex,
        "pdf_base64": pdf_b64,
        "pdf_path": str(out_pdf_path),
        "context_key": context_key,
        "context_path": str(ctx_path),
        "company_intel_used": {
            "culture_keywords": company_intel.get("culture_keywords", [])[:3],
            "tech_focus": company_intel.get("tech_focus", [])[:3],
            "insider_terms": company_intel.get("insider_terminology", [])[:3],
            "hook_available": bool(get_killer_hook(company)),
        },
        "id": context_key,
        "memory_id": context_key,
    })-e 


-e # ===== FILE: ./api/render_tex.py =====

"""
HIREX â€¢ api/render_tex.py
Template renderer for final LaTeX resume output.
Simplified for direct LaTeX input (no JSON parsing).
Author: Sri Akash Kadali
"""

import re
from backend.core.utils import log_event


# ============================================================
# ðŸ§  Direct LaTeX Renderer
# ============================================================
def render_final_tex(final_tex: str) -> str:
    """
    Returns the LaTeX text exactly as received from GPT/Humanize,
    after performing minimal safety cleanup and normalization.

    Args:
        final_tex (str): Full LaTeX document string (already formatted)
    Returns:
        str: Safe LaTeX text ready for compilation
    """
    if not isinstance(final_tex, str):
        raise ValueError("render_final_tex() expects a LaTeX string input.")

    # --- Trim and clean any code-fence artifacts ---
    cleaned = (
        final_tex.replace("```latex", "")
        .replace("```", "")
        .strip()
    )

    # --- Normalize line endings ---
    cleaned = cleaned.replace("\r\n", "\n").replace("\r", "\n")

    # --- Remove stray leading/trailing blank lines ---
    cleaned = re.sub(r"^\s*\n", "", cleaned)
    cleaned = re.sub(r"\n\s*$", "\n", cleaned)

    # --- Basic validation warnings ---
    if not re.search(r"\\documentclass", cleaned):
        log_event("âš ï¸ [RENDER] Missing \\documentclass header.")
    if "\\begin{document}" not in cleaned:
        log_event("âš ï¸ [RENDER] Missing \\begin{document} block.")

    # --- Ensure proper closing tag ---
    if not cleaned.strip().endswith("\\end{document}"):
        cleaned += "\n\\end{document}\n"

    # --- Collapse excessive blank lines for cleanliness ---
    cleaned = re.sub(r"\n{3,}", "\n\n", cleaned)

    log_event("âœ… [RENDER] Final LaTeX render complete and safe for compilation.")
    return cleaned


# ============================================================
# ðŸ§ª Local Test
# ============================================================
if __name__ == "__main__":
    sample_tex = r"""
\documentclass{article}
\begin{document}
Hello World

\section*{Education}
University of Maryland, College Park

\end{document}
"""
    print(render_final_tex(sample_tex))-e 


-e # ===== FILE: ./api/dashboard.py =====

# ============================================================
#  ASTRA v2.1.2 â€” Dashboard Analytics & History Endpoint (FINAL)
#  ------------------------------------------------------------
#  Provides:
#   â€¢ Aggregated event summaries (counts, not clones)
#   â€¢ Tone/mode analytics
#   â€¢ Weekly trend data (Mon..Sun)
#   â€¢ Recent history listing (deduped per Company__Role)
#   â€¢ Event type registry
#   â€¢ Robust log reading & safe JSONL parsing
#  Author: Sri Akash Kadali
# ============================================================

from __future__ import annotations

import json
from collections import Counter
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from fastapi import APIRouter, Query
from fastapi.responses import JSONResponse

from backend.core import config

router = APIRouter(prefix="/api/dashboard", tags=["dashboard"])

# ============================================================
# ðŸ“ Paths (read from config only; directories auto-created)
# ============================================================
LOG_PATH = Path(config.LOG_PATH)
HISTORY_PATH = Path(config.HISTORY_PATH)

for p in (LOG_PATH.parent, HISTORY_PATH.parent):
    p.mkdir(parents=True, exist_ok=True)


# ============================================================
# ðŸ§© Helpers: Time / JSONL / Normalization / Dedupe
# ============================================================
def _now_iso() -> str:
    """UTC now in ISO-8601 with trailing Z."""
    return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")


def _read_jsonl(path: Path, limit: int = 500) -> List[Dict[str, Any]]:
    """Safely read the last N lines of a JSONL file (newest first)."""
    if not path.exists():
        return []
    try:
        with open(path, "r", encoding="utf-8") as f:
            lines = f.readlines()[-limit:]
        records: List[Dict[str, Any]] = []
        # Reverse so newest first
        for line in reversed(lines):
            try:
                obj = json.loads(line)
                if isinstance(obj, dict):
                    records.append(obj)
            except json.JSONDecodeError:
                continue
        return records
    except Exception:
        return []


def _iso(ts: Optional[str]) -> str:
    """Coerce to ISO timestamp string (safe fallback to now)."""
    if not ts:
        return _now_iso()
    try:
        _ = datetime.fromisoformat(ts.replace("Z", "+00:00"))
        return ts
    except Exception:
        return _now_iso()


def _event_name(e: Dict[str, Any]) -> str:
    """Normalize event/type name."""
    return (e.get("event") or e.get("type") or "unknown").lower()


def _company_role_from_meta(e: Dict[str, Any]) -> Tuple[str, str]:
    """Extract (company, role) from common locations."""
    m = e.get("meta") or {}
    company = (m.get("company") or e.get("company") or "").strip()
    role = (m.get("role") or e.get("role") or "").strip()
    return company, role


def _ts_value(e: Dict[str, Any]) -> float:
    """Timestamp (epoch seconds) for ordering/dedupe."""
    ts_raw = e.get("timestamp") or e.get("time") or ""
    try:
        return datetime.fromisoformat(str(ts_raw).replace("Z", "+00:00")).timestamp()
    except Exception:
        return 0.0


def _dedupe_company_role(records: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Collapse multiple records for the same (company, role) combo,
    keeping the most recent one. This prevents dashboard tables
    from exploding with clones of similar actions for the same job.
    """
    best: Dict[Tuple[str, str], Dict[str, Any]] = {}
    for r in records:
        company, role = _company_role_from_meta(r)
        if not (company and role):
            # keep entries with no company/role (diagnostics) â€” single latest
            key = ("", "")
            prev = best.get(key)
            if prev is None or _ts_value(r) > _ts_value(prev):
                best[key] = r
            continue

        k = (company, role)
        prev = best.get(k)
        if prev is None or _ts_value(r) > _ts_value(prev):
            best[k] = r

    # Keep deterministic newest-first order
    out = sorted(best.values(), key=_ts_value, reverse=True)
    return out


# ============================================================
# ðŸ“Š Aggregations
# ============================================================
def summarize_events(events: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Generate analytic aggregates for dashboard visualizations."""
    summary: Dict[str, Any] = {
        "total_events": len(events),
        "optimize_runs": 0,
        "coverletters": 0,
        "superhuman_calls": 0,
        "talk_queries": 0,
        "mastermind_chats": 0,
        "tones": Counter(),
        "modes": Counter(),
        "avg_resume_length": 0.0,
        "distinct_company_roles": 0,
    }

    # Distinct (company, role) counter for high-level dedup metric
    distinct_pairs = set()

    total_len = 0
    len_count = 0
    for e in events:
        evt = _event_name(e)
        meta = e.get("meta", {}) or {}

        if "optimize" in evt:
            summary["optimize_runs"] += 1
        if "coverletter" in evt:
            summary["coverletters"] += 1
        if "superhuman" in evt or "humanize" in evt:
            summary["superhuman_calls"] += 1
        if "talk" in evt:
            summary["talk_queries"] += 1
        if "mastermind" in evt:
            summary["mastermind_chats"] += 1

        tone = str(meta.get("tone", "balanced")).lower()
        mode = str(meta.get("mode", "general")).lower()
        if tone:
            summary["tones"][tone] += 1
        if mode:
            summary["modes"][mode] += 1

        try:
            rl = int(meta.get("resume_len") or 0)
            if rl > 0:
                total_len += rl
                len_count += 1
        except Exception:
            pass

        c, r = _company_role_from_meta(e)
        if c or r:
            distinct_pairs.add((c, r))

    # Average only over entries that actually reported resume_len
    denom = max(len_count, 1)
    summary["avg_resume_length"] = round(total_len / denom, 2)
    summary["distinct_company_roles"] = len(distinct_pairs)

    # Convert counters to plain dicts for JSON
    summary["tones"] = dict(summary["tones"])
    summary["modes"] = dict(summary["modes"])
    return summary


def summarize_history(records: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Extract recent high-level activity (for dashboard table)."""
    out: List[Dict[str, Any]] = []
    for h in records:
        meta = h.get("meta", {}) or {}
        ts = _iso(h.get("timestamp") or h.get("time"))
        evt = _event_name(h)
        out.append(
            {
                "timestamp": ts,
                "event": evt,
                "company": meta.get("company", ""),
                "role": meta.get("role", ""),
                "tone": meta.get("tone", "balanced"),
                "score": meta.get("fit_score", None),
                "length": meta.get("resume_len", None),
                "source": h.get("origin", "system"),
            }
        )
    return out


def weekly_trend(records: List[Dict[str, Any]]) -> Dict[str, List[int]]:
    """
    Build Mon..Sun trend counts per category.
    """
    buckets = {
        "optimizations": [0] * 7,
        "coverletters": [0] * 7,
        "superhuman": [0] * 7,
        "mastermind": [0] * 7,
        "talk": [0] * 7,
    }

    def _dow(ts: str) -> int:
        try:
            d = datetime.fromisoformat(ts.replace("Z", "+00:00"))
            # Monday=0
            return d.weekday()
        except Exception:
            return 0

    for r in records:
        evt = _event_name(r)
        ts = _iso(r.get("timestamp") or r.get("time"))
        i = _dow(ts)
        if "optimize" in evt:
            buckets["optimizations"][i] += 1
        elif "coverletter" in evt:
            buckets["coverletters"][i] += 1
        elif "superhuman" in evt or "humanize" in evt:
            buckets["superhuman"][i] += 1
        elif "mastermind" in evt:
            buckets["mastermind"][i] += 1
        elif "talk" in evt:
            buckets["talk"][i] += 1

    return buckets


# ============================================================
# ðŸš€ Root: Combined payload (summary + trend + history)
# ============================================================
@router.get("")
@router.get("/")  # compatibility
async def dashboard_root(
    limit: int = Query(300, ge=1, le=2000),
    dedupe: bool = Query(True, description="Collapse multiple actions per (Company,Role) to the newest one"),
):
    events = _read_jsonl(LOG_PATH, limit)
    history = _read_jsonl(HISTORY_PATH, limit)
    records = history or events

    if dedupe:
        records = _dedupe_company_role(records)

    if not records:
        return {"summary": {}, "trend": {}, "history": [], "updated": _now_iso()}

    return {
        "summary": summarize_events(records),
        "trend": weekly_trend(records),
        "history": summarize_history(records)[:100],
        "updated": _now_iso(),
    }


# ============================================================
# ðŸš€ Endpoint: /summary
# ============================================================
@router.get("/summary")
async def get_summary(
    limit: int = Query(300, ge=1, le=2000),
    dedupe: bool = Query(True),
):
    """
    Aggregated dashboard summary used for top metrics and charts.
    Combines analytics from events.jsonl and history.jsonl.
    """
    events = _read_jsonl(LOG_PATH, limit)
    history = _read_jsonl(HISTORY_PATH, limit)

    if not events and not history:
        return JSONResponse({"message": "No analytics available.", "summary": {}, "recent": []})

    # Prefer history when present
    records = history or events
    if dedupe:
        records = _dedupe_company_role(records)

    summary = summarize_events(records)
    hist_data = summarize_history(records)

    return {"summary": summary, "recent": hist_data[:100], "updated": _now_iso()}


# ============================================================
# ðŸš€ Endpoint: /trend
# ============================================================
@router.get("/trend")
async def get_trend(
    limit: int = Query(300, ge=1, le=2000),
    dedupe: bool = Query(True),
):
    """Weekly Mon..Sun trend counts by category."""
    history = _read_jsonl(HISTORY_PATH, limit) or _read_jsonl(LOG_PATH, limit)
    if dedupe:
        history = _dedupe_company_role(history)
    return {"trend": weekly_trend(history), "updated": _now_iso()}


# ============================================================
# ðŸš€ Endpoint: /recent
# ============================================================
@router.get("/recent")
async def get_recent(
    limit: int = Query(100, ge=1, le=1000),
    dedupe: bool = Query(True),
):
    """Returns a chronological list of recent user-visible actions."""
    history = _read_jsonl(HISTORY_PATH, limit) or _read_jsonl(LOG_PATH, limit)
    if dedupe:
        history = _dedupe_company_role(history)
    return {"events": summarize_history(history)}


# ============================================================
# ðŸš€ Endpoint: /types
# ============================================================
@router.get("/types")
async def list_event_types():
    """Returns a deduplicated list of event types for frontend filters."""
    # Combine both sources for a more complete registry
    events = _read_jsonl(LOG_PATH, 1000) + _read_jsonl(HISTORY_PATH, 1000)
    types = sorted(
        {
            (e.get("event") or e.get("type") or "").lower()
            for e in events
            if (e.get("event") or e.get("type"))
        }
    )
    return {"types": types}


# ============================================================
# ðŸ§  Endpoint: /metrics
# ============================================================
@router.get("/metrics")
async def metrics_summary(
    limit: int = Query(500, ge=1, le=3000),
    dedupe: bool = Query(True),
):
    """Returns lightweight numeric insights (for quick dashboard cards)."""
    events = _read_jsonl(LOG_PATH, limit)
    if not events:
        return {
            "optimize": 0,
            "coverletters": 0,
            "superhuman": 0,
            "talk": 0,
            "mastermind": 0,
            "distinct_company_roles": 0,
            "updated": _now_iso(),
        }

    records = _dedupe_company_role(events) if dedupe else events
    summary = summarize_events(records)
    return {
        "optimize": summary["optimize_runs"],
        "coverletters": summary["coverletters"],
        "superhuman": summary["superhuman_calls"],
        "talk": summary["talk_queries"],
        "mastermind": summary["mastermind_chats"],
        "distinct_company_roles": summary["distinct_company_roles"],
        "updated": _now_iso(),
    }


# ============================================================
# ðŸ§¾ Endpoint: /raw
# ============================================================
@router.get("/raw")
async def raw_dump(limit: int = Query(100, ge=1, le=2000)):
    """
    Developer-only diagnostic endpoint: returns raw JSON lines.
    Use for backend debugging or analytics export.
    """
    events = _read_jsonl(LOG_PATH, limit)
    return {"count": len(events), "events": events}
-e 


-e # ===== FILE: ./api/debug.py =====

"""
============================================================
 HIREX v2.1.0 â€” api/debug.py
 ------------------------------------------------------------
 Lightweight diagnostic endpoint for frontend â†’ backend logs.

  â€¢ Accepts any POSTed JSON payload (dict or list) or raw text
  â€¢ Prints to console in readable, truncated format
  â€¢ Persists structured event via log_event()
  â€¢ Auto-tags origin, page, level, and timestamps
  â€¢ Never crashes on malformed or non-JSON payloads

 Author: Sri Akash Kadali
============================================================
"""

from __future__ import annotations

import json
from datetime import datetime
from typing import Any, Dict

from fastapi import APIRouter, Request
from fastapi.responses import JSONResponse

from backend.core.utils import log_event


# IMPORTANT:
#  - NO `/api` here
#  - `/api` is owned by main.py
router = APIRouter(prefix="/api/debug", tags=["debug"])


def _now_iso() -> str:
    return datetime.utcnow().isoformat()


def _truncate(obj: Any, limit: int = 800) -> str:
    """Truncate a JSON-serialized preview to avoid spammy console logs."""
    try:
        s = json.dumps(obj, ensure_ascii=False, indent=2)
    except Exception:
        s = str(obj)
    return (s[:limit] + "â€¦") if len(s) > limit else s


@router.get("/ping")
async def debug_ping():
    """Simple liveness check for the debug router."""
    return {"ok": True, "router": "debug", "time": _now_iso()}


# ============================================================
# ðŸ§  Frontend â†’ Backend Debug / Analytics Logger
# ============================================================
@router.post("/log")
async def debug_log(request: Request):
    """
    Receives arbitrary frontend debug or analytics payloads
    and logs them both to console and persistent JSONL.
    """

    # 1ï¸âƒ£ Parse body (JSON or raw text)
    payload: Dict[str, Any]
    try:
        body = await request.json()
        if isinstance(body, dict):
            payload = body
        else:
            payload = {"data": body, "non_dict_json": True}
    except Exception:
        raw = (await request.body()).decode("utf-8", "ignore")
        payload = {"raw": raw, "format_error": True}

    # 2ï¸âƒ£ Inject metadata
    headers = request.headers
    client_ip = request.client.host if request.client else "unknown"

    payload.setdefault("received_at", _now_iso())
    payload.setdefault("origin", client_ip)
    payload.setdefault("page", payload.get("page", "unknown"))
    payload.setdefault("level", payload.get("level", "debug"))
    payload.setdefault("user_agent", headers.get("user-agent", ""))
    payload.setdefault("referer", headers.get("referer", ""))
    payload.setdefault("timestamp", payload.get("received_at"))

    # 3ï¸âƒ£ Console output (safe + truncated)
    msg = payload.get("msg", "(no message)")
    page = payload.get("page", "?")
    print(f"[FE DEBUG] ({page}) {msg}")
    print("  â””â”€", _truncate({k: v for k, v in payload.items() if k != "raw"}))

    # 4ï¸âƒ£ Persist event
    try:
        log_event("frontend_debug", payload)
    except Exception as e:
        print(f"[WARN] Failed to persist debug event: {e}")

    # 5ï¸âƒ£ Response
    return JSONResponse(
        {
            "ok": True,
            "logged": True,
            "timestamp": payload["received_at"],
        }
    )-e 


-e # ===== FILE: ./api/talk.py =====

"""
============================================================
 HIREX v4.0.0 â€” talk.py (ULTIMATE KILLER ANSWERS)
 ------------------------------------------------------------
 MAJOR UPGRADES:
 - Anti-hallucination grounding with resume fact verification
 - Answer quality scoring (specificity, relevance, hook strength)
 - Skill gap analysis with honest addressing strategies
 - Interview stage awareness (recruiter vs technical vs final)
 - Follow-up question prediction
 - Red flag detection and proactive addressing
 - Personal brand/theme consistency
 - Multi-answer session consistency
 - Company-specific question bank
 - Behavioral STAR enforcement
 - Salary/negotiation intelligence
 - Output quality validation before returning

 Author: Sri Akash Kadali
============================================================
"""

from __future__ import annotations

import json
import re
import time
import random
import hashlib
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional, Dict, Any, Tuple, List, Set

import httpx
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

try:
    from openai import AsyncOpenAI
except Exception:
    AsyncOpenAI = None

from backend.core import config
from backend.core.utils import log_event, safe_filename, ensure_dir
from backend.core.security import secure_tex_input

router = APIRouter(prefix="/api/talk", tags=["talk"])

openai_client = AsyncOpenAI(api_key=getattr(config, "OPENAI_API_KEY", "")) if AsyncOpenAI else None

CONTEXT_DIR: Path = config.get_contexts_dir()
ensure_dir(CONTEXT_DIR)

SUMMARIZER_MODEL = getattr(config, "TALK_SUMMARY_MODEL", "gpt-4o-mini")
ANSWER_MODEL = getattr(config, "TALK_ANSWER_MODEL", "gpt-4o-mini")
CHAT_SAFE_DEFAULT = getattr(config, "DEFAULT_MODEL", "gpt-4o-mini")

# Session-level fact store for consistency across multiple questions
_SESSION_FACTS: Dict[str, Dict[str, Any]] = {}
_SESSION_ANSWERS: Dict[str, List[Dict[str, Any]]] = {}


# ============================================================
# ðŸ¢ COMPREHENSIVE COMPANY INTELLIGENCE DATABASE
# ============================================================

COMPANY_INTELLIGENCE = {
    "netflix": {
        "what_they_value": ["data-driven decisions", "experimentation culture", "ownership mentality", "impact over activity"],
        "culture_keywords": ["Freedom & Responsibility", "context not control", "keeper test", "candor"],
        "tech_strengths": ["Recommender Systems", "A/B Testing at Scale", "Personalization", "Streaming Infrastructure"],
        "what_impresses_them": [
            "Talk about IMPACT, not just tasks",
            "Show data-driven thinking with metrics",
            "Demonstrate ownership and autonomy",
            "Reference experimentation and iteration"
        ],
        "insider_terms": ["member experience", "title discovery", "personalization at scale"],
        "avoid_saying": ["I follow instructions well", "I'm a team player", "I'm passionate"],
        "common_questions": [
            "Tell me about a time you made a data-driven decision",
            "Describe a situation where you took ownership",
            "How do you handle ambiguity?",
            "Tell me about a time you disagreed with your manager"
        ],
        "interview_stages": {
            "recruiter": "Focus on culture fit and high-level experience",
            "technical": "Deep dive into systems design and ML expertise",
            "hiring_manager": "Ownership examples and impact stories",
            "final": "Leadership alignment and long-term vision"
        },
        "salary_range": {"entry": "$150k-$200k", "mid": "$200k-$350k", "senior": "$350k-$600k+"},
        "competitors": ["Disney+", "HBO Max", "Amazon Prime Video", "Apple TV+"],
        "why_not_competitors": "Netflix's experimentation culture and engineering autonomy is unmatched"
    },
    "google": {
        "what_they_value": ["technical excellence", "scalability thinking", "user impact", "10x improvements"],
        "culture_keywords": ["Googleyness", "think big", "user first", "psychological safety"],
        "tech_strengths": ["Distributed Systems", "AI/ML Infrastructure", "Search Quality", "Cloud Platform"],
        "what_impresses_them": [
            "Structured problem-solving approach",
            "Scalability and efficiency thinking",
            "Concrete technical depth",
            "User-centric impact framing"
        ],
        "insider_terms": ["OKRs", "launch and iterate", "10x improvement", "Noogler"],
        "avoid_saying": ["I work hard", "I'm detail-oriented", "I'm a fast learner"],
        "common_questions": [
            "Tell me about a technically challenging problem you solved",
            "How would you design X system?",
            "Tell me about a time you improved something by 10x",
            "How do you prioritize when everything is important?"
        ],
        "interview_stages": {
            "recruiter": "Googleyness assessment and experience overview",
            "technical": "Coding, system design, and ML depth",
            "hiring_manager": "Leadership and collaboration examples",
            "final": "Team match and culture fit"
        },
        "salary_range": {"entry": "$140k-$180k", "mid": "$200k-$400k", "senior": "$400k-$800k+"},
        "competitors": ["Microsoft", "Meta", "Amazon", "Apple"],
        "why_not_competitors": "Google's technical challenges and AI leadership are unparalleled"
    },
    "meta": {
        "what_they_value": ["move fast", "impact metrics", "product sense", "bold thinking"],
        "culture_keywords": ["Move Fast", "Be Bold", "Focus on Impact", "Build Social Value"],
        "tech_strengths": ["Ranking Systems", "Social Graph", "AR/VR", "Ads Optimization"],
        "what_impresses_them": [
            "Quantified impact with specific metrics",
            "Move fast mentality with examples",
            "Product intuition demonstrated",
            "Scale of systems you've worked on"
        ],
        "insider_terms": ["family of apps", "integrity systems", "social impact", "Bootcamp"],
        "avoid_saying": ["I'm careful and methodical", "I double-check everything", "I prefer stability"],
        "common_questions": [
            "Tell me about your biggest impact",
            "How do you make decisions with incomplete data?",
            "Describe a time you moved fast and broke things",
            "How do you measure success?"
        ],
        "interview_stages": {
            "recruiter": "Impact stories and culture fit",
            "technical": "Coding and system design at scale",
            "hiring_manager": "Product sense and leadership",
            "final": "Executive alignment"
        },
        "salary_range": {"entry": "$140k-$180k", "mid": "$200k-$400k", "senior": "$400k-$700k+"},
        "competitors": ["Google", "TikTok", "Snap", "Twitter/X"],
        "why_not_competitors": "Meta's scale of impact and bold technical bets are unique"
    },
    "amazon": {
        "what_they_value": ["customer obsession", "ownership", "bias for action", "dive deep", "deliver results"],
        "culture_keywords": ["Customer Obsession", "Ownership", "Bias for Action", "Dive Deep", "Leadership Principles"],
        "tech_strengths": ["AWS Services", "Supply Chain ML", "Retail Optimization", "Logistics"],
        "what_impresses_them": [
            "STAR format with specific metrics",
            "Leadership principles alignment",
            "Customer impact examples",
            "Ownership and accountability stories"
        ],
        "insider_terms": ["PR/FAQ", "6-pager", "bar raiser", "Day 1 mentality", "mechanisms", "working backwards"],
        "avoid_saying": ["That's not my job", "I waited for direction", "I delegated"],
        "common_questions": [
            "Tell me about a time you went above and beyond for a customer",
            "Describe a situation where you had to dive deep",
            "Tell me about a time you disagreed and committed",
            "How do you handle competing priorities?"
        ],
        "interview_stages": {
            "recruiter": "LP screening and experience fit",
            "technical": "Coding and system design",
            "loop": "Multiple LP-focused behavioral rounds",
            "bar_raiser": "Cross-team culture assessment"
        },
        "salary_range": {"entry": "$130k-$170k", "mid": "$180k-$350k", "senior": "$350k-$600k+"},
        "competitors": ["Google Cloud", "Microsoft Azure", "Walmart", "Shopify"],
        "why_not_competitors": "Amazon's customer obsession and ownership culture drive real impact"
    },
    "microsoft": {
        "what_they_value": ["growth mindset", "customer empathy", "collaboration", "inclusive culture"],
        "culture_keywords": ["Growth Mindset", "Customer Obsessed", "One Microsoft", "Learn-it-all"],
        "tech_strengths": ["Azure Cloud", "AI/Copilot", "Microsoft 365", "Developer Tools"],
        "what_impresses_them": [
            "Growth mindset examples with learning",
            "Collaboration across teams",
            "Customer impact stories",
            "Responsible AI awareness"
        ],
        "insider_terms": ["growth mindset", "customer zero", "inclusive design", "One Microsoft"],
        "avoid_saying": ["I already know everything", "I work best alone", "I avoid ambiguity"],
        "common_questions": [
            "Tell me about a time you learned from failure",
            "How do you collaborate with difficult stakeholders?",
            "Describe your approach to inclusive design",
            "How do you balance innovation with responsibility?"
        ],
        "interview_stages": {
            "recruiter": "Growth mindset and culture fit",
            "technical": "Coding and system design",
            "hiring_manager": "Collaboration and customer focus",
            "final": "As-appropriate leadership"
        },
        "salary_range": {"entry": "$130k-$170k", "mid": "$180k-$350k", "senior": "$350k-$600k+"},
        "competitors": ["Google", "Amazon", "Salesforce", "Oracle"],
        "why_not_competitors": "Microsoft's growth mindset culture and AI leadership momentum"
    },
    "apple": {
        "what_they_value": ["attention to detail", "user privacy", "craftsmanship", "simplicity"],
        "culture_keywords": ["Think Different", "Simplicity", "Privacy as Human Right", "Excellence"],
        "tech_strengths": ["On-Device ML", "Privacy-Preserving AI", "Hardware-Software Integration"],
        "what_impresses_them": [
            "Design thinking and user empathy",
            "Privacy-first approach",
            "Quality over speed examples",
            "Attention to detail stories"
        ],
        "insider_terms": ["DRI", "surprise and delight", "it just works", "top 100"],
        "avoid_saying": ["Good enough is fine", "Users don't care about details", "Move fast and break things"],
        "common_questions": [
            "Tell me about a time you obsessed over details",
            "How do you balance user experience with technical constraints?",
            "Describe your approach to privacy",
            "Tell me about something you're proud of building"
        ],
        "interview_stages": {
            "recruiter": "Culture fit and experience",
            "technical": "Deep technical expertise",
            "design": "User empathy and design thinking",
            "final": "Leadership alignment"
        },
        "salary_range": {"entry": "$140k-$180k", "mid": "$200k-$400k", "senior": "$400k-$700k+"},
        "competitors": ["Google", "Samsung", "Microsoft"],
        "why_not_competitors": "Apple's commitment to privacy and craftsmanship is unmatched"
    },
    "stripe": {
        "what_they_value": ["rigorous thinking", "users first", "writing quality", "long-term orientation"],
        "culture_keywords": ["Users First", "Move with Urgency", "Think Rigorously", "Trust and Amplify"],
        "tech_strengths": ["Payment Infrastructure", "Financial APIs", "Fraud Detection", "Developer Experience"],
        "what_impresses_them": [
            "Clear, rigorous thinking",
            "Developer empathy examples",
            "Long-term technical decisions",
            "Writing and communication quality"
        ],
        "insider_terms": ["increase GDP of internet", "payment rails", "developer love"],
        "avoid_saying": ["I prefer quick wins", "Documentation is boring", "I focus on short-term"],
        "common_questions": [
            "Walk me through a complex technical decision",
            "How do you think about API design?",
            "Tell me about a time you prioritized long-term over short-term",
            "How do you communicate technical concepts?"
        ],
        "interview_stages": {
            "recruiter": "Writing sample and culture fit",
            "technical": "System design and coding",
            "work_sample": "Take-home or pair programming",
            "final": "Team and leadership fit"
        },
        "salary_range": {"entry": "$150k-$200k", "mid": "$220k-$400k", "senior": "$400k-$650k+"},
        "competitors": ["Square", "Adyen", "Braintree", "Plaid"],
        "why_not_competitors": "Stripe's developer-first culture and rigorous thinking"
    },
    "airbnb": {
        "what_they_value": ["mission alignment", "customer empathy", "design-driven", "belonging"],
        "culture_keywords": ["Belong Anywhere", "Champion the Mission", "Be a Host", "Embrace Adventure"],
        "tech_strengths": ["Search & Ranking", "Pricing Algorithms", "Trust & Safety", "Payments"],
        "what_impresses_them": [
            "Mission and purpose alignment",
            "Customer/user empathy stories",
            "Creative problem-solving",
            "Design-thinking approach"
        ],
        "insider_terms": ["belonging", "host community", "guest journey", "Airbnb it"],
        "avoid_saying": ["I'm purely technical", "I don't care about mission", "Users are just data points"],
        "common_questions": [
            "Why does our mission resonate with you?",
            "Tell me about a time you advocated for the user",
            "How do you balance host and guest needs?",
            "Describe a creative solution you developed"
        ],
        "interview_stages": {
            "recruiter": "Mission alignment and culture",
            "technical": "System design and coding",
            "cross-functional": "Design and product collaboration",
            "final": "Leadership and values"
        },
        "salary_range": {"entry": "$140k-$180k", "mid": "$200k-$380k", "senior": "$380k-$600k+"},
        "competitors": ["Booking.com", "VRBO", "Hotels.com"],
        "why_not_competitors": "Airbnb's mission of belonging and design-driven culture"
    },
    "uber": {
        "what_they_value": ["systems thinking", "marketplace understanding", "reliability at scale", "data-driven"],
        "culture_keywords": ["Build Globally", "Act Like Owners", "Persevere", "Celebrate Differences"],
        "tech_strengths": ["Marketplace Optimization", "ETA Prediction", "Route Optimization", "Fraud Detection"],
        "what_impresses_them": [
            "Systems and marketplace thinking",
            "Reliability and scale examples",
            "Data-driven decision making",
            "Impact metrics at scale"
        ],
        "insider_terms": ["marketplace balance", "rider experience", "driver earnings", "surge"],
        "avoid_saying": ["I prefer simple problems", "Scale doesn't matter to me", "I avoid complexity"],
        "common_questions": [
            "How would you optimize a two-sided marketplace?",
            "Tell me about a system you built for reliability",
            "How do you make decisions with conflicting metrics?",
            "Describe a time you solved a complex systems problem"
        ],
        "interview_stages": {
            "recruiter": "Experience and culture fit",
            "technical": "System design and marketplace thinking",
            "coding": "Algorithmic problem-solving",
            "final": "Leadership and team fit"
        },
        "salary_range": {"entry": "$140k-$180k", "mid": "$200k-$380k", "senior": "$380k-$550k+"},
        "competitors": ["Lyft", "DoorDash", "Instacart"],
        "why_not_competitors": "Uber's global scale and marketplace complexity"
    },
    "databricks": {
        "what_they_value": ["technical excellence", "open source contribution", "customer impact", "data passion"],
        "culture_keywords": ["Customer Obsessed", "Unity", "Ownership", "Open Source First"],
        "tech_strengths": ["Lakehouse", "Delta Lake", "MLflow", "Spark", "Data Engineering"],
        "what_impresses_them": [
            "Deep technical expertise",
            "Open source appreciation/contribution",
            "Data architecture experience",
            "Customer-facing technical work"
        ],
        "insider_terms": ["Lakehouse", "Delta Lake", "data + AI", "open source", "Unity Catalog"],
        "avoid_saying": ["I prefer proprietary tools", "Open source is risky", "I avoid customer interaction"],
        "common_questions": [
            "How would you design a data lakehouse?",
            "Tell me about your open source contributions",
            "How do you approach data quality at scale?",
            "Describe a complex data architecture you built"
        ],
        "interview_stages": {
            "recruiter": "Technical background and culture",
            "technical": "Data architecture and Spark expertise",
            "system_design": "Lakehouse and ML infrastructure",
            "final": "Customer focus and team fit"
        },
        "salary_range": {"entry": "$150k-$200k", "mid": "$220k-$400k", "senior": "$400k-$600k+"},
        "competitors": ["Snowflake", "AWS", "Google BigQuery"],
        "why_not_competitors": "Databricks' open source DNA and unified data + AI platform"
    },
    "snowflake": {
        "what_they_value": ["engineering excellence", "customer focus", "big thinking", "integrity"],
        "culture_keywords": ["Put Customers First", "Integrity Always", "Think Big", "Be Excellent"],
        "tech_strengths": ["Data Cloud", "Data Sharing", "Snowpark", "Data Marketplace"],
        "what_impresses_them": [
            "Technical excellence examples",
            "Customer success stories",
            "Big thinking and ambition",
            "Performance optimization experience"
        ],
        "insider_terms": ["Data Cloud", "Snowpark", "data sharing economy", "zero-copy cloning"],
        "avoid_saying": ["Small improvements are fine", "Customers are annoying", "Good enough works"],
        "common_questions": [
            "How would you optimize query performance at scale?",
            "Tell me about a time you helped a customer succeed",
            "How do you approach data governance?",
            "Describe your most ambitious technical project"
        ],
        "interview_stages": {
            "recruiter": "Experience and culture fit",
            "technical": "Database internals and performance",
            "system_design": "Data architecture at scale",
            "final": "Customer focus and values"
        },
        "salary_range": {"entry": "$150k-$200k", "mid": "$220k-$400k", "senior": "$400k-$600k+"},
        "competitors": ["Databricks", "AWS Redshift", "Google BigQuery"],
        "why_not_competitors": "Snowflake's engineering excellence and data sharing vision"
    },
    "linkedin": {
        "what_they_value": ["member value", "relationships", "data-driven", "inclusive culture"],
        "culture_keywords": ["Members First", "Relationships Matter", "Be Open Honest Constructive", "Act Like Owner"],
        "tech_strengths": ["Feed Ranking", "Job Matching", "Graph Systems", "Economic Graph"],
        "what_impresses_them": [
            "Member/user empathy examples",
            "Data-driven decision making",
            "Collaboration stories",
            "Scale and impact metrics"
        ],
        "insider_terms": ["economic graph", "member value", "professional identity", "InDay"],
        "avoid_saying": ["Users are just metrics", "I work alone", "Data doesn't matter"],
        "common_questions": [
            "How would you improve job matching?",
            "Tell me about a time you improved member experience",
            "How do you balance engagement with member value?",
            "Describe a data-driven decision you made"
        ],
        "interview_stages": {
            "recruiter": "Culture fit and experience",
            "technical": "Coding and system design",
            "hiring_manager": "Member focus and collaboration",
            "final": "Values alignment"
        },
        "salary_range": {"entry": "$140k-$180k", "mid": "$200k-$380k", "senior": "$380k-$550k+"},
        "competitors": ["Indeed", "Glassdoor", "ZipRecruiter"],
        "why_not_competitors": "LinkedIn's professional graph and member-first culture"
    },
    "spotify": {
        "what_they_value": ["innovation", "collaboration", "user empathy", "autonomy"],
        "culture_keywords": ["Innovative", "Collaborative", "Sincere", "Passionate", "Playful"],
        "tech_strengths": ["Audio ML", "Personalization", "Content Delivery", "Creator Tools"],
        "what_impresses_them": [
            "Product passion and user empathy",
            "Personalization expertise",
            "Collaborative spirit",
            "Creative problem-solving"
        ],
        "insider_terms": ["Discover Weekly", "audio-first", "creator ecosystem", "squad model"],
        "avoid_saying": ["I don't listen to music", "Users don't know what they want", "I prefer hierarchy"],
        "common_questions": [
            "How would you improve music recommendations?",
            "Tell me about a time you collaborated across teams",
            "How do you balance creator and listener needs?",
            "Describe a personalization system you built"
        ],
        "interview_stages": {
            "recruiter": "Culture fit and product passion",
            "technical": "ML and system design",
            "squad": "Team collaboration assessment",
            "final": "Leadership and values"
        },
        "salary_range": {"entry": "$130k-$170k", "mid": "$180k-$350k", "senior": "$350k-$500k+"},
        "competitors": ["Apple Music", "YouTube Music", "Amazon Music"],
        "why_not_competitors": "Spotify's personalization leadership and squad autonomy"
    }
}

DEFAULT_COMPANY_INTELLIGENCE = {
    "what_they_value": ["technical excellence", "collaboration", "impact", "growth"],
    "culture_keywords": ["innovation", "teamwork", "excellence"],
    "tech_strengths": ["modern technology", "scalable systems"],
    "what_impresses_them": [
        "Specific achievements with metrics",
        "Problem-solving examples",
        "Collaboration stories",
        "Technical depth demonstration"
    ],
    "insider_terms": [],
    "avoid_saying": ["I'm a team player", "I work hard", "I'm passionate"],
    "common_questions": [],
    "interview_stages": {},
    "salary_range": {"entry": "$100k-$150k", "mid": "$150k-$250k", "senior": "$250k-$400k+"},
    "competitors": [],
    "why_not_competitors": ""
}


def get_company_intelligence(company_name: str) -> Dict[str, Any]:
    """Get comprehensive intelligence about a company."""
    company_lower = (company_name or "").lower().strip()
    
    for key, intel in COMPANY_INTELLIGENCE.items():
        if key in company_lower or company_lower in key:
            return intel
    
    for key, intel in COMPANY_INTELLIGENCE.items():
        if any(word in company_lower for word in key.split()):
            return intel
    
    return DEFAULT_COMPANY_INTELLIGENCE


# ============================================================
# ðŸŽ¯ ENHANCED QUESTION TYPE DETECTION & STRATEGY
# ============================================================

QUESTION_STRATEGIES = {
    "why_hire_you": {
        "patterns": [
            r"why should we hire you",
            r"why are you the right fit",
            r"why should we choose you",
            r"what makes you stand out",
            r"why you over other candidates",
            r"what sets you apart",
            r"why are you the best candidate",
            r"what do you bring to this role",
            r"what value do you add"
        ],
        "strategy": "PROOF + UNIQUE VALUE",
        "structure": [
            "Open with your STRONGEST, most RELEVANT achievement",
            "Show UNIQUE combination of skills they can't easily find",
            "Map directly to their SPECIFIC needs from JD",
            "Close with forward-looking contribution"
        ],
        "hook_templates": [
            "I've already solved the exact problem you're hiring for â€” {achievement}.",
            "The intersection of {skill1} and {skill2} that you need is exactly where I've built my career.",
            "In my last role, I {achievement}, which is precisely what this position requires.",
            "What sets me apart is that I don't just {skill} â€” I've {specific_outcome}."
        ],
        "likely_followups": [
            "Can you give me a specific example?",
            "How would you apply that here?",
            "What would you do in your first 90 days?",
            "How do you know you can do this at our scale?"
        ],
        "trap_warnings": [
            "Don't be arrogant or put down other candidates",
            "Don't be vague - they want SPECIFIC proof",
            "Don't just list skills - show IMPACT"
        ]
    },
    "why_this_company": {
        "patterns": [
            r"why do you want to work (here|at|for)",
            r"why this company",
            r"why .+\?",
            r"what attracts you to",
            r"what interests you about",
            r"why are you interested in",
            r"what draws you to"
        ],
        "strategy": "SPECIFIC COMPANY KNOWLEDGE + ALIGNMENT",
        "structure": [
            "Open with SPECIFIC company insight (product, tech, challenge)",
            "Show genuine understanding of their unique position",
            "Connect YOUR background to THEIR specific needs",
            "Demonstrate you've researched beyond the JD"
        ],
        "hook_templates": [
            "What drew me to {company} specifically is {specific_insight}.",
            "I've been following {company}'s work on {specific_thing}, and it aligns with {your_experience}.",
            "The challenge of {company_challenge} is one I've tackled before, and I'm drawn to solving it at {company}'s scale.",
            "{company}'s approach to {specific_approach} mirrors how I've built my most successful systems."
        ],
        "likely_followups": [
            "What do you know about our culture?",
            "Why not one of our competitors?",
            "What concerns do you have about us?",
            "How did you hear about us?"
        ],
        "trap_warnings": [
            "Don't be generic - they want SPECIFIC knowledge",
            "Don't mention salary/benefits as primary reason",
            "Don't badmouth competitors"
        ]
    },
    "why_this_role": {
        "patterns": [
            r"why this (role|position|job)",
            r"what interests you about this (role|position)",
            r"why are you applying for this",
            r"what excites you about this (role|position|opportunity)",
            r"why do you want this job"
        ],
        "strategy": "ROLE-SKILL MATCH + GROWTH",
        "structure": [
            "Show you understand EXACTLY what this role does",
            "Map your experience to the specific responsibilities",
            "Demonstrate how this is a natural next step",
            "Show enthusiasm through specificity, not generic excitement"
        ],
        "hook_templates": [
            "This role sits at the intersection of {area1} and {area2}, which is exactly where I've focused my career.",
            "The {specific_responsibility} in this role is something I've been doing successfully for {time}.",
            "I've built my career around {skill}, and this role is the natural next step to {goal}.",
            "What draws me to this specific role is {specific_aspect} â€” I've seen firsthand how impactful this work can be."
        ],
        "likely_followups": [
            "What don't you know about this role?",
            "What would be challenging for you?",
            "How does this fit your long-term goals?",
            "What would you change about this role?"
        ],
        "trap_warnings": [
            "Don't be vague about role responsibilities",
            "Don't focus only on what you'll GET",
            "Show understanding of challenges, not just perks"
        ]
    },
    "tell_me_about_yourself": {
        "patterns": [
            r"tell me about yourself",
            r"walk me through your background",
            r"introduce yourself",
            r"give me an overview of your experience",
            r"describe your background",
            r"walk me through your resume"
        ],
        "strategy": "RELEVANT NARRATIVE + TRAJECTORY",
        "structure": [
            "Start with current role/most relevant experience (Present)",
            "Connect past experiences in a coherent narrative (Past)",
            "Show intentional career trajectory toward THIS role (Future)",
            "End with why you're here NOW"
        ],
        "hook_templates": [
            "I'm a {role_type} who has spent the last {time} building {what_you_build}.",
            "My career has been focused on {theme}, most recently at {company} where I {achievement}.",
            "I've spent my career at the intersection of {area1} and {area2}, which led me to {this_opportunity}.",
            "What defines my work is {defining_theme} â€” at {company}, this meant {specific_example}."
        ],
        "likely_followups": [
            "Tell me more about {specific thing you mentioned}",
            "Why did you leave your last role?",
            "What's your biggest accomplishment?",
            "What are you looking for in your next role?"
        ],
        "trap_warnings": [
            "Don't recite your entire resume",
            "Don't start from childhood",
            "Keep it under 2 minutes spoken",
            "Make it RELEVANT to this role"
        ]
    },
    "strength": {
        "patterns": [
            r"(greatest|biggest|key|main) strength",
            r"what are you good at",
            r"what do you do well",
            r"what's your superpower",
            r"strongest skill",
            r"what do you excel at"
        ],
        "strategy": "SPECIFIC STRENGTH + PROOF",
        "structure": [
            "Name ONE specific strength (not generic)",
            "Immediately prove it with a concrete example",
            "Show impact/outcome of that strength",
            "Connect to how it helps THIS role"
        ],
        "hook_templates": [
            "My core strength is {specific_strength} â€” for example, at {company} I {specific_example}.",
            "I'm exceptionally good at {specific_thing}, which I demonstrated when I {achievement}.",
            "What I do best is {strength} â€” this is why I was able to {specific_outcome}.",
            "If I had to pick one thing, it's my ability to {strength}. At {company}, this meant {example}."
        ],
        "likely_followups": [
            "Can you give another example?",
            "How would that help in this role?",
            "What's your second greatest strength?",
            "Has that strength ever been a weakness?"
        ],
        "trap_warnings": [
            "Don't be generic (teamwork, communication)",
            "Don't claim strengths you can't prove",
            "Pick something RELEVANT to the role"
        ]
    },
    "weakness": {
        "patterns": [
            r"(greatest|biggest) weakness",
            r"area (for|of) improvement",
            r"what are you working on",
            r"development area",
            r"where do you struggle",
            r"what would you improve about yourself"
        ],
        "strategy": "HONEST + MITIGATION + GROWTH",
        "structure": [
            "Name a REAL weakness (not fake humble-brag)",
            "Show self-awareness about its impact",
            "Describe SPECIFIC steps you're taking to improve",
            "Show progress/results from those efforts"
        ],
        "hook_templates": [
            "I've learned that I {real_weakness}. To address this, I've {specific_action}.",
            "Earlier in my career, I struggled with {weakness}. I've since {how_you_improved}.",
            "One area I'm actively developing is {weakness}. Recently, I {specific_improvement_action}.",
            "I tend to {weakness}, so I've built systems to {mitigation}."
        ],
        "likely_followups": [
            "How has that weakness affected your work?",
            "Can you give a specific example?",
            "What triggered you to work on this?",
            "How do you know you're improving?"
        ],
        "trap_warnings": [
            "Don't say 'perfectionism' or 'work too hard'",
            "Don't pick something critical to the role",
            "Don't be TOO honest about fatal flaws",
            "Show genuine self-awareness"
        ]
    },
    "achievement": {
        "patterns": [
            r"(proudest|biggest|greatest|most significant) (achievement|accomplishment)",
            r"tell me about a time you",
            r"describe a situation where",
            r"give me an example of",
            r"share an experience when"
        ],
        "strategy": "STAR WITH IMPACT",
        "structure": [
            "Set context briefly (Situation/Task) - 15%",
            "Focus on YOUR specific actions - 60%",
            "Quantify the result/impact - 20%",
            "Connect learning to THIS role - 5%"
        ],
        "hook_templates": [
            "The achievement I'm most proud of is {achievement} because {why_meaningful}.",
            "At {company}, I faced {challenge}. I {actions}, which resulted in {outcome}.",
            "When {situation}, I {your_action}. This led to {quantified_result}.",
            "My most impactful work was {achievement}, where I {specific_contribution}."
        ],
        "likely_followups": [
            "What would you do differently?",
            "What did you learn from this?",
            "How did others contribute?",
            "What was the hardest part?"
        ],
        "trap_warnings": [
            "Don't make Situation too long",
            "Focus on YOUR actions, not team's",
            "QUANTIFY the result",
            "Don't pick something irrelevant"
        ]
    },
    "conflict": {
        "patterns": [
            r"conflict",
            r"disagreement",
            r"difficult (person|colleague|coworker|situation)",
            r"challenging relationship",
            r"how do you handle",
            r"dealt with a difficult"
        ],
        "strategy": "PROFESSIONAL + RESOLUTION-FOCUSED",
        "structure": [
            "Describe situation professionally (no blame)",
            "Show your approach to understanding the other side",
            "Explain actions YOU took to resolve",
            "Show positive outcome and learning"
        ],
        "hook_templates": [
            "I approach conflicts as opportunities to find better solutions. For example, when {situation}...",
            "In a recent disagreement about {topic}, I first sought to understand {their_perspective}...",
            "When I encountered {challenge}, I focused on {your_approach}...",
            "I believe most conflicts stem from {insight}. When {situation}, I {action}..."
        ],
        "likely_followups": [
            "What if the person didn't change?",
            "What would you do differently?",
            "How do you prevent conflicts?",
            "Tell me about a conflict you didn't resolve well"
        ],
        "trap_warnings": [
            "Don't badmouth the other person",
            "Don't avoid the question",
            "Show emotional intelligence",
            "Pick a professional conflict, not personal"
        ]
    },
    "failure": {
        "patterns": [
            r"tell me about a (time you )?fail",
            r"mistake you made",
            r"something that didn't work",
            r"a setback",
            r"when things went wrong"
        ],
        "strategy": "HONEST + LEARNING + GROWTH",
        "structure": [
            "Describe the failure honestly",
            "Take responsibility (no blame-shifting)",
            "Explain what you learned",
            "Show how you've applied that learning"
        ],
        "hook_templates": [
            "One failure that taught me a lot was when I {failure}. I learned {learning}.",
            "Early in my career, I {mistake}. This taught me to {lesson}.",
            "A project that didn't go as planned was {project}. The key learning was {insight}.",
            "I failed when I {failure}, but it led me to {positive_change}."
        ],
        "likely_followups": [
            "How did others react?",
            "What would you do differently now?",
            "How do you prevent similar failures?",
            "What was the impact of the failure?"
        ],
        "trap_warnings": [
            "Don't pick something trivial",
            "Don't blame others",
            "Show genuine learning",
            "Don't pick something that shows poor judgment"
        ]
    },
    "salary": {
        "patterns": [
            r"salary expectations",
            r"compensation",
            r"what are you looking for",
            r"pay expectations",
            r"how much do you want to make",
            r"what's your expected salary"
        ],
        "strategy": "RESEARCH-BACKED + FLEXIBLE",
        "structure": [
            "Show you've done research on market rates",
            "Give a range (not a single number)",
            "Express flexibility based on total comp",
            "Redirect to fit and opportunity"
        ],
        "hook_templates": [
            "Based on my research and experience level, I'm targeting {range}, though I'm flexible based on total compensation.",
            "I've researched the market rate for this role, which seems to be {range}. I'm open to discussing based on the full package.",
            "My expectation is in the {range} range, but I'm more focused on finding the right fit and growth opportunity.",
            "For this level of role in {location}, I understand the range is typically {range}. I'd love to understand your budget."
        ],
        "likely_followups": [
            "What's your current salary?",
            "What's the minimum you'd accept?",
            "How did you arrive at that number?",
            "What other factors matter to you?"
        ],
        "trap_warnings": [
            "Don't give a number too early",
            "Don't lowball yourself",
            "Don't lie about current salary",
            "Research the company's pay bands"
        ]
    },
    "leadership": {
        "patterns": [
            r"leadership (experience|style|example)",
            r"led a team",
            r"managed (people|team)",
            r"describe your leadership",
            r"how do you lead"
        ],
        "strategy": "EXAMPLE + STYLE + IMPACT",
        "structure": [
            "Describe a specific leadership situation",
            "Explain YOUR leadership approach",
            "Show impact on team and results",
            "Connect to how you'd lead here"
        ],
        "hook_templates": [
            "My leadership style is {style}. For example, when I led {team/project}, I {approach}.",
            "I believe effective leadership is about {philosophy}. At {company}, I demonstrated this by {example}.",
            "Leading {team} taught me that {insight}. I achieved this by {actions}.",
            "When I led {initiative}, I focused on {approach}, which resulted in {outcome}."
        ],
        "likely_followups": [
            "How do you handle underperformers?",
            "How do you motivate your team?",
            "What's your biggest leadership mistake?",
            "How do you make difficult decisions?"
        ],
        "trap_warnings": [
            "Don't be vague about your style",
            "Show results, not just process",
            "Be honest about team contributions",
            "Leadership isn't just about managing people"
        ]
    },
    "technical": {
        "patterns": [
            r"technical (challenge|problem|decision)",
            r"complex (system|architecture|problem)",
            r"how would you (design|build|architect)",
            r"walk me through (your|a) technical"
        ],
        "strategy": "DEPTH + TRADEOFFS + REASONING",
        "structure": [
            "Describe the technical context clearly",
            "Explain your approach and reasoning",
            "Discuss tradeoffs you considered",
            "Share the outcome and learnings"
        ],
        "hook_templates": [
            "The most challenging technical problem I solved was {problem}. I approached it by {approach}.",
            "When designing {system}, I had to balance {tradeoff1} with {tradeoff2}. I chose {choice} because {reasoning}.",
            "At {company}, I built {system} that {outcome}. The key technical decision was {decision}.",
            "A complex architecture decision I made was {decision}. The tradeoffs were {tradeoffs}."
        ],
        "likely_followups": [
            "What would you do differently now?",
            "How did you handle scale?",
            "What were the failure modes?",
            "How did you test this?"
        ],
        "trap_warnings": [
            "Don't be too high-level",
            "Show depth of understanding",
            "Discuss tradeoffs, not just solutions",
            "Be honest about what you don't know"
        ]
    },
    "generic": {
        "patterns": [],
        "strategy": "SPECIFIC PROOF + RELEVANCE",
        "structure": [
            "Answer directly with specific evidence",
            "Connect to JD requirements",
            "Show concrete examples",
            "Tie to this opportunity"
        ],
        "hook_templates": [
            "Based on my experience with {relevant_experience}, I {answer}.",
            "This connects directly to my work at {company}, where I {example}.",
            "The most relevant example is when I {specific_example}.",
            "I approach this by {approach}, which I demonstrated when {example}."
        ],
        "likely_followups": [
            "Can you elaborate on that?",
            "How would that apply here?",
            "What's a specific example?",
            "What did you learn from that?"
        ],
        "trap_warnings": [
            "Don't be vague",
            "Always give specific examples",
            "Connect to the role"
        ]
    }
}


def detect_question_type(question: str) -> Tuple[str, Dict[str, Any]]:
    """Detect the type of question and return appropriate strategy."""
    question_lower = question.lower().strip()
    
    for q_type, q_config in QUESTION_STRATEGIES.items():
        if q_type == "generic":
            continue
        for pattern in q_config["patterns"]:
            if re.search(pattern, question_lower):
                return q_type, q_config
    
    return "generic", QUESTION_STRATEGIES["generic"]


# ============================================================
# ðŸ›¡ï¸ ANTI-HALLUCINATION GROUNDING SYSTEM
# ============================================================

class FactGrounder:
    """Verify claims against resume facts to prevent hallucination."""
    
    def __init__(self):
        self.resume_facts: Dict[str, Any] = {}
        self.verified_claims: Set[str] = set()
        self.unverified_claims: Set[str] = set()
    
    async def extract_facts(self, resume_text: str, model: str) -> Dict[str, Any]:
        """Extract verifiable facts from resume."""
        if not resume_text.strip():
            return {}
        
        prompt = f"""Extract ONLY verifiable facts from this resume. Be precise and conservative.

RESUME:
{resume_text[:5000]}

Return STRICT JSON:
{{
    "companies": ["list of company names worked at"],
    "roles": ["list of job titles held"],
    "technologies": ["list of technologies mentioned"],
    "metrics": ["any quantified achievements with numbers"],
    "projects": ["named projects or systems"],
    "education": ["degrees, schools, certifications"],
    "years_experience": "approximate total years",
    "skills_claimed": ["skills explicitly claimed"],
    "achievements_verbatim": ["achievement statements as written"]
}}

ONLY include facts explicitly stated. Do NOT infer or add anything.
"""
        
        try:
            result = await _gen_text_smart("Extract facts as JSON.", prompt, model)
            match = re.search(r"\{[\s\S]*\}", result)
            if match:
                self.resume_facts = json.loads(match.group(0))
                return self.resume_facts
        except Exception as e:
            log_event("fact_extraction_fail", {"error": str(e)})
        
        return {}
    
    def verify_claim(self, claim: str, resume_text: str) -> Tuple[bool, str]:
        """Verify if a claim is grounded in resume facts."""
        claim_lower = claim.lower()
        resume_lower = resume_text.lower()
        
        # Check for specific keywords
        for company in self.resume_facts.get("companies", []):
            if company.lower() in claim_lower and company.lower() in resume_lower:
                self.verified_claims.add(claim)
                return True, f"Verified: mentions {company}"
        
        for tech in self.resume_facts.get("technologies", []):
            if tech.lower() in claim_lower and tech.lower() in resume_lower:
                self.verified_claims.add(claim)
                return True, f"Verified: mentions {tech}"
        
        for metric in self.resume_facts.get("metrics", []):
            # Check if numbers/percentages are from resume
            numbers_in_claim = re.findall(r'\d+%?', claim)
            numbers_in_resume = re.findall(r'\d+%?', resume_text)
            if numbers_in_claim and any(n in numbers_in_resume for n in numbers_in_claim):
                self.verified_claims.add(claim)
                return True, "Verified: metric from resume"
        
        # If claim has specific details not in resume, flag it
        self.unverified_claims.add(claim)
        return False, "Warning: claim may not be grounded in resume"


# ============================================================
# ðŸ“Š ANSWER QUALITY SCORING
# ============================================================

class AnswerQualityScorer:
    """Score answer quality across multiple dimensions."""
    
    def __init__(self):
        self.scores: Dict[str, float] = {}
        self.feedback: List[str] = []
    
    def score_answer(
        self,
        answer: str,
        question: str,
        q_type: str,
        company: str,
        jd_requirements: Dict[str, Any],
        resume_highlights: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Score answer quality and provide feedback."""
        
        self.scores = {}
        self.feedback = []
        answer_lower = answer.lower()
        
        # 1. Hook Strength (0-10)
        first_sentence = answer.split('.')[0] if answer else ""
        hook_score = self._score_hook(first_sentence, company)
        self.scores["hook_strength"] = hook_score
        
        # 2. Specificity (0-10)
        specificity_score = self._score_specificity(answer, resume_highlights)
        self.scores["specificity"] = specificity_score
        
        # 3. Relevance to JD (0-10)
        relevance_score = self._score_relevance(answer, jd_requirements)
        self.scores["jd_relevance"] = relevance_score
        
        # 4. Company Alignment (0-10)
        company_score = self._score_company_alignment(answer, company)
        self.scores["company_alignment"] = company_score
        
        # 5. Confidence Tone (0-10)
        confidence_score = self._score_confidence(answer)
        self.scores["confidence"] = confidence_score
        
        # 6. Length Appropriateness (0-10)
        length_score = self._score_length(answer)
        self.scores["length"] = length_score
        
        # 7. No-Cliche Check (0-10)
        cliche_score = self._score_no_cliches(answer)
        self.scores["no_cliches"] = cliche_score
        
        # 8. Answer-Question Match (0-10)
        match_score = self._score_question_match(answer, question, q_type)
        self.scores["question_match"] = match_score
        
        # Calculate overall score
        weights = {
            "hook_strength": 0.15,
            "specificity": 0.20,
            "jd_relevance": 0.15,
            "company_alignment": 0.10,
            "confidence": 0.10,
            "length": 0.05,
            "no_cliches": 0.10,
            "question_match": 0.15
        }
        
        overall = sum(self.scores[k] * weights[k] for k in weights)
        
        return {
            "overall_score": round(overall, 1),
            "dimension_scores": self.scores,
            "feedback": self.feedback,
            "grade": self._get_grade(overall),
            "pass": overall >= 7.0
        }
    
    def _score_hook(self, first_sentence: str, company: str) -> float:
        """Score the opening hook."""
        score = 5.0  # Base score
        
        # Bonus for company mention in first sentence
        if company.lower() in first_sentence.lower():
            score += 1.5
        
        # Bonus for specific achievement
        if any(word in first_sentence.lower() for word in ["built", "led", "designed", "achieved", "delivered"]):
            score += 1.5
        
        # Bonus for confidence
        if first_sentence and not first_sentence.lower().startswith(("i am", "i'm", "thank you", "i would")):
            score += 1.0
        
        # Penalty for generic opening
        if any(phrase in first_sentence.lower() for phrase in ["i am writing", "thank you for", "i believe", "i am excited"]):
            score -= 2.0
            self.feedback.append("Opening is generic - start with a specific achievement or insight")
        
        return max(0, min(10, score))
    
    def _score_specificity(self, answer: str, resume_highlights: Dict[str, Any]) -> float:
        """Score how specific the answer is."""
        score = 5.0
        
        # Count specific elements
        has_numbers = bool(re.search(r'\d+', answer))
        has_company_names = any(c.lower() in answer.lower() for c in resume_highlights.get("companies_worked", []))
        has_technologies = any(t.lower() in answer.lower() for t in resume_highlights.get("technical_skills", []))
        has_action_verbs = sum(1 for v in ["built", "designed", "led", "implemented", "delivered", "launched"] if v in answer.lower())
        
        if has_numbers:
            score += 1.5
        else:
            self.feedback.append("Add quantified achievements with numbers")
        
        if has_company_names:
            score += 1.0
        
        if has_technologies:
            score += 1.5
        
        if has_action_verbs >= 2:
            score += 1.0
        
        return max(0, min(10, score))
    
    def _score_relevance(self, answer: str, jd_requirements: Dict[str, Any]) -> float:
        """Score relevance to JD requirements."""
        score = 5.0
        answer_lower = answer.lower()
        
        # Check for JD skill mentions
        skills = jd_requirements.get("must_have_skills", []) + jd_requirements.get("tech_stack", [])
        skills_mentioned = sum(1 for s in skills if s.lower() in answer_lower)
        
        if skills_mentioned >= 3:
            score += 3.0
        elif skills_mentioned >= 2:
            score += 2.0
        elif skills_mentioned >= 1:
            score += 1.0
        else:
            self.feedback.append("Mention more JD-specific skills and requirements")
        
        # Check for responsibility alignment
        responsibilities = jd_requirements.get("key_responsibilities", [])
        resp_aligned = sum(1 for r in responsibilities if any(word in answer_lower for word in r.lower().split()[:3]))
        
        if resp_aligned >= 2:
            score += 2.0
        
        return max(0, min(10, score))
    
    def _score_company_alignment(self, answer: str, company: str) -> float:
        """Score alignment with company culture."""
        score = 5.0
        answer_lower = answer.lower()
        
        intel = get_company_intelligence(company)
        
        # Check for company name
        if company.lower() in answer_lower:
            score += 2.0
        
        # Check for culture keyword usage
        culture_hits = sum(1 for k in intel.get("culture_keywords", []) if k.lower() in answer_lower)
        score += min(2.0, culture_hits * 0.5)
        
        # Check for avoided phrases
        avoid_hits = sum(1 for a in intel.get("avoid_saying", []) if a.lower() in answer_lower)
        if avoid_hits > 0:
            score -= avoid_hits * 1.5
            self.feedback.append(f"Avoid phrases like: {intel.get('avoid_saying', [])[:2]}")
        
        return max(0, min(10, score))
    
    def _score_confidence(self, answer: str) -> float:
        """Score confidence level of the answer."""
        score = 7.0  # Start high, deduct for issues
        answer_lower = answer.lower()
        
        # Penalty for hedging language
        hedges = ["i think", "i believe", "maybe", "perhaps", "i hope", "i would try"]
        hedge_count = sum(1 for h in hedges if h in answer_lower)
        score -= hedge_count * 0.5
        
        # Penalty for desperate language
        desperate = ["grateful for any", "hope you consider", "humbly", "please give me a chance"]
        if any(d in answer_lower for d in desperate):
            score -= 2.0
            self.feedback.append("Remove desperate/pleading language - be confident")
        
        # Bonus for confident language
        confident = ["i delivered", "i led", "i built", "i achieved", "i drove"]
        confidence_hits = sum(1 for c in confident if c in answer_lower)
        score += min(2.0, confidence_hits * 0.5)
        
        return max(0, min(10, score))
    
    def _score_length(self, answer: str) -> float:
        """Score answer length appropriateness."""
        words = len(answer.split())
        
        if 100 <= words <= 200:
            return 10.0
        elif 80 <= words <= 250:
            return 8.0
        elif 60 <= words <= 300:
            return 6.0
            self.feedback.append("Adjust answer length (target 120-180 words)")
        else:
            self.feedback.append("Answer is too short or too long")
            return 4.0
    
    def _score_no_cliches(self, answer: str) -> float:
        """Score absence of clichÃ©s."""
        score = 10.0
        answer_lower = answer.lower()
        
        cliches = [
            "passionate", "team player", "hard worker", "go-getter",
            "think outside the box", "synergy", "leverage", "dynamic",
            "results-driven", "detail-oriented", "self-starter",
            "fast learner", "people person", "perfectionist"
        ]
        
        cliche_count = sum(1 for c in cliches if c in answer_lower)
        score -= cliche_count * 2.0
        
        if cliche_count > 0:
            self.feedback.append(f"Remove clichÃ©s: found {cliche_count} generic phrases")
        
        return max(0, min(10, score))
    
    def _score_question_match(self, answer: str, question: str, q_type: str) -> float:
        """Score how well the answer matches the question type."""
        score = 7.0
        answer_lower = answer.lower()
        
        if q_type == "why_hire_you":
            if "unique" in answer_lower or "different" in answer_lower or "sets me apart" in answer_lower:
                score += 2.0
            if any(v in answer_lower for v in ["built", "achieved", "delivered"]):
                score += 1.0
        
        elif q_type == "why_this_company":
            # Should mention company-specific things
            if re.search(r"(specifically|unique|particular|your)", answer_lower):
                score += 2.0
        
        elif q_type == "weakness":
            # Should show growth
            if any(w in answer_lower for w in ["learned", "improved", "working on", "developed"]):
                score += 2.0
            else:
                self.feedback.append("Show growth/improvement on the weakness")
        
        elif q_type == "achievement":
            # Should have STAR elements
            has_result = bool(re.search(r'(result|led to|achieved|improved)', answer_lower))
            if has_result:
                score += 2.0
            else:
                self.feedback.append("Include clear result/outcome of your achievement")
        
        return max(0, min(10, score))
    
    def _get_grade(self, score: float) -> str:
        """Convert score to letter grade."""
        if score >= 9.0:
            return "A+"
        elif score >= 8.5:
            return "A"
        elif score >= 8.0:
            return "A-"
        elif score >= 7.5:
            return "B+"
        elif score >= 7.0:
            return "B"
        elif score >= 6.5:
            return "B-"
        elif score >= 6.0:
            return "C+"
        elif score >= 5.5:
            return "C"
        else:
            return "Needs Improvement"


# ============================================================
# ðŸ” SKILL GAP ANALYZER
# ============================================================

async def analyze_skill_gaps(
    resume_highlights: Dict[str, Any],
    jd_requirements: Dict[str, Any],
    model: str
) -> Dict[str, Any]:
    """Analyze gaps between resume and JD requirements."""
    
    resume_skills = set(s.lower() for s in resume_highlights.get("technical_skills", []))
    jd_must_have = set(s.lower() for s in jd_requirements.get("must_have_skills", []))
    jd_nice_to_have = set(s.lower() for s in jd_requirements.get("nice_to_have_skills", []))
    
    # Find gaps
    must_have_gaps = jd_must_have - resume_skills
    nice_to_have_gaps = jd_nice_to_have - resume_skills
    
    # Find matches
    must_have_matches = jd_must_have & resume_skills
    nice_to_have_matches = jd_nice_to_have & resume_skills
    
    # Generate addressing strategies for gaps
    gap_strategies = {}
    for gap in list(must_have_gaps)[:5]:
        gap_strategies[gap] = _get_gap_addressing_strategy(gap, resume_skills)
    
    return {
        "must_have_matches": list(must_have_matches),
        "must_have_gaps": list(must_have_gaps),
        "nice_to_have_matches": list(nice_to_have_matches),
        "nice_to_have_gaps": list(nice_to_have_gaps),
        "match_percentage": len(must_have_matches) / max(1, len(jd_must_have)) * 100,
        "gap_strategies": gap_strategies,
        "strengths_to_emphasize": list(must_have_matches)[:5],
        "transferable_skills": _find_transferable_skills(resume_skills, must_have_gaps)
    }


def _get_gap_addressing_strategy(gap: str, resume_skills: Set[str]) -> str:
    """Get strategy to address a specific skill gap."""
    strategies = {
        "default": f"Acknowledge you're developing {gap} skills while highlighting related experience",
        "learning": f"Express genuine interest in deepening {gap} expertise through this role",
        "transferable": f"Connect your existing skills to {gap} through similar problem-solving approaches"
    }
    
    # Check for related skills
    related_found = [s for s in resume_skills if any(word in s for word in gap.split())]
    if related_found:
        return f"Leverage your {related_found[0]} experience as foundation for {gap}"
    
    return strategies["learning"]


def _find_transferable_skills(resume_skills: Set[str], gaps: Set[str]) -> List[str]:
    """Find transferable skills that could address gaps."""
    transferable = []
    
    skill_families = {
        "python": ["programming", "scripting", "automation"],
        "sql": ["database", "data", "query"],
        "machine learning": ["ai", "ml", "modeling", "statistics"],
        "aws": ["cloud", "infrastructure", "devops"],
        "docker": ["containerization", "kubernetes", "devops"],
        "spark": ["big data", "distributed", "hadoop"]
    }
    
    for skill in resume_skills:
        for gap in gaps:
            skill_lower = skill.lower()
            gap_lower = gap.lower()
            
            # Check if in same family
            for family_key, family_terms in skill_families.items():
                if any(t in skill_lower for t in [family_key] + family_terms):
                    if any(t in gap_lower for t in [family_key] + family_terms):
                        transferable.append(f"{skill} â†’ {gap}")
    
    return transferable[:5]


# ============================================================
# ðŸš¨ RED FLAG DETECTION
# ============================================================

async def detect_red_flags(
    resume_text: str,
    resume_highlights: Dict[str, Any],
    model: str
) -> Dict[str, Any]:
    """Detect potential red flags that need proactive addressing."""
    
    red_flags = []
    addressing_strategies = {}
    
    # Check for employment gaps (simplified heuristic)
    years_mentioned = re.findall(r'20\d{2}', resume_text)
    if years_mentioned:
        years = sorted(set(int(y) for y in years_mentioned))
        for i in range(len(years) - 1):
            if years[i+1] - years[i] > 1:
                gap = f"Potential gap between {years[i]} and {years[i+1]}"
                red_flags.append(gap)
                addressing_strategies[gap] = "Be prepared to explain this period positively (learning, personal project, etc.)"
    
    # Check for short tenures
    companies = resume_highlights.get("companies_worked", [])
    if len(companies) > 3:
        red_flags.append("Multiple companies - may raise job-hopping concerns")
        addressing_strategies["job_hopping"] = "Frame as intentional career growth and diverse experience"
    
    # Check for career change signals
    roles = resume_highlights.get("roles", [])
    if roles:
        role_types = set(r.lower().split()[0] for r in roles if r)
        if len(role_types) > 2:
            red_flags.append("Diverse role types - may raise focus concerns")
            addressing_strategies["career_change"] = "Present as intentional breadth-building for current goals"
    
    return {
        "red_flags": red_flags,
        "addressing_strategies": addressing_strategies,
        "proactive_topics": list(addressing_strategies.keys())
    }


# ============================================================
# ðŸŽ­ PERSONAL BRAND EXTRACTOR
# ============================================================

async def extract_personal_brand(
    resume_highlights: Dict[str, Any],
    model: str
) -> Dict[str, Any]:
    """Extract candidate's personal brand/theme for consistency."""
    
    achievements = resume_highlights.get("top_achievements", [])
    skills = resume_highlights.get("technical_skills", [])
    leadership = resume_highlights.get("leadership_examples", [])
    
    # Identify recurring themes
    themes = []
    
    # Technical depth theme
    if len(skills) > 5:
        themes.append("technical depth and expertise")
    
    # Leadership theme
    if leadership:
        themes.append("technical leadership and ownership")
    
    # Impact theme
    if any("impact" in str(a).lower() or "improved" in str(a).lower() for a in achievements):
        themes.append("measurable impact and results")
    
    # Innovation theme
    if any("built" in str(a).lower() or "created" in str(a).lower() or "designed" in str(a).lower() for a in achievements):
        themes.append("building and creating")
    
    # Primary brand statement
    primary_theme = themes[0] if themes else "technical excellence"
    
    return {
        "primary_theme": primary_theme,
        "supporting_themes": themes[1:3] if len(themes) > 1 else [],
        "brand_statement": f"A professional known for {primary_theme}",
        "consistency_keywords": themes,
        "differentiators": leadership[:2] if leadership else achievements[:2]
    }


# ============================================================
# ðŸ”® FOLLOW-UP QUESTION PREDICTOR
# ============================================================

def predict_followup_questions(
    question: str,
    answer: str,
    q_type: str,
    q_strategy: Dict[str, Any]
) -> List[Dict[str, str]]:
    """Predict likely follow-up questions based on the answer."""
    
    followups = []
    
    # Get strategy-defined follow-ups
    likely_followups = q_strategy.get("likely_followups", [])
    for f in likely_followups[:3]:
        followups.append({
            "question": f,
            "type": "standard",
            "preparation_tip": "Be ready with a specific example"
        })
    
    # Analyze answer for specific follow-up triggers
    answer_lower = answer.lower()
    
    # If numbers mentioned, expect drilling
    if re.search(r'\d+%?', answer):
        followups.append({
            "question": "How did you measure that? / How did you arrive at that number?",
            "type": "verification",
            "preparation_tip": "Be ready to explain your methodology"
        })
    
    # If project mentioned, expect details
    if "project" in answer_lower or "system" in answer_lower:
        followups.append({
            "question": "Tell me more about the technical architecture",
            "type": "depth",
            "preparation_tip": "Know the technical details of what you mentioned"
        })
    
    # If team mentioned, expect collaboration questions
    if "team" in answer_lower or "collaborated" in answer_lower:
        followups.append({
            "question": "How did you handle disagreements with the team?",
            "type": "behavioral",
            "preparation_tip": "Have a specific conflict resolution example ready"
        })
    
    return followups[:5]


# ============================================================
# ðŸ”’ UTILITIES
# ============================================================

def _tex_safe(s: str) -> str:
    try:
        return secure_tex_input(s)
    except TypeError:
        return secure_tex_input("inline.txt", s)


def _is_responses_only_model(name: str) -> bool:
    if not name:
        return False
    return bool(re.match(r"^(gpt-image|dall[- ]?e|whisper)", name, flags=re.I))


def _get_session_key(jd_text: str, resume_text: str) -> str:
    """Generate session key for consistency tracking."""
    content = (jd_text[:500] + resume_text[:500]).encode()
    return hashlib.md5(content).hexdigest()[:16]


# ============================================================
# ðŸ§  REQUEST MODEL
# ============================================================

class TalkReq(BaseModel):
    jd_text: str = ""
    question: str
    resume_tex: Optional[str] = None
    resume_plain: Optional[str] = None
    tone: str = "balanced"
    humanize: bool = True
    model: str = ANSWER_MODEL
    context_key: Optional[str] = None
    context_id: Optional[str] = None
    title: Optional[str] = None
    use_latest: bool = True
    # New optional fields
    interview_stage: Optional[str] = None  # recruiter, technical, hiring_manager, final
    include_quality_score: bool = True
    include_followups: bool = True


# ============================================================
# ðŸ§© CONTEXT HELPERS
# ============================================================

def _path_for_key(key: str) -> Path:
    return CONTEXT_DIR / f"{safe_filename(key)}.json"


def _latest_path() -> Optional[Path]:
    files = sorted(CONTEXT_DIR.glob("*.json"), key=lambda p: p.stat().st_mtime, reverse=True)
    return files[0] if files else None


def _read_json(path: Optional[Path]) -> Dict[str, Any]:
    if not path or not path.exists():
        return {}
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return {}


def _coerce_key_from_ctx(ctx: Dict[str, Any], fallback_path: Optional[Path]) -> str:
    if ctx.get("key"):
        return str(ctx["key"]).strip()
    c, r = (ctx.get("company") or "").strip(), (ctx.get("role") or "").strip()
    if c and r:
        return f"{safe_filename(c)}__{safe_filename(r)}"
    return fallback_path.stem if fallback_path else ""


def _pick_resume_from_ctx(ctx: Dict[str, Any]) -> str:
    h = (ctx.get("humanized") or {})
    o = (ctx.get("optimized") or {})
    for candidate in (h.get("tex"), o.get("tex"), ctx.get("humanized_tex"), ctx.get("resume_tex")):
        if isinstance(candidate, str) and candidate.strip():
            return candidate
    return ""


def _pick_coverletter_from_ctx(ctx: Dict[str, Any]) -> str:
    cl = (ctx.get("cover_letter") or {})
    v = cl.get("tex")
    return v.strip() if isinstance(v, str) else ""


def _load_context(req: TalkReq) -> Tuple[Dict[str, Any], Optional[Path]]:
    path: Optional[Path] = None
    if (req.context_key or "").strip():
        path = _path_for_key(req.context_key.strip())
    elif (req.context_id or req.title or "").strip():
        stem = safe_filename((req.context_id or req.title or "").strip())
        path = CONTEXT_DIR / f"{stem}.json"
    elif req.use_latest:
        path = _latest_path()

    ctx = _read_json(path)
    if ctx:
        meta = {
            "key": _coerce_key_from_ctx(ctx, path),
            "company": ctx.get("company"),
            "role": ctx.get("role"),
        }
        log_event("talk_context_used", meta)
    return ctx, path


# ============================================================
# ðŸ§© OPENAI HELPERS
# ============================================================

async def _gen_text_smart(system: str, user: str, model: str) -> str:
    if not openai_client:
        raise HTTPException(status_code=500, detail="OpenAI SDK not installed.")
    if not (getattr(config, "OPENAI_API_KEY", "") or "").strip():
        raise HTTPException(status_code=400, detail="OPENAI_API_KEY missing.")

    requested_model = (model or "").strip() or CHAT_SAFE_DEFAULT

    if _is_responses_only_model(requested_model):
        requested_model = CHAT_SAFE_DEFAULT

    try:
        r = await openai_client.chat.completions.create(
            model=requested_model,
            messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
        )
        return (r.choices[0].message.content or "").strip()
    except Exception as e:
        log_event("talk_gen_fail", {"error": str(e), "model": requested_model})
        raise


# ============================================================
# ðŸ”Ž RESUME & JD ANALYSIS
# ============================================================

async def extract_resume_highlights(resume_text: str, model: str = SUMMARIZER_MODEL) -> Dict[str, Any]:
    """Extract KEY achievements and skills from resume."""
    if not (resume_text or "").strip():
        return {"achievements": [], "skills": [], "experiences": [], "companies_worked": [], "technical_skills": []}

    prompt = f"""Extract the MOST IMPRESSIVE and RELEVANT highlights from this resume.

RESUME:
{resume_text[:5000]}

Return STRICT JSON:
{{
    "top_achievements": ["3-5 most impressive achievements with QUANTIFIED outcomes"],
    "technical_skills": ["key technical skills with context"],
    "leadership_examples": ["ownership/leadership examples"],
    "unique_strengths": ["what makes this candidate unique"],
    "companies_worked": ["company names"],
    "quantified_results": ["any results with numbers/metrics"],
    "roles": ["job titles held"]
}}

Focus on SPECIFIC, IMPRESSIVE, QUANTIFIED achievements.
"""

    try:
        result = await _gen_text_smart("Extract resume highlights as JSON.", prompt, model)
        match = re.search(r"\{[\s\S]*\}", result)
        if match:
            return json.loads(match.group(0))
    except Exception as e:
        log_event("resume_highlight_fail", {"error": str(e)})
    
    return {"achievements": [], "skills": [], "experiences": [], "companies_worked": [], "technical_skills": []}


async def extract_jd_requirements(jd_text: str, model: str = SUMMARIZER_MODEL) -> Dict[str, Any]:
    """Extract key requirements from JD."""
    if not (jd_text or "").strip():
        return {"requirements": [], "tech_stack": [], "responsibilities": [], "must_have_skills": [], "nice_to_have_skills": [], "key_responsibilities": []}

    prompt = f"""Extract the KEY requirements from this job description.

JOB DESCRIPTION:
{jd_text[:4000]}

Return STRICT JSON:
{{
    "must_have_skills": ["required technical skills"],
    "nice_to_have_skills": ["preferred skills"],
    "key_responsibilities": ["main job duties"],
    "tech_stack": ["specific technologies mentioned"],
    "team_context": "what team/product this is for",
    "success_metrics": ["how success might be measured"],
    "company_challenges": ["challenges this role addresses"]
}}

Be specific. Extract REAL requirements from the JD.
"""

    try:
        result = await _gen_text_smart("Extract JD requirements as JSON.", prompt, model)
        match = re.search(r"\{[\s\S]*\}", result)
        if match:
            return json.loads(match.group(0))
    except Exception as e:
        log_event("jd_extract_fail", {"error": str(e)})
    
    return {"requirements": [], "tech_stack": [], "responsibilities": [], "must_have_skills": [], "nice_to_have_skills": [], "key_responsibilities": []}


# ============================================================
# ðŸ’¬ ULTIMATE KILLER ANSWER GENERATION
# ============================================================

async def generate_killer_answer(
    jd_text: str,
    resume_text: str,
    question: str,
    company: str,
    role: str,
    model: str,
    cover_letter: str = "",
    resume_highlights: Optional[Dict[str, Any]] = None,
    jd_requirements: Optional[Dict[str, Any]] = None,
    skill_gaps: Optional[Dict[str, Any]] = None,
    personal_brand: Optional[Dict[str, Any]] = None,
    interview_stage: Optional[str] = None,
) -> str:
    """Generate an ULTIMATE KILLER answer with all enhancements."""
    
    # Detect question type and get strategy
    q_type, q_strategy = detect_question_type(question)
    
    # Get company intelligence
    company_intel = get_company_intelligence(company)
    
    # Build context strings
    achievements_str = ""
    if resume_highlights:
        achievements = resume_highlights.get("top_achievements", [])
        if achievements:
            achievements_str = "TOP ACHIEVEMENTS FROM RESUME (use these EXACT facts):\n" + "\n".join(f"â€¢ {a}" for a in achievements[:5])
    
    jd_reqs_str = ""
    if jd_requirements:
        skills = jd_requirements.get("must_have_skills", [])
        responsibilities = jd_requirements.get("key_responsibilities", [])
        if skills:
            jd_reqs_str += "REQUIRED SKILLS (mention 2-3): " + ", ".join(skills[:8]) + "\n"
        if responsibilities:
            jd_reqs_str += "KEY RESPONSIBILITIES: " + "; ".join(responsibilities[:5])
    
    # Skill gap context
    gap_context = ""
    if skill_gaps and skill_gaps.get("must_have_gaps"):
        gaps = skill_gaps.get("must_have_gaps", [])[:3]
        strategies = skill_gaps.get("gap_strategies", {})
        gap_context = f"\nâš ï¸ SKILL GAPS TO ADDRESS HONESTLY (if relevant):\n"
        for gap in gaps:
            strategy = strategies.get(gap, "Show willingness to learn")
            gap_context += f"â€¢ {gap}: {strategy}\n"
    
    # Personal brand context
    brand_context = ""
    if personal_brand:
        brand_context = f"\nðŸŽ¯ PERSONAL BRAND THEME: {personal_brand.get('primary_theme', 'technical excellence')}\n"
        brand_context += f"Consistently emphasize: {', '.join(personal_brand.get('consistency_keywords', []))}\n"
    
    # Interview stage calibration
    stage_context = ""
    if interview_stage:
        stage_intel = company_intel.get("interview_stages", {}).get(interview_stage, "")
        if stage_intel:
            stage_context = f"\nðŸ“‹ INTERVIEW STAGE: {interview_stage.upper()}\nFocus: {stage_intel}\n"
    
    what_impresses = company_intel.get("what_impresses_them", [])
    avoid_saying = company_intel.get("avoid_saying", [])
    
    # Build the ultimate prompt
    sys_prompt = f"""You are helping a candidate give a KILLER answer that will WIN the interview.

ðŸŽ¯ QUESTION TYPE: {q_type.upper()}
ðŸ“‹ STRATEGY: {q_strategy['strategy']}

REQUIRED STRUCTURE:
{chr(10).join(f"â€¢ {s}" for s in q_strategy['structure'])}

ðŸ¢ WHAT {company.upper()} VALUES:
{chr(10).join(f"â€¢ {v}" for v in company_intel.get('what_they_value', [])[:4])}

âœ… WHAT IMPRESSES THEM:
{chr(10).join(f"â€¢ {w}" for w in what_impresses[:4])}

âŒ AVOID SAYING (company-specific):
{chr(10).join(f"â€¢ {a}" for a in avoid_saying[:4])}

ðŸ’¡ OPENING HOOK IDEAS (adapt one to be specific):
{chr(10).join(f"â€¢ {h}" for h in q_strategy['hook_templates'][:3])}

âš ï¸ TRAP WARNINGS:
{chr(10).join(f"â€¢ {t}" for t in q_strategy.get('trap_warnings', [])[:3])}
{stage_context}
{brand_context}
{gap_context}

ðŸ“ ANSWER REQUIREMENTS:
1. HOOK: First sentence must grab attention - NO generic openings
2. GROUNDING: Use ONLY facts from the resume - do NOT invent achievements
3. SPECIFICITY: Include EXACT numbers, tools, company names from resume
4. RELEVANCE: Map directly to THIS company's needs using JD keywords
5. FORWARD: Show what you'll CONTRIBUTE, not just what you've done
6. CONFIDENCE: Sound natural and confident - no hedging or pleading
7. LENGTH: 2-3 paragraphs, 120-180 words total

ðŸš« ABSOLUTE RULES - NEVER VIOLATE:
- Do NOT invent achievements, metrics, or company names not in resume
- Do NOT use clichÃ©s: "passionate", "team player", "hard worker", "excited"
- Do NOT start with: "I am writing...", "Thank you for...", "I believe..."
- Do NOT mention GPA, graduation dates, or academic achievements
- Do NOT sound desperate: "grateful for opportunity", "hope you consider"
- Do NOT be generic - EVERY sentence must be specific to THIS role/company
- Do NOT use hedging: "I think", "maybe", "perhaps"

âœ¨ TONE: Confident professional who knows their worth and has done their research.
"""

    user_prompt = f"""Generate a KILLER answer for this question:

QUESTION: {question}

COMPANY: {company}
ROLE: {role}

{achievements_str}

{jd_reqs_str}

JOB DESCRIPTION (key excerpts):
{jd_text[:3000]}

RESUME (ONLY use facts from here - do not invent):
{resume_text[:3000]}

{f'COVER LETTER (additional context):{chr(10)}{cover_letter[:1500]}' if cover_letter else ''}

Remember:
- Open with a HOOK that grabs attention
- Use ONLY facts from the resume
- Be SPECIFIC with examples and outcomes
- Show you understand {company}'s unique needs
- Sound CONFIDENT but not arrogant
- 2-3 paragraphs, 120-180 words
"""

    start = time.time()
    answer = await _gen_text_smart(sys_prompt, user_prompt, model=model)
    latency = round(time.time() - start, 2)
    
    log_event("killer_answer_generated", {
        "question_type": q_type,
        "company": company,
        "latency": latency,
        "words": len(answer.split()),
        "interview_stage": interview_stage
    })

    return _tex_safe(answer)


# ============================================================
# âœ¨ HUMANIZE (with answer-specific instructions)
# ============================================================

async def humanize_answer(answer_text: str, tone: str, q_type: str) -> Tuple[str, bool]:
    """Refine the answer while preserving killer elements."""
    api_base = (getattr(config, "API_BASE_URL", "") or "").rstrip("/") or "http://127.0.0.1:8000"
    url = f"{api_base}/api/superhuman/rewrite"
    
    instructions = (
        f"Rewrite this {q_type} interview answer. "
        "PRESERVE: the opening hook, specific achievements, numbers, company names, and confident tone. "
        "IMPROVE: natural flow, remove any AI-sounding phrases, make it sound like a real human. "
        "KEEP: 2-3 paragraphs, 120-180 words total. "
        "DO NOT: add clichÃ©s, make it generic, remove specific details, or change facts."
    )
    
    payload = {
        "text": instructions + "\n\n" + answer_text,
        "mode": "interview_answer",
        "tone": tone,
        "latex_safe": True,
    }

    try:
        async with httpx.AsyncClient(timeout=45.0) as client:
            r = await client.post(url, json=payload)
        r.raise_for_status()
        data = r.json()
        rewritten = data.get("rewritten") or answer_text
        was_humanized = isinstance(rewritten, str) and rewritten.strip() != answer_text.strip()
        return _tex_safe(rewritten), was_humanized
    except Exception as e:
        log_event("talk_humanize_fail", {"error": str(e)})
        return answer_text, False


# ============================================================
# ðŸ”„ ANSWER IMPROVEMENT LOOP
# ============================================================

async def improve_answer_if_needed(
    answer: str,
    quality_score: Dict[str, Any],
    question: str,
    company: str,
    role: str,
    jd_requirements: Dict[str, Any],
    resume_highlights: Dict[str, Any],
    model: str,
    max_iterations: int = 2
) -> str:
    """Improve answer if quality score is below threshold."""
    
    if quality_score.get("overall_score", 0) >= 7.5:
        return answer  # Good enough
    
    if max_iterations <= 0:
        return answer  # Gave up
    
    feedback = quality_score.get("feedback", [])
    if not feedback:
        return answer
    
    improvement_prompt = f"""Improve this interview answer based on the following feedback:

CURRENT ANSWER:
{answer}

FEEDBACK TO ADDRESS:
{chr(10).join(f"â€¢ {f}" for f in feedback)}

QUESTION: {question}
COMPANY: {company}
ROLE: {role}

Requirements:
- Fix the specific issues mentioned in feedback
- Keep the same length (120-180 words)
- Maintain confidence and specificity
- Do NOT add clichÃ©s or generic phrases
- Do NOT invent new achievements

Return only the improved answer, nothing else.
"""

    try:
        improved = await _gen_text_smart(
            "You are improving an interview answer based on specific feedback.",
            improvement_prompt,
            model
        )
        
        # Re-score
        scorer = AnswerQualityScorer()
        new_score = scorer.score_answer(
            improved, question, "generic", company, jd_requirements, resume_highlights
        )
        
        if new_score.get("overall_score", 0) > quality_score.get("overall_score", 0):
            log_event("answer_improved", {
                "old_score": quality_score.get("overall_score"),
                "new_score": new_score.get("overall_score")
            })
            return improved
        
    except Exception as e:
        log_event("answer_improvement_fail", {"error": str(e)})
    
    return answer


# ============================================================
# ðŸŸ¢ HEALTH CHECK
# ============================================================

@router.get("/ping")
async def ping():
    now = datetime.now(tz=timezone.utc)
    return {"ok": True, "service": "talk", "version": "4.0.0", "epoch": time.time(), "iso": now.isoformat()}


# ============================================================
# ðŸš€ MAIN ENDPOINT - ULTIMATE VERSION
# ============================================================

@router.post("/answer")
@router.post("")
async def talk_to_hirex(req: TalkReq):
    """
    Generate an ULTIMATE, interview-winning answer.
    
    Features:
    - Question type detection with tailored strategy
    - Company-specific intelligence (values, culture, what impresses)
    - Anti-hallucination grounding (verify claims against resume)
    - Answer quality scoring with feedback
    - Skill gap analysis with addressing strategies
    - Follow-up question prediction
    - Personal brand consistency
    - Interview stage calibration
    - Automatic answer improvement loop
    """
    
    # Load context if needed
    jd_text = (req.jd_text or "").strip()
    resume_tex = (req.resume_tex or "").strip()
    cover_letter_tex = ""
    used_key = ""
    used_company = ""
    used_role = ""

    if (not jd_text) or (not resume_tex and not (req.resume_plain or "").strip()):
        ctx, ctx_path = _load_context(req)
        if ctx:
            jd_text = jd_text or (ctx.get("jd_text") or "")
            resume_tex = resume_tex or _pick_resume_from_ctx(ctx)
            cover_letter_tex = _pick_coverletter_from_ctx(ctx)
            used_key = _coerce_key_from_ctx(ctx, ctx_path)
            used_company = (ctx.get("company") or "").strip()
            used_role = (ctx.get("role") or "").strip()

    if not jd_text.strip():
        raise HTTPException(status_code=400, detail="Job Description missing.")
    if not (resume_tex or (req.resume_plain or "").strip()):
        raise HTTPException(status_code=400, detail="Resume text missing.")

    resume_text = resume_tex or req.resume_plain or ""
    model = (req.model or ANSWER_MODEL).strip() or ANSWER_MODEL
    
    # Extract company and role from JD if not from context
    if not used_company or not used_role:
        try:
            extract_prompt = f"""Extract company and role from this JD.
Return JSON: {{"company": "...", "role": "..."}}
JD: {jd_text[:2000]}"""
            result = await _gen_text_smart("Extract as JSON.", extract_prompt, SUMMARIZER_MODEL)
            match = re.search(r"\{[\s\S]*\}", result)
            if match:
                data = json.loads(match.group(0))
                used_company = used_company or data.get("company", "Company")
                used_role = used_role or data.get("role", "Role")
        except Exception:
            used_company = used_company or "Company"
            used_role = used_role or "Role"

    # Detect question type
    q_type, q_strategy = detect_question_type(req.question)

    # Extract resume highlights and JD requirements
    resume_highlights = await extract_resume_highlights(resume_text, model)
    jd_requirements = await extract_jd_requirements(jd_text, model)

    # Analyze skill gaps
    skill_gaps = await analyze_skill_gaps(resume_highlights, jd_requirements, model)

    # Extract personal brand
    personal_brand = await extract_personal_brand(resume_highlights, model)

    # Detect red flags
    red_flags = await detect_red_flags(resume_text, resume_highlights, model)

    # Generate killer answer
    draft_answer = await generate_killer_answer(
        jd_text=jd_text,
        resume_text=resume_text,
        question=req.question,
        company=used_company,
        role=used_role,
        model=model,
        cover_letter=cover_letter_tex,
        resume_highlights=resume_highlights,
        jd_requirements=jd_requirements,
        skill_gaps=skill_gaps,
        personal_brand=personal_brand,
        interview_stage=req.interview_stage,
    )

    # Score answer quality
    scorer = AnswerQualityScorer()
    quality_score = scorer.score_answer(
        draft_answer,
        req.question,
        q_type,
        used_company,
        jd_requirements,
        resume_highlights
    )

    # Improve if score is low
    if quality_score.get("overall_score", 0) < 7.5:
        draft_answer = await improve_answer_if_needed(
            draft_answer,
            quality_score,
            req.question,
            used_company,
            used_role,
            jd_requirements,
            resume_highlights,
            model
        )
        # Re-score
        quality_score = scorer.score_answer(
            draft_answer, req.question, q_type, used_company, jd_requirements, resume_highlights
        )

    # Humanize if requested
    if req.humanize:
        final_answer, was_humanized = await humanize_answer(draft_answer, req.tone, q_type)
    else:
        final_answer, was_humanized = draft_answer, False

    # Predict follow-up questions
    followup_predictions = []
    if req.include_followups:
        followup_predictions = predict_followup_questions(req.question, final_answer, q_type, q_strategy)

    # Get company intel summary
    company_intel = get_company_intelligence(used_company)

    # Log
    log_event("talk_ultimate_answer", {
        "question": req.question[:100],
        "question_type": q_type,
        "company": used_company,
        "role": used_role,
        "humanized": was_humanized,
        "quality_score": quality_score.get("overall_score"),
        "quality_grade": quality_score.get("grade"),
        "interview_stage": req.interview_stage
    })

    # Build response (same interface as before, with additional fields)
    response = {
        # Original fields (backward compatible)
        "question": req.question.strip(),
        "question_type": q_type,
        "strategy_used": q_strategy["strategy"],
        "draft_answer": draft_answer,
        "final_text": final_answer,
        "answer": final_answer,
        "tone": req.tone,
        "humanized": was_humanized,
        "model": model,
        "company_intel": {
            "what_they_value": company_intel.get("what_they_value", [])[:3],
            "what_impresses_them": company_intel.get("what_impresses_them", [])[:3],
            "avoid_saying": company_intel.get("avoid_saying", [])[:3],
            "culture_keywords": company_intel.get("culture_keywords", [])[:3],
        },
        "context": {
            "key": used_key,
            "company": used_company,
            "role": used_role,
            "has_cover_letter": bool(cover_letter_tex),
        },
        
        # NEW: Quality scoring
        "quality": {
            "overall_score": quality_score.get("overall_score", 0),
            "grade": quality_score.get("grade", "N/A"),
            "pass": quality_score.get("pass", False),
            "dimension_scores": quality_score.get("dimension_scores", {}),
            "feedback": quality_score.get("feedback", []),
        } if req.include_quality_score else None,
        
        # NEW: Follow-up predictions
        "predicted_followups": followup_predictions if req.include_followups else None,
        
        # NEW: Skill gap analysis
        "skill_analysis": {
            "match_percentage": skill_gaps.get("match_percentage", 0),
            "strengths_to_emphasize": skill_gaps.get("strengths_to_emphasize", [])[:5],
            "gaps_to_address": skill_gaps.get("must_have_gaps", [])[:3],
            "gap_strategies": skill_gaps.get("gap_strategies", {}),
            "transferable_skills": skill_gaps.get("transferable_skills", [])[:3],
        },
        
        # NEW: Personal brand
        "personal_brand": {
            "primary_theme": personal_brand.get("primary_theme", ""),
            "brand_statement": personal_brand.get("brand_statement", ""),
            "consistency_keywords": personal_brand.get("consistency_keywords", [])[:3],
        },
        
        # NEW: Red flags detected
        "red_flags": {
            "detected": red_flags.get("red_flags", []),
            "addressing_strategies": red_flags.get("addressing_strategies", {}),
        } if red_flags.get("red_flags") else None,
        
        # NEW: Interview stage context
        "interview_stage": {
            "stage": req.interview_stage,
            "focus": company_intel.get("interview_stages", {}).get(req.interview_stage, ""),
        } if req.interview_stage else None,
        
        # NEW: Trap warnings for this question type
        "trap_warnings": q_strategy.get("trap_warnings", [])[:3],
        
        # NEW: Salary intelligence (if salary question)
        "salary_intel": company_intel.get("salary_range") if q_type == "salary" else None,
        
        # NEW: Common questions for this company
        "company_common_questions": company_intel.get("common_questions", [])[:5],
        
        # NEW: Why not competitors (if "why this company" question)
        "competitor_differentiation": {
            "competitors": company_intel.get("competitors", []),
            "why_not_them": company_intel.get("why_not_competitors", ""),
        } if q_type == "why_this_company" else None,
    }
    
    # Clean up None values for cleaner response
    response = {k: v for k, v in response.items() if v is not None}
    
    return response


# ============================================================
# ðŸ“š ADDITIONAL ENDPOINTS
# ============================================================

@router.get("/company-intel/{company}")
async def get_company_intel(company: str):
    """Get company intelligence for preparation."""
    intel = get_company_intelligence(company)
    return {
        "company": company,
        "found": intel != DEFAULT_COMPANY_INTELLIGENCE,
        "intelligence": intel
    }


@router.get("/question-types")
async def list_question_types():
    """List all supported question types and their strategies."""
    return {
        "question_types": {
            q_type: {
                "strategy": config["strategy"],
                "structure": config["structure"],
                "hook_templates": config["hook_templates"][:2],
                "trap_warnings": config.get("trap_warnings", [])[:2],
                "likely_followups": config.get("likely_followups", [])[:3]
            }
            for q_type, config in QUESTION_STRATEGIES.items()
        }
    }


@router.post("/analyze-gaps")
async def analyze_gaps_endpoint(
    jd_text: str,
    resume_text: str,
    model: str = SUMMARIZER_MODEL
):
    """Analyze skill gaps between resume and JD."""
    resume_highlights = await extract_resume_highlights(resume_text, model)
    jd_requirements = await extract_jd_requirements(jd_text, model)
    skill_gaps = await analyze_skill_gaps(resume_highlights, jd_requirements, model)
    
    return {
        "resume_skills": resume_highlights.get("technical_skills", []),
        "jd_requirements": jd_requirements.get("must_have_skills", []),
        "analysis": skill_gaps
    }


@router.post("/score-answer")
async def score_answer_endpoint(
    answer: str,
    question: str,
    company: str,
    jd_text: str = "",
    resume_text: str = ""
):
    """Score an answer and get improvement feedback."""
    q_type, _ = detect_question_type(question)
    
    jd_requirements = {}
    resume_highlights = {}
    
    if jd_text:
        jd_requirements = await extract_jd_requirements(jd_text, SUMMARIZER_MODEL)
    if resume_text:
        resume_highlights = await extract_resume_highlights(resume_text, SUMMARIZER_MODEL)
    
    scorer = AnswerQualityScorer()
    score = scorer.score_answer(
        answer, question, q_type, company, jd_requirements, resume_highlights
    )
    
    return {
        "question": question,
        "question_type": q_type,
        "company": company,
        "score": score
    }


@router.post("/predict-followups")
async def predict_followups_endpoint(
    question: str,
    answer: str
):
    """Predict likely follow-up questions."""
    q_type, q_strategy = detect_question_type(question)
    followups = predict_followup_questions(question, answer, q_type, q_strategy)
    
    return {
        "question": question,
        "question_type": q_type,
        "predicted_followups": followups
    }


@router.post("/extract-brand")
async def extract_brand_endpoint(
    resume_text: str,
    model: str = SUMMARIZER_MODEL
):
    """Extract personal brand from resume."""
    resume_highlights = await extract_resume_highlights(resume_text, model)
    personal_brand = await extract_personal_brand(resume_highlights, model)
    
    return {
        "personal_brand": personal_brand,
        "resume_highlights": resume_highlights
    }


@router.post("/detect-red-flags")
async def detect_red_flags_endpoint(
    resume_text: str,
    model: str = SUMMARIZER_MODEL
):
    """Detect potential red flags in resume."""
    resume_highlights = await extract_resume_highlights(resume_text, model)
    red_flags = await detect_red_flags(resume_text, resume_highlights, model)
    
    return {
        "red_flags": red_flags
    }-e 


-e # ===== FILE: ./api/context_store.py =====

# ============================================================
#  HIREX v2.1.0 â€” context_store.py (FINAL, stable-key + dedupe)
#  Store & retrieve JD + (optimized/humanized) resume + cover-letter.
#  File-per-(Company,Role) using key:  {safe_company}__{safe_role}.json
#  "title_for_memory" keeps a timestamped title for UI memory only.
#  Back-compat:
#   â€¢ /api/context/list returns items with both key and id (id===key)
#   â€¢ /api/context/get accepts key=..., id_or_title=..., latest=true
#   â€¢ /api/context/get flattens nested fields for older UIs
# ============================================================

from __future__ import annotations

import json
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any, List, Tuple

from fastapi import APIRouter, HTTPException, Form, Query

from backend.core import config
from backend.core.utils import safe_filename, log_event, ensure_dir

router = APIRouter(prefix="/api/context", tags=["context"])

# ---- Resolve contexts directory with robust fallback ----
def _default_contexts_dir() -> Path:
    # Conservative default inside backend data; ensures writeable path exists
    here = Path(__file__).resolve().parent
    root = here.parents[2] if len(here.parents) >= 3 else here
    return (root / "backend" / "data" / "contexts")

_get_dir = getattr(config, "get_contexts_dir", None)
try:
    CONTEXT_DIR: Path = Path(_get_dir()) if callable(_get_dir) else _default_contexts_dir()
except Exception:
    CONTEXT_DIR: Path = _default_contexts_dir()

ensure_dir(CONTEXT_DIR)


# ---------------------- internal helpers ----------------------

def _nowstamp() -> str:
    return datetime.utcnow().strftime("%Y%m%d-%H%M%S")


def _iso_utc() -> str:
    # ISO 8601 with 'Z' suffix for UTC
    return datetime.utcnow().isoformat(timespec="seconds") + "Z"


def _make_key(company: str, role: str) -> str:
    return f"{safe_filename(company)}__{safe_filename(role)}"


def _path_for_key(key: str) -> Path:
    return CONTEXT_DIR / f"{safe_filename(key)}.json"


def _read(path: Path) -> Dict[str, Any]:
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return {}


def _write(path: Path, payload: Dict[str, Any]) -> None:
    ensure_dir(path.parent)
    path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")


def _coerce_key(d: Dict[str, Any], path: Optional[Path] = None) -> str:
    # Prefer explicit key in file; else derive from company/role; else from filename (legacy)
    if "key" in d and str(d["key"]).strip():
        return str(d["key"]).strip()
    company = str(d.get("company") or "").strip()
    role = str(d.get("role") or "").strip()
    if company and role:
        return _make_key(company, role)
    if path is not None:
        return path.stem
    return ""


def _updated_at(d: Dict[str, Any], default_ts: float = 0.0) -> float:
    try:
        ts = d.get("updated_at") or d.get("saved_at") or ""
        if isinstance(ts, str) and ts:
            # accept '...Z' or bare ISO
            iso = ts.rstrip("Z")
            return datetime.fromisoformat(iso).timestamp()
    except Exception:
        pass
    return default_ts


def _compact_meta(d: Dict[str, Any], key: str) -> Dict[str, Any]:
    """Return a compact row for list(), compatible with old UIs."""
    title = d.get("title_for_memory") or d.get("title") or f"{d.get('company','')} â€” {d.get('role','')}"
    has_opt = bool(((d.get("optimized") or {}).get("tex")) or d.get("resume_tex"))
    has_hum = bool(((d.get("humanized") or {}).get("tex")) or d.get("humanized_tex"))
    cl = d.get("cover_letter") or {}
    has_cl = bool(cl.get("tex") or cl.get("pdf_b64") or d.get("cover_letter_tex") or d.get("cover_letter_pdf_b64"))
    return {
        "key": key,
        "id": key,                     # back-compat for frontends expecting .id
        "title": title,
        "company": d.get("company"),
        "role": d.get("role"),
        "updated_at": d.get("updated_at") or d.get("saved_at"),
        "has_optimized": has_opt,
        "has_humanized": has_hum,
        "has_cover_letter": has_cl,
        "model": d.get("model"),
        "fit_score": d.get("fit_score"),
    }


def _load_all_contexts() -> List[Tuple[str, Path, Dict[str, Any]]]:
    """Return list of (key, path, data)."""
    items: List[Tuple[str, Path, Dict[str, Any]]] = []
    for p in CONTEXT_DIR.glob("*.json"):
        data = _read(p)
        key = _coerce_key(data, p) or p.stem
        items.append((key, p, data))
    return items


def _merge_update(existing: Dict[str, Any], patch: Dict[str, Any]) -> Dict[str, Any]:
    """
    Merge PATCH into existing:
      - Only overwrite nested blobs if new fields are non-empty.
      - Maintain 'optimized', 'humanized', 'cover_letter' subobjects.
    """
    out = dict(existing or {})
    # shallow updates
    for k in ["key", "company", "role", "jd_text", "model", "fit_score"]:
        v = patch.get(k, None)
        if v is not None and (not isinstance(v, str) or v.strip() != ""):
            out[k] = v

    # maintain timestamped memory title
    if "title_for_memory" in patch and patch["title_for_memory"]:
        out["title_for_memory"] = patch["title_for_memory"]

    # legacy flat fields -> normalize into subobjects
    if "resume_tex" in patch or "pdf_base64" in patch:
        opt = dict(out.get("optimized") or {})
        if str(patch.get("resume_tex", "")).strip():
            opt["tex"] = patch["resume_tex"]
        if str(patch.get("pdf_base64", "")).strip():
            opt["pdf_b64"] = patch["pdf_base64"]
        out["optimized"] = opt

    if "humanized_tex" in patch or "pdf_base64_humanized" in patch:
        hum = dict(out.get("humanized") or {})
        if str(patch.get("humanized_tex", "")).strip():
            hum["tex"] = patch["humanized_tex"]
        if str(patch.get("pdf_base64_humanized", "")).strip():
            hum["pdf_b64"] = patch["pdf_base64_humanized"]
        out["humanized"] = hum

    # modern subobjects (prefer these if provided)
    if "optimized" in patch and isinstance(patch["optimized"], dict):
        base = dict(out.get("optimized") or {})
        for k, v in patch["optimized"].items():
            if v is not None and (not isinstance(v, str) or v.strip() != ""):
                base[k] = v
        out["optimized"] = base

    if "humanized" in patch and isinstance(patch["humanized"], dict):
        base = dict(out.get("humanized") or {})
        for k, v in patch["humanized"].items():
            if v is not None and (not isinstance(v, str) or v.strip() != ""):
                base[k] = v
        out["humanized"] = base

    if "cover_letter" in patch and isinstance(patch["cover_letter"], dict):
        base = dict(out.get("cover_letter") or {})
        for k, v in patch["cover_letter"].items():
            if v is not None and (not isinstance(v, str) or v.strip() != ""):
                base[k] = v
        out["cover_letter"] = base

    out["updated_at"] = _iso_utc()
    return out


def _flatten_for_frontend(d: Dict[str, Any]) -> Dict[str, Any]:
    """
    Provide flat aliases expected by older front-ends:
      resume_tex, pdf_base64, humanized_tex, pdf_base64_humanized,
      cover_letter_tex, cover_letter_pdf_b64
    """
    out = dict(d)
    opt = d.get("optimized") or {}
    hum = d.get("humanized") or {}
    cl  = d.get("cover_letter") or {}

    # Resume (optimized)
    out["resume_tex"] = out.get("resume_tex") or opt.get("tex") or ""
    out["pdf_base64"] = out.get("pdf_base64") or opt.get("pdf_b64") or ""

    # Humanized
    out["humanized_tex"] = out.get("humanized_tex") or hum.get("tex") or ""
    out["pdf_base64_humanized"] = out.get("pdf_base64_humanized") or hum.get("pdf_b64") or ""

    # Cover letter
    out["cover_letter_tex"] = out.get("cover_letter_tex") or cl.get("tex") or ""
    out["cover_letter_pdf_b64"] = out.get("cover_letter_pdf_b64") or cl.get("pdf_b64") or ""

    # Convenience â€” mirror some names used by UIs
    out["company_name"] = out.get("company")
    out["role_name"] = out.get("role")
    out["title"] = out.get("title_for_memory") or out.get("title") or f"{out.get('company','')} â€” {out.get('role','')}"

    return out


# -------------------------- routes ----------------------------

@router.post("/save")
async def save_context(
    company: str = Form(...),
    role: str = Form(...),
    jd_text: str = Form(""),

    # Legacy flat payloads from older UI (will be normalized)
    resume_tex: str = Form(""),
    humanized_tex: str = Form(""),
    pdf_base64: str = Form(""),
    pdf_base64_humanized: str = Form(""),

    # Optional modern nested payloads (optimized/humanized/cover_letter)
    optimized: str = Form("", description="JSON string of optimized block (tex, pdf_b64, pdf_path)"),
    humanized: str = Form("", description="JSON string of humanized block (tex, pdf_b64, pdf_path, enabled)"),
    cover_letter: str = Form("", description="JSON string of cover_letter block (tex, pdf_b64, pdf_path, tone, length)"),

    model: str = Form(""),
    fit_score: str = Form(""),
):
    """
    Persist context under a STABLE key per (Company, Role).
    Overwrites previous file with the same key (dedup by design).
    Keeps a 'title_for_memory' that includes a timestamp for UI history labels.
    """
    key = _make_key(company, role)
    path = _path_for_key(key)

    # Parse optional JSON blocks if provided
    def _parse_json_str(s: str) -> Dict[str, Any]:
        try:
            return json.loads(s) if s and s.strip().startswith("{") else {}
        except Exception:
            return {}

    patch: Dict[str, Any] = {
        "key": key,
        "company": company,
        "role": role,
        "jd_text": jd_text,
        "model": model or getattr(config, "DEFAULT_MODEL", "gpt-4o-mini"),
        "fit_score": fit_score,
        "title_for_memory": f"{safe_filename(company)}_{safe_filename(role)}_{_nowstamp()}",
    }

    # legacy flat fields
    if resume_tex or pdf_base64:
        patch.update({"resume_tex": resume_tex, "pdf_base64": pdf_base64})
    if humanized_tex or pdf_base64_humanized:
        patch.update({"humanized_tex": humanized_tex or resume_tex, "pdf_base64_humanized": pdf_base64_humanized})

    # modern nested overrides (preferred)
    opt_obj = _parse_json_str(optimized)
    hum_obj = _parse_json_str(humanized)
    cl_obj = _parse_json_str(cover_letter)
    if opt_obj: patch["optimized"] = opt_obj
    if hum_obj: patch["humanized"] = hum_obj
    if cl_obj: patch["cover_letter"] = cl_obj

    existing = _read(path) if path.exists() else {}
    merged = _merge_update(existing, patch)
    _write(path, merged)

    log_event("context_saved", {"key": key, "company": company, "role": role, "path": str(path)})
    return {"ok": True, "key": key, "path": str(path), "updated_at": merged["updated_at"]}


@router.get("/list")
async def list_contexts(
    limit: int = Query(50, ge=1, le=500),
    dedupe: bool = Query(True),
):
    """
    List recent contexts (newest first). If legacy timestamped files exist,
    `dedupe=True` collapses multiple files to the single latest per key.
    """
    entries = _load_all_contexts()

    # Build (key -> newest (path,data))
    # If dedupe=False we pseudo-namespace keys to keep all files distinct.
    by_key: Dict[str, Tuple[Path, Dict[str, Any], float]] = {}
    for key, p, d in entries:
        ts = _updated_at(d, p.stat().st_mtime)
        idx_key = key if dedupe else f"{key}::{p.name}"
        cur = by_key.get(idx_key)
        if (cur is None) or (ts > cur[2]):
            by_key[idx_key] = (p, d, ts)

    # Sort newest first and compact
    rows = sorted(by_key.items(), key=lambda kv: kv[1][2], reverse=True)[:limit]
    items = [_compact_meta(d, _coerce_key(d, p)) for (_k, (p, d, _)) in rows]
    return {"items": items}


@router.get("/get")
async def get_context(
    key: str = Query("", description="Stable key: {company}__{role}"),
    id_or_title: str = Query("", description="(Back-compat) Either a stable key or a title_for_memory string."),
    latest: bool = Query(False),
):
    """
    Fetch full saved context by:
      â€¢ latest=true (newest item overall), OR
      â€¢ key=stable_key, OR
      â€¢ id_or_title=(stable_key or title_for_memory) â€” back-compat

    Response includes flattened fields for older UIs:
      resume_tex, pdf_base64, humanized_tex, pdf_base64_humanized,
      cover_letter_tex, cover_letter_pdf_b64
    """
    # Case 1: newest overall
    # Case 1: newest overall
    if latest or (not key.strip() and not id_or_title.strip()):
        newest_path: Optional[Path] = None
        newest_ts = -1.0
        for k, p, d in _load_all_contexts():
            ts = _updated_at(d, p.stat().st_mtime)
            if ts > newest_ts:
                newest_ts, newest_path = ts, p
        if not newest_path:
            raise HTTPException(status_code=404, detail="Context not found")
        return _flatten_for_frontend(_read(newest_path))

    # Case 2: explicit stable key
    if key.strip():
        path = _path_for_key(key)
        if not path.exists():
            raise HTTPException(status_code=404, detail="Context not found")
        return _flatten_for_frontend(_read(path))

    # Case 3: back-compat lookup via id_or_title (try key match, then title_for_memory)
    wanted = id_or_title.strip()
    # Try as key first
    candidate = _path_for_key(wanted)
    if candidate.exists():
        return _flatten_for_frontend(_read(candidate))

    # Fallback: scan for title_for_memory match (exact, then loose)
    best: Optional[Dict[str, Any]] = None
    best_ts = -1.0
    for k, p, d in _load_all_contexts():
        title = (d.get("title_for_memory") or d.get("title") or "").strip()
        if title == wanted or safe_filename(title) == safe_filename(wanted):
            ts = _updated_at(d, p.stat().st_mtime)
            if ts > best_ts:
                best, best_ts = d, ts
    if best is not None:
        return _flatten_for_frontend(best)

    raise HTTPException(status_code=404, detail="Context not found")


@router.delete("/delete")
async def delete_context(
    key: str = Query(..., description="Stable key: {company}__{role}")
):
    """
    Delete the single context file for the given (Company, Role) key.
    """
    path = _path_for_key(key)
    if not path.exists():
        raise HTTPException(status_code=404, detail="Context not found")
    path.unlink()
    log_event("context_deleted", {"key": key})
    return {"deleted": True, "key": key}
-e 


-e # ===== FILE: ./api/superhuman.py =====

"""
============================================================
 HIREX v2.1.2 â€” superhuman.py
 ------------------------------------------------------------
 SuperHuman Humanizer API
  â€¢ Rewrites text for clarity, flow, and tone
  â€¢ Preserves factual integrity and metrics
  â€¢ Supports resume, coverletter, paragraph, sentence modes
  â€¢ LaTeX-safe output for integration with HIREX optimizer
  â€¢ Powered by AI Humanize API (https://aihumanize.io)
  â€¢ Local fallback available (tagless) if explicitly enabled

 Author: Sri Akash Kadali
============================================================
"""

from __future__ import annotations

import asyncio
import json
import re
import time
from typing import List, Union, Dict, Any, Optional

import httpx
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field

from backend.core import config
from backend.core.utils import log_event
from backend.core.security import secure_tex_input


# ============================================================
# ðŸ”§ Setup
# ============================================================

router = APIRouter(prefix="/api/superhuman", tags=["superhuman"])

# Vendor endpoints used by HIREX.
HUMANIZE_REWRITE_URL = "https://aihumanize.io/api/v1/rewrite"
HUMANIZE_BALANCE_URL = "https://aihumanize.io/api/v1/surplus"

# Credentials (see core/config.py)
HUMANIZE_API_KEY: str = getattr(config, "HUMANIZE_API_KEY", "") or ""
HUMANIZE_MAIL: str = getattr(config, "HUMANIZE_MAIL", "") or ""

# Behavior toggles and limits
_MAX_ITEMS = 25
_TIMEOUT_S = 120
_LOCAL_ENABLED = bool(getattr(config, "SUPERHUMAN_LOCAL_ENABLED", False))  # default off per new requirements
_CONCURRENCY = 6  # limit concurrent outbound calls

# Humanize always-on defaults (from config; can be overridden via .env)
_HUMANIZE_DEFAULT_ON = getattr(config, "HUMANIZE_DEFAULT_ON", True)
_HUMANIZE_MODE_DEFAULT = str(getattr(config, "HUMANIZE_MODE_DEFAULT", "balance")).lower()
_AIH_MODE_ID = getattr(config, "AIHUMANIZE_MODE_ID", {"quality": "0", "balance": "1", "enhanced": "2"})


# ============================================================
# ðŸ§  Request Model
# ============================================================

from pydantic import BaseModel, Field
from typing import List, Union, Optional

class RewriteRequest(BaseModel):
    text: Union[str, List[str]] = Field(..., description="Text or list of texts to rewrite.")
    mode: str = Field(default="resume")
    tone: str = Field(default="balanced")
    latex_safe: bool = Field(default=True)
    constraints: Dict[str, Any] = Field(
        default_factory=lambda: {"no_fabrication": True, "keep_metrics": True},
        description="Behavior guards such as no_fabrication, keep_metrics",
    )
    max_len: int = Field(1600, description="Max input chars per item (truncate beyond).")


# ============================================================
# ðŸ§© Tone/Mode â†’ AIHumanize model code
#   0: quality   1: balance   2: enhanced
# ============================================================

def _resolve_model_code(tone: str) -> int:
    t = (tone or "").lower().strip()
    if t in {"default", ""}:
        t = _HUMANIZE_MODE_DEFAULT
    if t in {"formal", "academic", "quality"}:
        return 0
    if t in {"balanced", "confident", "balance"}:
        return 1
    if t in {"conversational", "enhanced"}:
        return 2
    # Fallback to configured default mapping
    try:
        return int(_AIH_MODE_ID.get(_HUMANIZE_MODE_DEFAULT, "1"))
    except Exception:
        return 1


# ============================================================
# ðŸ§¼ Post-processing
# ============================================================

_FALLBACK_TAG_RE = re.compile(r"^\[LOCAL-FALLBACK:[^\]]+\]\s*", re.IGNORECASE)

def _clean_text(text: str, latex_safe: bool, mode: str) -> str:
    """Normalize whitespace, strip any fallback labels, and optionally LaTeX-sanitize."""
    t = (text or "").replace("\r", "")
    t = _FALLBACK_TAG_RE.sub("", t)  # never leak [LOCAL-FALLBACK:*]
    t = re.sub(r"[ \t\f\v]+", " ", t).strip()

    if mode == "resume":
        # Resume bullets should be single-line and punchy; trim trailing period
        t = t.replace("\n", " ").rstrip(" .")

    if latex_safe:
        t = secure_tex_input(t)

    return t


# ============================================================
# ðŸ§© Local fallback (offline mode) â€” TAGLESS by design
# ============================================================

def _local_rewrite_stub(text: str, tone: str, mode: str) -> str:
    """
    Offline fallback when no API connectivity or creds are invalid.
    Keep light-touch edits and NEVER prefix any label (tagless).
    """
    t = (text or "")
    # basic normalization + a couple of clarity nips
    t = re.sub(r"\bu\b", "you", t, flags=re.IGNORECASE)
    t = re.sub(r"\br\b", "are", t, flags=re.IGNORECASE)
    t = re.sub(r"\bim\b", "I am", t, flags=re.IGNORECASE)
    if (tone or "").lower().strip() in {"formal", "academic"}:
        t = (t.replace("I'm", "I am")
               .replace("don't", "do not")
               .replace("can't", "cannot"))
    return t.strip()


# ============================================================
# ðŸ” Creds / Headers helpers
# ============================================================

def _require_api_creds() -> None:
    """
    Ensure Humanize is enabled by default and credentials are present.
    If fallback is enabled explicitly, we don't raise here (but still prefer API).
    """
    if not _HUMANIZE_DEFAULT_ON:
        raise HTTPException(status_code=503, detail="Humanize disabled by configuration.")
    if not HUMANIZE_API_KEY or not HUMANIZE_MAIL:
        if _LOCAL_ENABLED:
            log_event("âš ï¸ superhuman_local_fallback", {"reason": "missing_credentials"})
            return
        raise HTTPException(
            status_code=503,
            detail="Humanize API credentials missing. "
                   "Set HUMANIZE_API_KEY and HUMANIZE_MAIL in your .env.",
        )


def _header_variants(key: str) -> List[Dict[str, str]]:
    """
    Build header variants to maximize compatibility and reduce CF challenges.
    """
    key = (key or "").strip()
    base = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "User-Agent": "Mozilla/5.0",
    }
    return [
        dict(base, **{"Authorization": key}),
        dict(base, **{"Authorization": f"Bearer {key}"}),
        dict(base, **{"X-API-KEY": key}),
    ]


def _payload_with_aliases(model_code: int, mail: str, text: str) -> Dict[str, Any]:
    """
    Include common field aliases used by different Humanize integrations.
    Canonical fields:
      - model: 0|1|2
      - mail: registered email
      - data: text to rewrite
    Aliases:
      - email: same as mail
      - text: same as data
      - token: some gateways expect token in body (rare)
    """
    return {
        "model": model_code,
        "mail": mail,
        "email": mail,
        "data": text,
        "text": text,
        "token": HUMANIZE_API_KEY,  # harmless if ignored
    }


# ============================================================
# âš™ï¸ Core Rewrite
# ============================================================

async def _call_humanize(text: str, tone: str, mode: str) -> str:
    """
    Low-level caller that tries multiple header styles automatically.
    Raises HTTPException on hard failures.
    """
    model_code = _resolve_model_code(tone)
    payload = _payload_with_aliases(model_code, HUMANIZE_MAIL, text)

    last_err: Optional[str] = None
    start_time = time.time()

    async with httpx.AsyncClient(timeout=_TIMEOUT_S, headers={"User-Agent": "Mozilla/5.0", "Accept": "application/json"}) as client:
        for hdr in _header_variants(HUMANIZE_API_KEY):
            try:
                r = await client.post(HUMANIZE_REWRITE_URL, headers=hdr, json=payload)
                # Try to parse JSON; if not JSON, surface an HTTP error
                try:
                    data = r.json()
                except json.JSONDecodeError:
                    r.raise_for_status()
                    raise HTTPException(status_code=502, detail="Humanize API returned invalid JSON.")

                code = int(data.get("code", r.status_code))
                msg = str(data.get("msg") or "")
                if code != 200:
                    # Common: 1003 Invalid API Key
                    last_err = f"Humanize error ({code}): {msg or 'unknown'}; hdr={list(hdr.keys())[0]}"
                    # try next header variant
                    continue

                rewritten_raw = data.get("data") or ""
                if not isinstance(rewritten_raw, str):
                    rewritten_raw = str(rewritten_raw)

                latency = round(time.time() - start_time, 2)
                log_event(
                    "superhuman_rewrite_http_success",
                    {"mode": mode, "tone": tone, "chars": len(text), "latency_s": latency, "hdr": list(hdr.keys())[0]},
                )
                return rewritten_raw

            except Exception as e:
                last_err = f"{type(e).__name__}: {e}; hdr={list(hdr.keys())[0]}"
                # try next header variant

    # If we got here, all header variants failed
    raise HTTPException(status_code=502, detail=last_err or "Humanize call failed.")


async def rewrite_single(
    text: str,
    mode: str,
    tone: str,
    constraints: dict,  # reserved for future guarding/filtering
    latex_safe: bool,
    max_len: int,
) -> str:
    """Rewrite a single block of text using the AIHumanize API or (optional) fallback."""
    t_in = (text or "").strip()[: max_len]
    if not t_in:
        return ""

    # Prefer API if creds present; otherwise use optional fallback
    if HUMANIZE_API_KEY and HUMANIZE_MAIL:
        try:
            rewritten_raw = await _call_humanize(t_in, tone, mode)
            return _clean_text(rewritten_raw, latex_safe, mode)
        except HTTPException as e:
            log_event("âš ï¸ superhuman_rewrite_error", {"error": str(e)})
            if _LOCAL_ENABLED:
                log_event("âš™ï¸ using_local_rewrite_fallback", {"text_len": len(t_in)})
                return _clean_text(_local_rewrite_stub(t_in, tone, mode), latex_safe, mode)
            raise
    else:
        if _LOCAL_ENABLED:
            log_event("âš™ï¸ using_local_rewrite_fallback", {"reason": "missing_credentials", "text_len": len(t_in)})
            return _clean_text(_local_rewrite_stub(t_in, tone, mode), latex_safe, mode)
        raise HTTPException(status_code=503, detail="Humanize credentials missing and local fallback disabled.")


# ============================================================
# ðŸš€ Main Endpoint
# ============================================================

@router.post("/rewrite")
async def rewrite_text(req: RewriteRequest):
    """
    SuperHuman rewrite engine â€” transforms one or more text inputs via AIHumanize API.
    Fails fast if Humanize is disabled or credentials are missing (unless explicit local fallback is enabled).
    """
    _require_api_creds()

    if not req.text:
        raise HTTPException(status_code=400, detail="No text provided.")

    items = req.text if isinstance(req.text, list) else [req.text]
    if len(items) > _MAX_ITEMS:
        raise HTTPException(status_code=413, detail=f"Too many items (max {_MAX_ITEMS}).")

    sem = asyncio.Semaphore(_CONCURRENCY)

    async def _bounded_rewrite(t: str):
        async with sem:
            return await rewrite_single(t, req.mode, req.tone, req.constraints, req.latex_safe, req.max_len)

    results = await asyncio.gather(*[_bounded_rewrite(t) for t in items], return_exceptions=True)

    # Propagate first error if any
    for r in results:
        if isinstance(r, Exception):
            raise r

    log_event(
        "superhuman_batch_complete",
        {
            "count": len(items),
            "mode": req.mode,
            "tone": req.tone,
            "latex_safe": req.latex_safe,
            "creds_present": bool(HUMANIZE_API_KEY and HUMANIZE_MAIL),
            "local_enabled": _LOCAL_ENABLED,
        },
    )

    return {"rewritten": results if isinstance(req.text, list) else results[0]}


# ============================================================
# ðŸ’° Balance Check Endpoint
# ============================================================

@router.get("/balance")
async def check_balance():
    """Return remaining words balance from AIHumanize API (or local indicator)."""
    if not (HUMANIZE_API_KEY and HUMANIZE_MAIL):
        if _LOCAL_ENABLED:
            return {"remaining_words": "âˆž (local mode)"}
        raise HTTPException(status_code=503, detail="Humanize API credentials missing.")

    payload = {"mail": HUMANIZE_MAIL, "email": HUMANIZE_MAIL, "token": HUMANIZE_API_KEY}

    async with httpx.AsyncClient(timeout=_TIMEOUT_S, headers={"User-Agent": "Mozilla/5.0", "Accept": "application/json"}) as client:
        last_err: Optional[str] = None
        for hdr in _header_variants(HUMANIZE_API_KEY):
            try:
                r = await client.post(HUMANIZE_BALANCE_URL, headers=hdr, json=payload)
                try:
                    data = r.json()
                except json.JSONDecodeError:
                    r.raise_for_status()
                    raise HTTPException(status_code=502, detail="Humanize balance returned invalid JSON.")

                code = int(data.get("code", r.status_code))
                if code != 200:
                    last_err = f"Humanize balance error ({code}): {data.get('msg') or 'unknown'}; hdr={list(hdr.keys())[0]}"
                    continue

                remaining = data.get("data") or 0
                try:
                    remaining_int = int(remaining)
                except Exception:
                    remaining_int = remaining
                return {"remaining_words": remaining_int}
            except Exception as e:
                last_err = f"{type(e).__name__}: {e}; hdr={list(hdr.keys())[0]}"

    log_event("âš ï¸ superhuman_balance_error", {"error": last_err or "unknown"})
    if _LOCAL_ENABLED:
        return {"remaining_words": "unknown (local fallback)"}
    raise HTTPException(status_code=502, detail=last_err or "Balance check failed.")


# ============================================================
# ðŸ”Ž Health / Debug
# ============================================================

@router.get("/health")
async def health():
    """Simple health check for the superhuman service."""
    return {
        "ok": True,
        "default_on": _HUMANIZE_DEFAULT_ON,
        "local_fallback": _LOCAL_ENABLED,
        "has_api_key": bool(HUMANIZE_API_KEY),
        "has_mail": bool(HUMANIZE_MAIL),
        "endpoint_rewrite": HUMANIZE_REWRITE_URL,
        "endpoint_balance": HUMANIZE_BALANCE_URL,
        "mode_default": _HUMANIZE_MODE_DEFAULT,
    }
-e 


